{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "220fd459",
   "metadata": {},
   "source": [
    "# INFANT MORTALITY PREDICTIONS WITH MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28b766",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208d2e0",
   "metadata": {},
   "source": [
    "Infant mortality is the death of an infant within the first year of life and continues to be a very prominent issue within developed nations such as the United States. According to the Centers for Disease Control and Prevention (CDC), a total of 23,455 deaths occurred in children under the age of 1 year in 2015, which represents an increase of 240 deaths from the previous year. The infant mortality rate is an important marker of the overall health of a society. \n",
    "\n",
    "There are many determinants that impact infant mortality. The Linked Death files collected by the National Bureau of Economic Research from the National Vital Statistics System of the National Center for Health Statistics includes death to all infants born in the same calendar year for which the death certificate can be linked to a birth certificate in the denominator file. We will be working with the 2015 Linked Death files, the last calendar year for which such data is available.\n",
    "\n",
    "The objective of this project was to create a machine learning classification model that would predict the top 3 causes of infant death based on 8 user feature inputs. The causes of death were categorized according to the International Classification of Diseases, Tenth Revision (ICD-10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe56492",
   "metadata": {},
   "source": [
    "#### 1. Importing Relevant Packages\n",
    "\n",
    "#### 2. Exploratory Data Analysis\n",
    "\n",
    "#### 3. Basic Data Transformation\n",
    "\n",
    "#### 4. Constructing the DataFrame\n",
    "\n",
    "#### 5. Creating a Machine Learning Model\n",
    "\n",
    "#### 6. Saving Model\n",
    "\n",
    "#### 7. Making Predictions with Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec0c14",
   "metadata": {},
   "source": [
    "### Importing Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a4e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier, \n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report, \n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_recall_fscore_support,\n",
    "    average_precision_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed1ec8",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347e89b",
   "metadata": {},
   "source": [
    "Data is downloaded directly from the 2015 Linked Birth/Infant Death Cohort Data from the National Bureau of Economic Research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b118de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laterec</th>\n",
       "      <th>dob_yy</th>\n",
       "      <th>dob_mm</th>\n",
       "      <th>dob_tt</th>\n",
       "      <th>dob_wk</th>\n",
       "      <th>bfacil</th>\n",
       "      <th>f_bfacil</th>\n",
       "      <th>bfacil3</th>\n",
       "      <th>mageimp</th>\n",
       "      <th>magerep</th>\n",
       "      <th>...</th>\n",
       "      <th>record_16</th>\n",
       "      <th>record_17</th>\n",
       "      <th>record_18</th>\n",
       "      <th>record_19</th>\n",
       "      <th>record_20</th>\n",
       "      <th>d_restatus</th>\n",
       "      <th>hospd</th>\n",
       "      <th>dweekday</th>\n",
       "      <th>dod_yy</th>\n",
       "      <th>dod_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1504</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1752</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1222</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1107</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>613</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>1130</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23353</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>730</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23354</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>1847</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23355</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>444</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23356</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>2051</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23357 rows Ã— 343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       laterec  dob_yy  dob_mm  dob_tt  dob_wk  bfacil  f_bfacil  bfacil3  \\\n",
       "0            0    2015       1    1504       5       1         1        1   \n",
       "1            0    2015       1    1752       7       1         1        1   \n",
       "2            0    2015       1    1222       2       1         1        1   \n",
       "3            0    2015       1    1107       6       1         1        1   \n",
       "4            0    2015       1     613       3       1         1        1   \n",
       "...        ...     ...     ...     ...     ...     ...       ...      ...   \n",
       "23352        0    2015       9    1130       6       1         1        1   \n",
       "23353        0    2015      10     730       5       1         1        1   \n",
       "23354        0    2015      11    1847       4       1         1        1   \n",
       "23355        0    2015      11     444       7       1         1        1   \n",
       "23356        0    2015      12    2051       7       1         1        1   \n",
       "\n",
       "       mageimp  magerep  ...  record_16  record_17  record_18  record_19  \\\n",
       "0            1        1  ...          2          2          2          2   \n",
       "1            2        2  ...          1          1          1          1   \n",
       "2            3        3  ...          1          1          1          1   \n",
       "3            2        2  ...          1          1          1          1   \n",
       "4            2        2  ...          1          1          1          1   \n",
       "...        ...      ...  ...        ...        ...        ...        ...   \n",
       "23352        2        2  ...          3          3          3          3   \n",
       "23353        2        2  ...          3          3          3          3   \n",
       "23354        1        1  ...          1          1          1          1   \n",
       "23355        2        2  ...          1          1          1          1   \n",
       "23356        2        2  ...          3          3          3          3   \n",
       "\n",
       "       record_20  d_restatus  hospd  dweekday  dod_yy  dod_mm  \n",
       "0              2           2      1         2    2015       1  \n",
       "1              1           1      2         2    2015       4  \n",
       "2              1           1      1         2    2015       1  \n",
       "3              1           1      2         7    2015       5  \n",
       "4              1           1      1         3    2015       1  \n",
       "...          ...         ...    ...       ...     ...     ...  \n",
       "23352          3           3      2         1    2016       1  \n",
       "23353          3           3      1         6    2015      10  \n",
       "23354          1           1      2         3    2016       2  \n",
       "23355          1           1      1         7    2015      11  \n",
       "23356          3           3      1         1    2016       4  \n",
       "\n",
       "[23357 rows x 343 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('linkco2015usnum.csv',low_memory=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b98ee98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'laterec': [0]\n",
      "Column 'dob_yy': [2015]\n",
      "Column 'dob_mm': [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Column 'dob_tt': [1504 1752 1222 ...  202  629  539]\n",
      "Column 'dob_wk': [5 7 2 6 3 4 1]\n",
      "Column 'bfacil': [1 4 5 6 2 7 3 0 9]\n",
      "Column 'f_bfacil': [1 0 2]\n",
      "Column 'bfacil3': [1 2 3]\n",
      "Column 'mageimp': [1 2 3 4 5]\n",
      "Column 'magerep': [1 2 3 4 5]\n",
      "Column 'mager': [18 20 32 25 24 35 28 30 26 27 23 19 21 22 33 38 34 17 29 31 37 16 39 36\n",
      " 40 15 43 44 42 41 46 47 50 45 49 14 48 13 12]\n",
      "Column 'mager14': [ 6  8 10  9 11  7  5  4 12  3 13 14  1]\n",
      "Column 'mager9': [2 3 5 4 6 7 8 9 1]\n",
      "Column 'mbstate_rec': [1 2 3]\n",
      "Column 'restatus': [1 2 3 4]\n",
      "Column 'mrace31': [ 1  2 19  6  4  3 10  5 11 13 14 25 15  8 23 16 12 21  9  7 99 20 22 30\n",
      " 28]\n",
      "Column 'mrace6': [1 2 6 4 3 5 9]\n",
      "Column 'mrace15': [ 1  2 15  9  5 10  3  7 13  6  8  4 14 12 11 99]\n",
      "Column 'mbrace': [1 2 4 3]\n",
      "Column 'mraceimp': [1 0 4 2 5 3 9]\n",
      "Column 'mhisp_r': [5 0 1 4 2 9 3]\n",
      "Column 'f_mhisp': [1 2 7 6 8 3 0 4 5]\n",
      "Column 'mracehisp': [7 2 1 6 4 3 5 8]\n",
      "Column 'mar_p': ['Y' 'N' 'X' 'U' '2' '1']\n",
      "Column 'dmar': [2 1]\n",
      "Column 'mar_imp': [1 3 2 4 5 7 6 9 0 8]\n",
      "Column 'f_mar_p': [1 3 2 4 5 7 6 9 0 8]\n",
      "Column 'meduc': [3 8 5 6 2 1 4 7 9 0]\n",
      "Column 'f_meduc': [1 2 3 9 5 4 0]\n",
      "Column 'fagerpt_flg': [1 9 4 3 2 5 6 7 0]\n",
      "Column 'fagecomb': [19 99 47 32 31 35 33 39 21 30 26 23 28 29 34 24 22 27 37 25 44 51 36 38\n",
      " 40 42 45 41 20 17 15 49 18 48 53 58 50 46 55 66 16 57 56 52 43 62 54 73\n",
      " 60 64 65 61  4  7 11  5  3  6  2  9  8 67 59 10 13 14 69 63]\n",
      "Column 'fage11': [ 2 11  8  5  6  3  4  7  9 10  1]\n",
      "Column 'frace31': [99  2  1  7  4  6  3 16 13  5 14 10 15 23 22 25  9  8 19 31 30 21]\n",
      "Column 'frace6': [9 2 1 6 4 3 5]\n",
      "Column 'frace15': [99  2  1 15  4  9  5  7  3 13 10  6 12 14  8 11]\n",
      "Column 'fbrace': [9 2 1 4 3]\n",
      "Column 'fhisp_r': [1 9 0 5 4 2 3]\n",
      "Column 'f_fhisp': [1 2 8 7 3 5 6 4 0 9]\n",
      "Column 'fracehisp': [7 8 2 1 6 4 3 9 5 0]\n",
      "Column 'feduc': [3 9 4 6 1 2 5 7 8 0]\n",
      "Column 'f_feduc': [1 0 9]\n",
      "Column 'riorlive': [ 0  1  2  3  5  4  6  7  8 10  9 99 11 12]\n",
      "Column 'riordead': [ 0  1  2 99  3  9  5 10  4  6]\n",
      "Column 'riorterm': [ 0  2  3  1  5  4 10 99  7 13  6  9 11 12  8 15]\n",
      "Column 'lbo_rec': [1 2 3 4 7 5 8 6 9]\n",
      "Column 'tbo_rec': [1 2 3 7 4 5 6 8 9]\n",
      "Column 'illb_r': [888  17  37  49  27   3  87  54  58  12  25  11 999  67  14  46  26  22\n",
      "  56  62  15  18 101   9  41  38  85 126  61  66  10  33  88  43  45 279\n",
      "  34  44  78  21  92  20  89 112  48 142 115 140  59  97  76  32  19  16\n",
      "  28  13  63  50  24   7  51  53 143  29  40  35  23 169  52  47  57 116\n",
      "  30 114  82  42  60  81  31  98  68  86  39 118  79 102  77 154 172  36\n",
      " 297  64 177  84  73  90  70  80 103  69 245 131  75 111 162  65 141  83\n",
      "   8 113 124 107  71 224   6 273 184 139 123  72  55 250 148 134 189 108\n",
      " 138 185 165  94 137  74 156 127 130  91 243 105 159  99 135 145 129 121\n",
      " 286  95 122 110 155 152 251  93 171 216 167 175 300 136 149 104 183 125\n",
      " 237 106 151 158 190 178 100 117 198 128 215 157 206 166  96 191 212 133\n",
      " 173 119 236 146 109 164 247 186 194 147 197 176 229 120 242 227 218 219\n",
      " 270 221 238 225 132 187 181 201 203 150 161 222   0   1   4 160 252 199\n",
      " 253 281 174 144 240 153 192 179 217   5 182 209 163 263 214 188 231 196\n",
      " 170 230 223 239 207 284 195 202 260 266 233 168 276 205 204 248 193 249\n",
      " 226 275 256 211 228 200 277 208 262 288 280 292 235 254 180 210 232 271]\n",
      "Column 'illb_r11': [88  2  5  6  4  0  8  1 99  7  3 10  9 11]\n",
      "Column 'ilop_r': [888  83 112 999  19 100  39  72  37  18 116  22   7  15  80  59  30  51\n",
      "  29  25  82  13  99 109  45 146   9 160  17  89  53  32  12 114  20  27\n",
      "   3  11  10  62   8  21  23  69 212  16  68 104  97  81  14   6 111  49\n",
      "  34  93 176 275  50 155 188 110  65  31  95 221 129 139 108   5  78  66\n",
      "  55  38  44  24 113 179  85  40  47 128  75  28  64  42  35  33  90 125\n",
      "  56  67  43  92 147 119  79  77 118  70 150 145  58  41 131  54  26  88\n",
      "  36  87  84 196 184  73 121  46 211 252 154  63  86 195 148 198 177  71\n",
      " 165  74 199 151 213 166  52 107 209  57 102 253  60 186 136 117  94 153\n",
      " 106 126 168   0   1   4  48 132  91 167  61 206 175 169 103 127 223 142\n",
      " 152  76 225 189 187 178 101 105 122 123 300 134 135 162 164 180 133 144\n",
      " 159 158 224 183  96 141 185 200 204 172  98 124 203 194 137 191 115 236\n",
      " 266 174 138 140 143 274 193 231 157 182 130 190 173 215 290 170 161 251\n",
      " 149 254 171 156 202 292 120 235 258 210]\n",
      "Column 'ilop_r11': [88  8 99  3  5  1  2  6  4  0  7 10  9 11]\n",
      "Column 'ilp_r': [888  17  83  37  49 999   3  87  19  58  12  25  11  67  14  46  26  22\n",
      "  39  54  15  18   9  41  38 126  66  10   7  88  45 279  34  44  30  78\n",
      "  21  51  92  29  20  89 112  48  13 140  59  99  97  32  16 160  63  50\n",
      "  24  53 143 114  35  23  40  27 169  47  42   8  60  52  31  98  68 118\n",
      "  79 102  77  43 154 172  36 297  64   6  61  33  73  70  80  82 103  81\n",
      "  69  28 245 131  75 111  86 162  65   5  55  62  57 141 142 179 113 124\n",
      " 101 107  71 139  56  72 250 148 134 189 108 165  94 137  74  90 127  91\n",
      " 243 159 135 145  76 129 121 286 122 155 152 110 251  93 171 216 167 138\n",
      " 123 175 136 115  85 149 104  84 156 237 106 151 158 190 100 117 198 128\n",
      " 177 157  96 191  95 212 133 173 183 236 146 109 300 164 247 150 125 116\n",
      " 147 197 176 229 120 105 184 242 218 219 270 221 238 187 181 201 206 224\n",
      " 222   0   1   4 252 161 194 132 199 253 186 185 281 119 144 130 223 217\n",
      " 163 178 263 214 153 170 209 239 207 166 284 260 196 174 233 204 168 276\n",
      " 225 205 192 248 193 215 226 182 211 200 195 188 208 292 235 180 228 210\n",
      " 232 231 249 203]\n",
      "Column 'ilp_r11': [88  2  8  5  6 99  0  3  4  1  7 10  9 11]\n",
      "Column 'recare': [ 4  3  8  2  1  0  6  7  5 99  9 10 11]\n",
      "Column 'f_mpcb': [1 3 2 5 0 4]\n",
      "Column 'recare5': [2 1 3 4 5 0]\n",
      "Column 'revis': [ 6 12 13  2  3  9  4  7 15  5 10  0  8 11 16  1 25 20 19 14 17 99 42 21\n",
      " 35 18 24 40 30 44 37 26 32 29 27 28 36 23 22 34 49 38 48 50 39 33 41 55\n",
      " 98 60]\n",
      "Column 'revis_rec': [ 4  7  8  2  3  6  5  9  1 11 10 12]\n",
      "Column 'f_tpcv': ['1' 'Y' 'N' '0' 'U' '3' '2' '7' '5' '6' '4']\n",
      "Column 'wic': ['Y' 'N' 'U' '0' '1' '3' '2' '7' '5' '6' '4']\n",
      "Column 'f_wic': [1 0 2 9 4 3 7 5 6]\n",
      "Column 'cig_0': [ 0  6 20 10  4  7 99  5  8  3 15 40  1  2 12 25 30 98 14 11 37 28 26 71\n",
      " 22 16 21 55 65 80 60  9 18 13 35 19 17 50 75 23 32 90]\n",
      "Column 'cig_1': [ 0  6 10 99 20  3  4  7  5  8 15  9  1  2 40 25 12 30 98 11 37 28 26 71\n",
      " 22 16 21 55 65 80 60 13 19 17 50 18 90 14 23]\n",
      "Column 'cig_2': [ 0  6 10 99 20  4  2  7  5 15  3  8  1 35 12 40 30 11 37 28 26 71 22 16\n",
      " 21 55 65 80 60  9 13 17 18 25 98 19 90]\n",
      "Column 'cig_3': [ 0  6 10 99 20  2  4  5  7 15  8  3  1 12 40 30 11 37 28 26 71 22 16 21\n",
      " 55 65 80 60  9 13 98 14 18 17 25 19]\n",
      "Column 'cig0_r': [0 2 3 1 6 4 5 7]\n",
      "Column 'cig1_r': [0 2 6 3 1 4 5 7]\n",
      "Column 'cig2_r': [0 2 6 3 1 4 7 5]\n",
      "Column 'cig3_r': [0 2 6 3 1 4 7 5]\n",
      "Column 'f_cigs_0': ['1' 'Y' 'N' 'U' '0' '3' '2' '7' '5' '6' '4']\n",
      "Column 'f_cigs_1': ['1' 'Y' 'N' 'U' '0' '3' '2' '7' '5' '6' '4']\n",
      "Column 'f_cigs_2': ['1' 'Y' 'N' 'U' '0' '3' '2' '7' '5' '6' '4']\n",
      "Column 'f_cigs_3': ['1' 'Y' 'N' 'U' '0' '3' '2' '7' '5' '6' '4']\n",
      "Column 'cig_rec': ['N' 'Y' 'U' '0' '1' '3' '2' '7' '5' '6' '4']\n",
      "Column 'f_tobaco': [1 6 5 0 9 7 3 2 4]\n",
      "Column 'mhtr': [60 61 65 63 66 64 68 67 69 62 58 59 71 73 57 55 70 72 99 38 78 52 74 53\n",
      " 48 56 49 51 75 54  0  1 37 28  5 26 12 30 11 22 16 21  3 10 50 77 76 40\n",
      " 46]\n",
      "Column 'f_m_ht': [1 3 2 4 5 9 0 7 6]\n",
      "Column 'bmi': [ 17.8  36.8  30.1  24.8  22.5  21.   46.5  28.9  23.5  29.5  42.4  30.9\n",
      "  99.9  20.7  32.3  22.7  18.3  22.3  25.4  33.3  20.8  38.2  29.   29.4\n",
      "  35.4  25.8  32.9  31.8  23.   33.   48.5  29.2  41.8  29.8  29.3  27.5\n",
      "  18.8  17.6  31.9  30.3  35.5  31.5  27.2  24.2  35.8  36.6  32.6  25.6\n",
      "  33.6  26.6  26.3  18.6  23.3  49.5  28.3  27.6  31.7  27.3  16.6  26.5\n",
      "  25.1  19.8  21.7  35.2  29.9  24.9  48.7  19.5  29.1  25.7  24.1  20.1\n",
      "  23.9  32.8  27.   33.8  35.9  17.5  16.9  19.2  24.5  20.2  49.6  27.8\n",
      "  32.4  18.2  26.7  21.3  30.7  44.2  38.8  34.4  38.6  21.5  30.4  33.1\n",
      "  28.2  35.7  29.6  34.5  39.1  17.7  40.6  21.6  25.   42.9  43.2  28.7\n",
      "  14.5  23.2  19.   16.8  32.7  20.6  20.4  27.9  19.3  31.   23.8  31.2\n",
      "  22.9  43.3  30.2  31.6  24.   53.9  20.5  23.6  28.1  47.9  52.5  41.6\n",
      "  22.8  45.2  17.4  43.6  42.7  34.   26.   21.8  22.1  33.7  26.1  50.1\n",
      "  40.8  25.2  51.7  19.4  19.6  29.7  24.7  33.2  20.   24.6  18.9  38.3\n",
      "  27.4  24.4  38.9  24.3  41.   36.   52.8  44.9  44.6  32.   16.3  25.3\n",
      "  17.9  34.6  16.4  32.2  28.   22.   18.7  44.7  34.7  45.6  43.9  30.8\n",
      "  19.9  36.7  21.2  19.1  46.1  39.5  35.3  36.5  33.4  25.5  21.9  32.5\n",
      "  19.7  47.5  18.1  37.8  48.9  25.9  37.2  30.6  35.1  17.2  36.2  42.\n",
      "  28.8  38.1  23.4  34.8  43.4  41.4  16.1  34.2  30.   38.5  37.1  51.6\n",
      "  18.   21.4  37.4  34.9  26.9  39.9  31.3  42.3  34.3  28.5  61.5  36.1\n",
      "  32.1  38.7  31.4  54.9  30.5  26.8  20.9  51.4  43.8  26.4  37.6  27.7\n",
      "  40.   28.6  20.3  15.3  50.7  31.1  39.3  46.9  21.1  15.8  45.8  18.5\n",
      "  44.1  27.1  46.3  41.3  22.2  23.7  40.7  15.5  37.7  22.6  23.1  50.4\n",
      "  53.2  45.7  44.4  40.4  39.8  36.9  26.2  41.2  14.6  33.5  15.9  14.7\n",
      "  33.9  17.3  37.   46.   42.5  34.1  16.   46.6  58.2  38.   35.6  37.9\n",
      "  42.6  45.3  36.4  49.1  35.   39.7  61.3  39.6  40.3  56.1  36.3  45.4\n",
      "  17.1  17.   44.8  45.   52.2  18.4  37.5  28.4  40.2  47.2  44.3  22.4\n",
      "  14.9  39.   47.6  39.2  61.8  67.8  51.5  45.1  38.4  48.2  45.9  44.5\n",
      "  41.9  49.8  41.5  47.8  41.7  50.2  16.5  53.3  15.4  42.1  54.8  56.4\n",
      "  15.7  48.1  13.7  42.8  46.2  40.5  41.1  43.7  53.4  55.9  47.3  39.4\n",
      "  53.8  51.    0.    1.  374.  283.  263.  122.  303.  112.  715.  223.\n",
      " 162.  213.  555.  101.   11.  655.   50.6  56.9  54.6  42.2  37.3  43.1\n",
      "  48.6  56.3  45.5  53.   58.3  53.1  50.3  48.3  15.6  59.6  43.   49.4\n",
      "  50.8  55.3  57.7  52.9  51.1  50.   62.2  60.2  49.9  58.1  40.1  15.2\n",
      "  64.4  49.2  59.4  43.5  60.6  47.   68.5  47.1  56.6  48.8  46.8  52.4\n",
      "  49.   59.   15.1  68.   47.7  47.4  57.2  16.2  53.7  52.   55.1  59.7\n",
      "  48.4  54.   61.   49.3  55.8  52.7  44.   61.1  50.5  59.1  14.8  59.2\n",
      "  46.4  13.3  16.7  60.1  54.7  40.9  49.7  58.4 404.   54.1  55.6  13.9\n",
      "  57.6  52.3  54.5  60.7  55.2  62.6  48.   56.2  51.2  50.9  14.1  61.9\n",
      "  56.7  64.5  54.3  57.9  55.4  53.5  51.9  57.4  15.   60.9  58.7  46.7\n",
      "  58.6]\n",
      "Column 'bmi_r': [1 5 4 2 6 3 9 0 7]\n",
      "Column 'wgt_r': [ 91 195 181 140 135 130 271 190 150 200 247 180 999 128 100 118 148 141\n",
      " 183 164 188 240 170 204 185 114 169 265 236 179 160 120 210 106 194 149\n",
      " 215 202 155 105 307 145 176 227  82 119 115 199 163 136 275 117 175 158\n",
      " 103 139 162 197 110 178 102 165 143 107 166 280 157 116 208 282 248 220\n",
      " 213 219 232 125 193 235 113 156 122 250 171 198 104  98 209 109 192 259\n",
      " 112 230 268 314 129 142 279 278  92 262 241 161 228 134 147 172 187 320\n",
      " 238 217 207 144 212 124 216 154 138 153 256 123 270 337 260  89 152 167\n",
      " 127 101 203 205 132  99 229 274 289 214 263  96 126 206 331 137 245 182\n",
      " 211 223 283 184 294  88 300 159 173 121  90 201 218 111 254 244 375 133\n",
      " 108 177 340 290 186  95 324 224 273 310 174 146 168 226  97 131 252 312\n",
      " 225 151 239 242  75 234  84 255  94 246 189  83 221 330 231 350 222 233\n",
      " 264 258 357 327 304  80 196  87 243 295 306 371 286 237 308  79 191 287\n",
      " 299 276 257 269 360 298 341 272  93  86 292 296 302 251  85 267 297   0\n",
      "   1 374  51 303 715 555  31  11 655 321 370 249 301 354 253 372 369 288\n",
      " 347 348 284 277 285 316 339 293 326 315 313 333 261 309 338 365 325 319\n",
      " 328 318 311 329 323 305 345 356 266 344 317 346 281 404 335  76  78 336\n",
      " 355 353 366]\n",
      "Column 'f_pwgt': [1 2 3 9 0 4 7 5 6]\n",
      "Column 'dwgt_r': [100 195 199 168 153 164 272 215 172 249 220 999 163 238 152 110 128 160\n",
      " 212 180 222 171 188 250 196 190 214 142 173 274 224 200 217 175 127 118\n",
      " 192 203 174 139 237 230 243 189 204 166 170 202 130 165 305 150 231 125\n",
      " 156 208 178 158 154 235 141 186 146 283 216 181 185 129 198 176 207 205\n",
      " 240 126 135 124 148 169 140 122 182 281 258 286 254 228 244 134 138 197\n",
      " 247 159 132 260 280 210 113 233 400 112 193 187 162 279 155 245 226 223\n",
      " 350 137 263 108 253 229 177 276 151 360 191 183 194 206 290 157 143 147\n",
      " 292 227 343 114 161 236 120 218 213 136 107 179 241 322 184 246 311 332\n",
      " 123 167 117 211 121 144 145 358 255 264 133 318 115 242 225 270 149 252\n",
      " 259 248 119 398 282 278 364 101 111 209 109 131 232 326 257 289 221 320\n",
      " 275 268 295 262 296 265 313 368 341 271 261 201 105 302 256 335 239 338\n",
      " 327 273 346 315 297 331 116 291 266 234 103 345 287 251 219 299 267 334\n",
      " 269 312 303 304 372 325 300 285 363 306 340 284 330 102 348 310 373 328\n",
      " 294 307 106 293  40   0  26  99   9  34   5  20  11   7  23  25  36  18\n",
      "  15   3  37  21  30  24  13  12  28  16  22   2   8  35  32 374  54  70\n",
      "  10   4  51  14  50  42  38  31  29   6  17  46  44   1  33 715  45 555\n",
      " 655 316 371 324 323 319 277 298 349 317 308 301 333 321 356 352 362 329\n",
      " 378 357 309 104 288 392 336 314 375 361 355 384 342 337 386 367 396 351\n",
      " 354 390 359 370  27  98  19  49 404  87  48 379 339 380 395 387 383 365\n",
      " 377 388 369]\n",
      "Column 'f_dwgt': [1 5 4 0 2 3 6 9 7 8]\n",
      "Column 'wtgain': [ 8  0 18 28 34  1 25 22 15  2 40 99 23 38 24 10 12 39  7 20 35  4  9 54\n",
      " 14 21 57 19 30 53 60 49 11  5 27 16 48 33 26 36 61 13  3 43 29 50  6 31\n",
      " 17 44 63 37 55 41 58 46 98 69 32 51 62 52 65 70 74 42 45 59 56 93 47 83\n",
      " 89 64 73 76 67 68 79 80 85 82 75 78 84 66 71 77 81 96 87 88 90 86 95 94\n",
      " 72 91 97 92]\n",
      "Column 'wtgain_rec': [1 2 3 4 9 5]\n",
      "Column 'f_wtgain': ['1' 'N' 'Y' '0' 'U']\n",
      "Column 'rf_pdiab': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'rf_gdiab': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'rf_phype': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'rf_ghype': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'rf_ehype': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'rf_ppb': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'f_rf_pdiab': ['1' 'N' 'Y' '0' 'U']\n",
      "Column 'f_rf_gdiab': ['1' 'N' 'Y' '0' 'U']\n",
      "Column 'f_rf_phype': ['1' 'N' 'Y' '0' 'U']\n",
      "Column 'f_rf_ghype': ['1' 'N' 'Y' '0' 'U']\n",
      "Column 'f_rf_ehype': ['1' 'N' '0' 'Y' 'U']\n",
      "Column 'f_rf_ppb': ['1' 'N' 'Y' '0' 'U']\n",
      "Column 'rf_inft': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'rf_drg': ['X' 'Y' 'U' 'N' '0' '1']\n",
      "Column 'rf_art': ['X' 'N' 'U' 'Y' '0' '1']\n",
      "Column 'f_rf_drg': ['1' 'N' '0' 'Y' 'U']\n",
      "Column 'f_rf_art': ['1' 'N' '0' 'Y' 'U']\n",
      "Column 'rf_cesar': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'rf_cesarn': [ 0  1  2  4  3  5 99 11  7  6]\n",
      "Column 'f_rf_cesar': [1 0 9]\n",
      "Column 'f_rf_ncesar': [1 0 9]\n",
      "Column 'no_risks': [1 0 9]\n",
      "Column 'ip_gon': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ip_syph': ['N' 'U' 'Y' '0' '1']\n",
      "Column 'ip_chlam': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ip_hepb': ['N' 'U' 'Y' '0' '1']\n",
      "Column 'ip_hepc': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'f_ip_gon': [1 0 9]\n",
      "Column 'f_ip_syph': [1 0 9]\n",
      "Column 'f_ip_chlam': [1 0 9]\n",
      "Column 'f_ip_hepb': [1 0 9]\n",
      "Column 'f_ip_hepc': [1 0 9]\n",
      "Column 'no_infec': [1 0 9]\n",
      "Column 'ob_succ': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ob_fail': ['N' 'U' 'Y' '0' '1']\n",
      "Column 'f_ob_succ': [1 0]\n",
      "Column 'f_ob_fail': [1 0]\n",
      "Column 'seqnum_co': [    1     2     3 ... 23355 23356 23357]\n",
      "Column 'ld_indl': ['N' 'Y' '0' '1' 'U']\n",
      "Column 'ld_augm': ['N' 'Y' '0' '1' 'U']\n",
      "Column 'ld_ster': ['N' 'Y' '0' '1' 'U']\n",
      "Column 'ld_antb': ['Y' 'N' '0' '1' 'U']\n",
      "Column 'ld_chor': ['Y' 'N' '0' '1' 'U']\n",
      "Column 'ld_anes': ['Y' 'N' '0' '1' 'U']\n",
      "Column 'f_ld_indl': [1 0 9]\n",
      "Column 'f_ld_augm': [1 0 9]\n",
      "Column 'f_ld_ster': [1 0 9]\n",
      "Column 'f_ld_antb': [1 0 9]\n",
      "Column 'f_ld_chor': [1 0 9]\n",
      "Column 'f_ld_anes': [1 0 9]\n",
      "Column 'no_lbrdlv': [0 1 9]\n",
      "Column 'me_pres': [1 2 9 3 0]\n",
      "Column 'me_rout': [1 4 3 2 0 9]\n",
      "Column 'me_trial': ['X' 'N' 'Y' 'U' '0' '1' '2']\n",
      "Column 'f_me_pres': [1 3 4 0 2 6 9 5]\n",
      "Column 'f_me_rout': [1 3 4 0 2 6 9 5]\n",
      "Column 'f_me_trial': [1 3 4 0 2 6 9 5]\n",
      "Column 'rdmeth_rec': [1 4 3 2 5 9 6]\n",
      "Column 'dmeth_rec': [1 2 9]\n",
      "Column 'f_dmeth_rec': ['1' 'N' '0' 'Y' 'U']\n",
      "Column 'mm_mtr': ['N' 'Y' '0' '1' 'U']\n",
      "Column 'mm_plac': ['N' 'Y' '0' '1' 'U']\n",
      "Column 'mm_rupt': ['N' 'Y' '0' '1' 'U']\n",
      "Column 'mm_uhyst': ['N' 'Y' '0' '1' 'U']\n",
      "Column 'mm_aicu': ['N' 'Y' '0' '1' 'U']\n",
      "Column 'f_mm_mtr': [1 0 9]\n",
      "Column 'f_mm_': [1 0 9]\n",
      "Column 'f_mm_rupt': [1 0 9]\n",
      "Column 'f_mm_uhyst': [1 0 9]\n",
      "Column 'f_mm_aicu': [1 0 9]\n",
      "Column 'no_mmorb': [1 0 9]\n",
      "Column 'attend': [1 2 3 5 4 9]\n",
      "Column 'mtran': ['N' 'Y' '0' '1' 'U']\n",
      "Column 'ay': [1 2 3 8 5 6 4 9 0]\n",
      "Column 'ay_rec': [1 2 3 4 9 0]\n",
      "Column 'f_pay': [1 0 9]\n",
      "Column 'f_pay_rec': [1 0 9]\n",
      "Column 'apgar5': [ 8  9  2 10  1  7  6 99  3  4  0  5]\n",
      "Column 'apgar5r': [3 4 1 2 5]\n",
      "Column 'f_apgar5': [1 8 0 9]\n",
      "Column 'apgar10': [88  0  2  1  5 99  3  6  8  4  7 10  9]\n",
      "Column 'apgar10r': [5 1 2 3 4]\n",
      "Column 'dplural': [1 2 3 4 5]\n",
      "Column 'imp_plur': ['9' '1' '2' '3' '4' 'M' 'F' '5']\n",
      "Column 'setorder_r': ['9' '1' '2' '3' '4' 'M' 'F' '5']\n",
      "Column 'sex': ['M' 'F']\n",
      "Column 'imp_sex': [0 9 1]\n",
      "Column 'dlmp_mm': [ 5  4 99  8  7  6  9  3 10 11 12  1  2]\n",
      "Column 'dlmp_yy': [2014 9999 2015 2013]\n",
      "Column 'combgst_imp': [1 0 2 3 4 9]\n",
      "Column 'obgest_flg': [3 1 2 4 9]\n",
      "Column 'combgest': [31 35 39 22 36 20 24 32 40 28 41 38 25 21 26 30 29 23 45 34 42 37 18 27\n",
      " 19 44 99 33 43 17 46 47]\n",
      "Column 'estrec10': [ 3  5  7  2  4  8  9  6 10  1 99]\n",
      "Column 'estrec3': [1 2 3]\n",
      "Column 'lmpused': [3 2 1 4 9]\n",
      "Column 'oegest_comb': [31 36 39 22 21 23 35 34 20 29 37 38 24 28 26 33 25 27 18 19 17 32 40 99\n",
      " 41 30 42 43 44 46]\n",
      "Column 'oegest_r10': [ 3  5  7  2  6  4  1  8 99  9 10]\n",
      "Column 'oegest_r3': [1 2 3]\n",
      "Column 'bwtr14': [ 6  9  7  8  2  1  5  4  3 10 11 14 12 13]\n",
      "Column 'bwtr4': [2 3 1 4]\n",
      "Column 'brthwgt': [1559 3288 2438 ... 1331 4260  789]\n",
      "Column 'bwtimp': ['Y' 'N' '1' 'U' '0']\n",
      "Column 'ab_aven1': ['Y' 'N' 'U' '0' '1']\n",
      "Column 'ab_aven6': ['Y' 'N' 'U' '0' '1']\n",
      "Column 'ab_nicu': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ab_surf': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ab_anti': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ab_seiz': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'f_ab_aven1': [1 0 9]\n",
      "Column 'f_ab_aven6': [1 0 9]\n",
      "Column 'f_ab_nicu': [1 0 9]\n",
      "Column 'f_ab_surf': [1 0 9]\n",
      "Column 'f_ab_anti': [1 0 9]\n",
      "Column 'f_ab_seiz': [1 0 9]\n",
      "Column 'no_abnorm': [0 1 9]\n",
      "Column 'ca_anen': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ca_mnsb': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ca_cchd': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ca_cdh': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ca_omph': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ca_gast': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'f_ca_anen': ['1' 'N' '0' 'U' 'Y']\n",
      "Column 'f_ca_mnsb': ['1' 'N' '0' 'U' 'Y']\n",
      "Column 'f_ca_cchd': ['1' 'N' '0' 'U' 'Y']\n",
      "Column 'f_ca_cdh': ['1' 'N' '0' 'U' 'Y']\n",
      "Column 'f_ca_omph': ['1' 'N' '0' 'U' 'Y']\n",
      "Column 'f_ca_gast': ['1' 'N' '0' 'U' 'Y']\n",
      "Column 'ca_limb': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ca_cleft': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ca_clpal': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'ca_down': ['N' 'P' 'C' 'U' '0' '1']\n",
      "Column 'ca_disor': ['N' 'P' 'C' 'U' '0' '1']\n",
      "Column 'ca_hypo': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'f_ca_limb': [1 0 9]\n",
      "Column 'f_ca_cleft': [1 0 9]\n",
      "Column 'f_ca_clpal': [1 0 9]\n",
      "Column 'f_ca_down': [1 0 9]\n",
      "Column 'f_ca_disor': [1 0 9]\n",
      "Column 'f_ca_hypo': [1 0 9]\n",
      "Column 'no_congen': [1 0 9]\n",
      "Column 'itran': ['Y' 'N' 'U' '0' '1']\n",
      "Column 'ilive': ['Y' 'N' 'U' '0' '1']\n",
      "Column 'bfed': ['N' 'Y' 'U' '0' '1']\n",
      "Column 'f_bfed': [1 0 2 4 5]\n",
      "Column 'ubfacil': [1 4 3 2 5 9]\n",
      "Column 'urf_diab': [2 1 9]\n",
      "Column 'urf_chype': [2 1 9]\n",
      "Column 'urf_phype': [2 1 9]\n",
      "Column 'urf_ehype': [2 1 9]\n",
      "Column 'ume_forc': [2 1 9]\n",
      "Column 'ume_vacu': [2 1 9]\n",
      "Column 'uob_indu': [2 1 9]\n",
      "Column 'uld_bree': [2 1 9]\n",
      "Column 'uca_anen': [2 1 9]\n",
      "Column 'uca_spina': [2 1 9]\n",
      "Column 'uca_omph': [2 1 9]\n",
      "Column 'uca_clip': [2 1 9]\n",
      "Column 'uca_hern': [2 1 9]\n",
      "Column 'uca_down': [2 1 9]\n",
      "Column 'flgnd': [1]\n",
      "Column 'aged': [  4  93   0 141  35  59  41  44   6  65   1   2  26  33  20  85  73  56\n",
      "   5  61   3 120 154 143  71 156 147   7  29 150  63 222 145 351  47 336\n",
      "   9 127  60  78 201  19 100 140   8  45  13 261 119 114  14  87  89  40\n",
      "  16  11  57  77  30 142  96 139  23  24 192  69  94  38 132  36  31 364\n",
      " 134 200 199  70 121 179  21  83 161  58 129  37 313 111 153  27 342  18\n",
      " 187  80  32 210  42  92 173 216  22  12  53 357 239  39 122 159 259 130\n",
      "  55  28 157  62  10 219 240  72 137 264  25 217 245 165 136 257 361 331\n",
      "  48 180  15 103 294 112  17  95 224 191 234 209 135 176 281 151 144  67\n",
      " 117 345 101 182  34  74 170 102 109  88 146 115  46  76 164  91  66 256\n",
      " 343  43 293 307 255 125  86 107  75 126  64 215 230 118 193 211 274 110\n",
      " 198  97 233 108 123 185 287  49 138 225  99 167 190  79 175  50 303 260\n",
      " 227  84 251 223  90 162 317 283 184 105  51 160 266  54 267 306 171 158\n",
      " 330 104 113 172 296 214 275 291 253 218 246 178 221 116 286 177 181  98\n",
      " 252 226 319 270 189 237 195 324  52 133 174 229 206  68 236 254 228 183\n",
      " 196 212 124 355 106 128 353 238 312 213 232 277 304 149 356 301 314 205\n",
      " 262 168 208 186 197 333 272 332 298 231 188 202 155 131 347 289  82 207\n",
      " 220 204 338 285 203 279 263 302 166 300 152 299 269 271 315 278 273 325\n",
      " 354 290 349  81 242 163 346 309 276 358 148 284 311 244 305 250 268 248\n",
      " 335 247 363 350 318 327 320 295 326 360 308 194 341 288 321 359 249 243\n",
      " 258 297 337 169 265 339 235 329 362 316 334 344 340 322 348 292 352 282\n",
      " 280 323 310 328 241]\n",
      "Column 'ager5': [3 5 1 2 4]\n",
      "Column 'ager22': [ 6 14  1 15  2 12  8 13  3  4 11 10  7  5 16  9 18 22 17 19 21 20]\n",
      "Column 'manner': ['7' '5' 'U' '4' '1' '3' 'B' 'C' 'D' 'O' 'R' 'E']\n",
      "Column 'dispo': ['U' 'B' 'C' 'R' 'E' 'D' 'O']\n",
      "Column 'autopsy': ['N' 'Y' 'U']\n",
      "Column 'lace': ['P' 'Q' 'R' 'A' 'I' 'J' '0' 'D' 'V' '9' 'E' 'B' 'N' 'C' '8' 'K' 'G' '5'\n",
      " 'Y' 'M' 'H' '2' 'L' '1' '4' 'F']\n",
      "Column 'ucod': ['P369' 'Q249' 'Q602' 'R95' 'P280' 'Q213' 'P039' 'A090' 'R99' 'I678'\n",
      " 'Q897' 'P072' 'Q913' 'J189' 'P549' 'P239' 'P018' 'Q789' 'W75' 'P011'\n",
      " 'P522' 'D689' 'P293' 'Q245' 'A419' 'P220' 'J849' 'P77' 'J984' 'P021'\n",
      " 'J690' 'Q000' 'P070' 'P271' 'P364' 'V892' 'P251' 'P010' 'P523' 'J840'\n",
      " 'P269' 'Q893' 'Q042' 'Q614' 'P548' 'P209' 'P298' 'P291' 'Q336' 'Q043'\n",
      " 'P543' 'P368' 'P073' 'P219' 'Q917' 'A391' 'P240' 'I272' 'P780' 'J80'\n",
      " 'E872' 'Q211' 'P916' 'Q613' 'D899' 'Q771' 'Q248' 'Q212' 'B99' 'Q606'\n",
      " 'P026' 'V874' 'P969' 'D761' 'E875' 'R092' 'R579' 'Y09' 'P362' 'Q790'\n",
      " 'I469' 'P290' 'N19' 'A099' 'C919' 'P614' 'P352' 'P013' 'P529' 'I615'\n",
      " 'Q318' 'D849' 'X30' 'Q878' 'P059' 'Q899' 'P960' 'P159' 'V877' 'C349'\n",
      " 'Q283' 'P234' 'P015' 'A415' 'K550' 'Q601' 'J129' 'P832' 'P288' 'Q234'\n",
      " 'P005' 'P398' 'Q279' 'J961' 'E889' 'J14' 'Q798' 'Q927' 'G934' 'E46'\n",
      " 'I498' 'I514' 'E713' 'P038' 'Q799' 'G709' 'I279' 'Q431' 'P027' 'B348'\n",
      " 'Q688' 'Q870' 'P236' 'Y34' 'C959' 'Q230' 'Q909' 'I456' 'I64' 'D682' 'Y20'\n",
      " 'Q792' 'Q774' 'Q929' 'P008' 'A022' 'K631' 'G931' 'Q898' 'P012' 'Q02'\n",
      " 'P001' 'Q039' 'Y21' 'Q642' 'P020' 'P912' 'G938' 'Q049' 'P521' 'P360'\n",
      " 'I429' 'Q204' 'P002' 'I515' 'G529' 'Y11' 'W79' 'B49' 'Q935' 'P378' 'G129'\n",
      " 'P292' 'A401' 'P375' 'Q638' 'P241' 'Q203' 'P023' 'Q251' 'J101' 'W74'\n",
      " 'B342' 'Q201' 'P941' 'I370' 'Q321' 'J980' 'Q210' 'J120' 'P022' 'K449'\n",
      " 'J180' 'Q605' 'P60' 'A379' 'A081' 'Q795' 'Q054' 'Q611' 'P253' 'Q282'\n",
      " 'Q330' 'G009' 'A402' 'C629' 'Q894' 'J40' 'I119' 'P229' 'P968' 'Q246'\n",
      " 'P279' 'Q780' 'Q257' 'K566' 'J219' 'K766' 'P071' 'Q262' 'K403' 'E848'\n",
      " 'K659' 'W84' 'I898' 'G419' 'E722' 'Q619' 'Q250' 'Q256' 'Q231' 'I209'\n",
      " 'G002' 'P524' 'W78' 'Q339' 'Y079' 'P358' 'Q772' 'I871' 'P035' 'P942'\n",
      " 'Q255' 'Q225' 'C64' 'J069' 'J869' 'P90' 'G712' 'I422' 'P017' 'Q433'\n",
      " 'Q999' 'Q019' 'P250' 'Q438' 'Q324' 'Q743' 'P000' 'Q872' 'E880' 'P016'\n",
      " 'Q678' 'Q200' 'P024' 'Q793' 'P285' 'I499' 'C719' 'E725' 'D376' 'P612'\n",
      " 'Q258' 'K768' 'G039' 'N12' 'G008' 'Q639' 'Q892' 'I517' 'P049' 'A490'\n",
      " 'I619' 'I620' 'Q858' 'N189' 'P033' 'W83' 'W65' 'Q059' 'G319' 'J860' 'X92'\n",
      " 'P392' 'M726' 'I788' 'I609' 'K729' 'Q928' 'E752' 'P284' 'Q038' 'Q871'\n",
      " 'X85' 'Q349' 'Q048' 'P232' 'Q933' 'G003' 'B349' 'K638' 'Q458' 'D720'\n",
      " 'Q333' 'W67' 'Q444' 'X00' 'Y26' 'Q268' 'D582' 'Q442' 'I120' 'I319' 'H669'\n",
      " 'Q254' 'J152' 'J386' 'P399' 'I518' 'Q998' 'W80' 'I629' 'K904' 'Q228'\n",
      " 'D432' 'W19' 'K358' 'R278' 'P528' 'P504' 'V090' 'Q809' 'A410' 'J982'\n",
      " 'J42' 'I420' 'Q412' 'P044' 'I823' 'X47' 'I424' 'G049' 'Q182' 'G318'\n",
      " 'D748' 'G629' 'V446' 'Q232' 'K668' 'Q379' 'D70' 'Q447' 'P361' 'Q764'\n",
      " 'P031' 'D821' 'Q220' 'Q224' 'V031' 'C749' 'Q263' 'Q392' 'Q320' 'W69'\n",
      " 'I428' 'J181' 'Q223' 'P833' 'J988' 'J371' 'D589' 'V486' 'A329' 'D471'\n",
      " 'K562' 'Q018' 'P289' 'G952' 'P028' 'P351' 'J128' 'P249' 'N898' 'B009'\n",
      " 'N179' 'Q939' 'Q056' 'B259' 'P158' 'W04' 'D151' 'J850' 'W06' 'Q874'\n",
      " 'P526' 'J969' 'Q273' 'E711' 'E871' 'J930' 'Q970' 'V489' 'D560' 'E724'\n",
      " 'Q969' 'K070' 'Q794' 'Q030' 'Q079' 'J209' 'V819' 'P914' 'P034' 'C80'\n",
      " 'J398' 'Q031' 'E86' 'Q410' 'D685' 'X44' 'N343' 'P112' 'I890' 'P910'\n",
      " 'D693' 'N139' 'P036' 'Q240' 'Q648' 'K219' 'J210' 'I709' 'D820' 'P964'\n",
      " 'P210' 'I442' 'J22' 'Q242' 'P509' 'W76' 'E561' 'I409' 'Q229' 'X599'\n",
      " 'P006' 'A493' 'P042' 'G98' 'K902' 'I10' 'Y839' 'P702' 'P003' 'N289'\n",
      " 'D489' 'J00' 'P230' 'Y848' 'P030' 'N390' 'K661' 'E149' 'J218' 'X91'\n",
      " 'E831' 'A498' 'B340' 'X95' 'R090' 'Y069' 'D649' 'J981' 'Q759' 'G409'\n",
      " 'Q159' 'Q040' 'P051' 'P041' 'Q643' 'A499' 'J154' 'L022' 'G937' 'P783'\n",
      " 'J960' 'I519' 'Q012' 'P592' 'B201' 'G711' 'Q226' 'I421' 'G729' 'V030'\n",
      " 'J121' 'D181' 'V436' 'Q046' 'I458' 'P261' 'Q604' 'I400' 'E877' 'K318'\n",
      " 'Y08' 'Q315' 'J13' 'Q819' 'D610' 'I219' 'Q934' 'Y14' 'K559' 'Q620' 'G919'\n",
      " 'G111' 'E343' 'Q390' 'E348' 'C925' 'Q219' 'Q221' 'D65' 'E232' 'Q400'\n",
      " 'E161' 'Q915' 'K565' 'W20' 'A084' 'Y04' 'I471' 'D487' 'C910' 'Q549' 'Y33'\n",
      " 'P965' 'A080' 'D480' 'J841' 'Y00' 'E250' 'G908' 'M303' 'I313' 'P769'\n",
      " 'Q649' 'K561' 'R568' 'J90' 'R739' 'Q808' 'C920' 'C716' 'I509' 'P701'\n",
      " 'P082' 'I251' 'Q264' 'G120' 'A879' 'E878' 'E770' 'K740' 'I99' 'G128'\n",
      " 'Q623' 'Y071' 'I639' 'Y12' 'W31' 'J939' 'G911' 'Q348' 'Y833' 'M622'\n",
      " 'E744' 'B378' 'Q423' 'B399' 'I270' 'J450' 'B332' 'Y061' 'M841' 'I288'\n",
      " 'P809' 'G918' 'K859' 'G809' 'P019' 'D591' 'A403' 'G404' 'K769' 'Q938'\n",
      " 'V439' 'Q288' 'Q891' 'P393' 'P560' 'G060' 'W73' 'N049' 'R402' 'Y430'\n",
      " 'A509' 'J041' 'R048' 'C951' 'J155' 'Y836' 'I822' 'Y832' 'D759' 'P009'\n",
      " 'A86' 'J100' 'J81' 'D806' 'V476' 'P025' 'Q564' 'K37' 'X97' 'M246' 'R068'\n",
      " 'J111' 'P501' 'D410' 'I269' 'M889' 'I249' 'P550' 'V092' 'P613' 'I501'\n",
      " 'Q439' 'P394' 'I425' 'P610' 'P788' 'A370' 'Q932' 'B379' 'Y078' 'E870'\n",
      " 'I741' 'Q645' 'X09' 'K720' 'R98' 'G122' 'N258' 'G936' 'C717' 'I513'\n",
      " 'Q411' 'A409' 'Q778' 'E230' 'P53' 'J158' 'A491' 'I461' 'Q070' 'R11'\n",
      " 'B449' 'D580' 'V499' 'N320' 'A021' 'K761' 'Q600' 'Q959' 'Q873' 'C929'\n",
      " 'Q239' 'E874' 'P029' 'J09' 'K228' 'G001' 'D696' 'Q402' 'Q391' 'R629'\n",
      " 'E849' 'P359' 'P599' 'Q668' 'P559' 'P961' 'J208' 'I472' 'I059' 'B007'\n",
      " 'D619' 'E742' 'J151' 'P545' 'E740' 'K567' 'K598' 'P120' 'A051' 'I749'\n",
      " 'A870' 'B377' 'Q631' 'W22' 'I490' 'I633' 'Y605' 'X94' 'Q338' 'Q430'\n",
      " 'K255' 'Q829' 'D819' 'E782' 'L299' 'K529' 'C222' 'D758' 'P150' 'Q206'\n",
      " 'Y01' 'N288' 'K746' 'P700' 'Y03' 'P283' 'X99' 'D694' 'Q773' 'K402' 'I500'\n",
      " 'R298' 'J122' 'Q791' 'I710' 'P525' 'P363' 'Q758' 'E778' 'J459' 'J989'\n",
      " 'K767' 'C499' 'R628' 'Q978' 'R02' 'A599' 'R18' 'B258' 'A412' 'Q740'\n",
      " 'E830' 'M318' 'P918' 'G042' 'I773' 'K223' 'P372' 'X41' 'J851' 'B179'\n",
      " 'K741' 'K922' 'P781' 'K593' 'J150' 'M629' 'C762' 'P043' 'E723' 'E274'\n",
      " 'E320' 'Q233' 'Q776' 'A047' 'W44' 'I899' 'K404' 'Q931' 'X590' 'J387'\n",
      " 'Q280' 'P252' 'G961' 'J159' 'Q332' 'P611' 'E785' 'P38' 'J449' 'J156'\n",
      " 'J399' 'W54' 'Q044' 'Q559' 'E876' 'D760' 'I829' 'Q060' 'X42' 'B341'\n",
      " 'G473' 'V890' 'M319' 'J439' 'Q513' 'R570' 'R784' 'J050' 'G403' 'V887'\n",
      " 'Q222' 'D573' 'E840' 'Q621' 'V536' 'Q675' 'B250' 'Q911' 'G628' 'I679'\n",
      " 'G935' 'Q310' 'G939' 'E803' 'X37' 'K221' 'C229' 'N10' 'Q777' 'G121'\n",
      " 'R788' 'K296' 'I740' 'K759' 'V496' 'Q782' 'M009' 'J029' 'R609' 'D180'\n",
      " 'K929' 'G710' 'P579' 'D469' 'F069' 'C950' 'B206' 'P929' 'P243' 'P139'\n",
      " 'E550' 'L988' 'J110' 'R688' 'Y05' 'I739' 'J040' 'D572' 'I258' 'E835'\n",
      " 'I779']\n",
      "Column 'ucodr130': [106 123 127 135 103  84   3 136  51 132  89 130  57 110  98  78 128 146\n",
      "  76  31 117   9  96  62 115  80  61 119 102 141 100  75 101 122  94 125\n",
      "  90  95 131   8  99  47  37  32  22  81 156  50  68  26 113 108 151  87\n",
      "  92  27 124  77  64 116 104  73  38 133  44  35  52 126  82  18 158 129\n",
      "   2  66  43 120  49 148  56 145  65   7 121  40  59  58  36 147 155  54\n",
      "  72  28  69  85 137 149  30  45 143 150  83 142  48 157 114 153 154 112\n",
      "  16  34  91  41  19  60  42  10 111 107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'recwt': [1.       1.004292 1.00565  1.017857 1.024135 1.010169 1.008361 1.007874\n",
      " 1.003945 1.019544 1.024096 1.025    1.02439  1.005102 1.0033   1.011236\n",
      " 1.036    1.017751 1.002132 1.005338 1.00885  1.005736 1.010753 1.003891\n",
      " 1.03518  1.002532 1.017241 1.012346 1.017544]\n",
      "Column 'eanum': [ 4  3  1  2  5  6  9  7  8 10 12 11 13 14]\n",
      "Column 'econdp_1': [1 2 6 3 4]\n",
      "Column 'econds_1': [1]\n",
      "Column 'enicon_1': ['P290' 'I469' 'Q602' 'R95' 'P285' 'P072' 'A090' 'R99' 'I678' 'Q897'\n",
      " 'P219' 'J189' 'P523' 'P220' 'P239' 'P018' 'Q789' 'T71' 'P522' 'R090'\n",
      " 'P269' 'I429' 'A419' 'J849' 'Q249' 'P77' 'I272' 'P073' 'J690' 'Q000'\n",
      " 'I509' 'P364' 'T07' 'R688' 'P251' 'I959' 'P209' 'J840' 'Q042' 'P369'\n",
      " 'E875' 'P280' 'P291' 'R278' 'R092' 'P543' 'P368' 'Q917' 'A391' 'Q043'\n",
      " 'P293' 'P780' 'R001' 'I519' 'Q336' 'J969' 'Q211' 'Q913' 'P916' 'Q771'\n",
      " 'Q248' 'B99' 'Q899' 'P026' 'D761' 'P968' 'Q049' 'T179' 'I288' 'P352'\n",
      " 'I629' 'S069' 'G002' 'A415' 'I279' 'D849' 'T670' 'P960' 'P614' 'C793'\n",
      " 'P234' 'P288' 'A499' 'N19' 'J984' 'J129' 'P832' 'P60' 'Q234' 'P005'\n",
      " 'P398' 'J961' 'T149' 'P284' 'J14' 'Q798' 'Q999' 'P011' 'E46' 'K550'\n",
      " 'Q790' 'P292' 'P229' 'Q799' 'G709' 'P362' 'J156' 'Q059' 'Q870' 'P236'\n",
      " 'C959' 'G934' 'J154' 'S099' 'Q774' 'Q929' 'P210' 'A029' 'K659' 'G931'\n",
      " 'R570' 'Q639' 'Q02' 'T818' 'T751' 'N185' 'Q878' 'G938' 'I500' 'I515'\n",
      " 'T436' 'K297' 'B49' 'P524' 'Q039' 'P378' 'P298' 'Q601' 'R579' 'P548'\n",
      " 'Q638' 'P023' 'J101' 'B342' 'E86' 'I518' 'J980' 'J180' 'P360' 'A099'\n",
      " 'K729' 'A379' 'P021' 'Q330' 'G009' 'J960' 'C629' 'P010' 'J40' 'P969'\n",
      " 'P549' 'P279' 'I829' 'K566' 'T099' 'J219' 'Q262' 'J181' 'E849' 'J81'\n",
      " 'P012' 'S065' 'K559' 'P271' 'Q613' 'G419' 'I499' 'Q606' 'I514' 'I620'\n",
      " 'E872' 'I219' 'J939' 'G129' 'G409' 'Q203' 'Q245' 'G936' 'P529' 'R571'\n",
      " 'Q927' 'P250' 'I269' 'P035' 'K449' 'R068' 'P741' 'Q019' 'J80' 'Q743'\n",
      " 'G318' 'N179' 'G935' 'R578' 'G039' 'Q892' 'R098' 'P049' 'P059' 'I619'\n",
      " 'P027' 'N189' 'N328' 'I319' 'I788' 'K631' 'I442' 'Q038' 'D689' 'J930'\n",
      " 'B349' 'Q333' 'Q898' 'K913' 'T598' 'T210' 'G932' 'P253' 'I422' 'E889'\n",
      " 'Q228' 'G049' 'S061' 'Q792' 'K358' 'S079' 'I749' 'A410' 'J386' 'I420'\n",
      " 'T599' 'I498' 'Q213' 'I424' 'Q419' 'P504' 'D748' 'R568' 'P109' 'Q894'\n",
      " 'K562' 'Q780' 'Q232' 'I501' 'K668' 'P942' 'K767' 'P232' 'G473' 'R064'\n",
      " 'P112' 'D821' 'P022' 'Q263' 'B348' 'J398' 'J159' 'Q282' 'P249' 'Q998'\n",
      " 'P289' 'P351' 'Q230' 'J128' 'P070' 'R509' 'P158' 'Q611' 'R628' 'J850'\n",
      " 'Q928' 'J988' 'G008' 'D560' 'E724' 'Q251' 'Q079' 'T405' 'P039' 'P914'\n",
      " 'C80' 'J989' 'T462' 'R048' 'T450' 'N139' 'Q240' 'K219' 'J210' 'P261'\n",
      " 'P910' 'J150' 'J942' 'E561' 'J041' 'P006' 'A493' 'C780' 'G98' 'Q256'\n",
      " 'E871' 'P000' 'P399' 'P038' 'P015' 'I10' 'P013' 'N049' 'J950' 'Q200'\n",
      " 'J958' 'T828' 'N390' 'Q255' 'B009' 'E713' 'D432' 'T019' 'S019' 'I510'\n",
      " 'S368' 'Q212' 'J981' 'G919' 'Q909' 'P002' 'P024' 'E161' 'R560' 'G937'\n",
      " 'P008' 'Q321' 'Q935' 'Q438' 'A401' 'Q012' 'B24' 'D181' 'S020' 'I458'\n",
      " 'G918' 'S318' 'J120' 'J209' 'I400' 'Q987' 'E877' 'Q315' 'J13' 'Q819'\n",
      " 'K070' 'A491' 'L988' 'P030' 'P964' 'Q390' 'T509' 'Q225' 'Q620' 'Q031'\n",
      " 'Q046' 'L88' 'J42' 'M628' 'A403' 'Q201' 'E348' 'P361' 'C919' 'K661'\n",
      " 'Q605' 'P020' 'A084' 'T749' 'I471' 'Q874' 'E752' 'I409' 'J069' 'R18'\n",
      " 'Q318' 'T503' 'I639' 'D480' 'J841' 'J00' 'M303' 'R060' 'P528' 'Q614'\n",
      " 'D487' 'P159' 'I461' 'Q254' 'C920' 'C716' 'Q400' 'I64' 'Q893' 'P240'\n",
      " 'P082' 'P299' 'A490' 'T811' 'Q273' 'Q764' 'I615' 'G120' 'A879' 'E790'\n",
      " 'P769' 'K740' 'T730' 'G128' 'Q793' 'Q643' 'P363' 'K318' 'E722' 'R298'\n",
      " 'T406' 'P230' 'G911' 'Q348' 'Q433' 'E744' 'I609' 'J051' 'T812' 'B399'\n",
      " 'I270' 'B332' 'S068' 'G048' 'K859' 'G809' 'E343' 'Q283' 'G939' 'K769'\n",
      " 'I99' 'T810' 'P393' 'T858' 'Q279' 'G060' 'T887' 'P375' 'P044' 'C951'\n",
      " 'P783' 'G978' 'I517' 'Q257' 'A86' 'Q871' 'S090' 'D806' 'G712' 'S029'\n",
      " 'E878' 'P90' 'D65' 'T300' 'J111' 'P294' 'I491' 'D410' 'Q220' 'M889'\n",
      " 'I249' 'P550' 'P912' 'Q210' 'K922' 'P702' 'T741' 'P788' 'A370' 'B340'\n",
      " 'J152' 'I741' 'C749' 'S212' 'R98' 'Q938' 'N258' 'R900' 'Q749' 'C717'\n",
      " 'Q411' 'G729' 'J153' 'A409' 'N289' 'S399' 'P781' 'Q794' 'A402' 'B449'\n",
      " 'Q048' 'N320' 'R198' 'S129' 'Q772' 'R008' 'S297' 'K529' 'R470' 'Q204'\n",
      " 'K650' 'B377' 'T141' 'E874' 'P029' 'T68' 'S219' 'G001' 'D696' 'K720'\n",
      " 'S066' 'B259' 'T403' 'G404' 'E740' 'S299' 'K088' 'K561' 'Q619' 'E149'\n",
      " 'P019' 'Q795' 'J151' 'K255' 'Q829' 'E782' 'C222' 'P359' 'P025' 'J208'\n",
      " 'Q392' 'P700' 'P283' 'T091' 'Y09' 'T819' 'D582' 'Q773' 'E725' 'Q339'\n",
      " 'M622' 'E831' 'Q688' 'I513' 'T426' 'P525' 'Q758' 'T862' 'E870' 'J459'\n",
      " 'T814' 'S273' 'Q221' 'T796' 'C499' 'P365' 'R02' 'B258' 'R58' 'Q338'\n",
      " 'A412' 'J218' 'L989' 'M318' 'T58' 'P918' 'P241' 'G042' 'T860' 'I259'\n",
      " 'Q872' 'K768' 'K741' 'C925' 'E778' 'R11' 'C762' 'K223' 'E830' 'E723'\n",
      " 'T317' 'S131' 'P281' 'D489' 'Q776' 'S250' 'T829' 'Q264' 'I490' 'I472'\n",
      " 'J22' 'D758' 'I899' 'J387' 'P200' 'A492' 'T404' 'P003' 'I773' 'I898'\n",
      " 'E785' 'K639' 'J449' 'P509' 'Q239' 'Q439' 'K929' 'J121' 'J399' 'R233'\n",
      " 'Q559' 'D760' 'G711' 'I425' 'B341' 'D151' 'M319' 'E742' 'A411' 'Q513'\n",
      " 'R784' 'J050' 'I709' 'S062' 'Q811' 'D739' 'Q678' 'T983' 'T817' 'B250'\n",
      " 'Q911' 'P961' 'C719' 'Q349' 'J982' 'A498' 'Q044' 'Q231' 'Q233' 'T465'\n",
      " 'I313' 'S268' 'E803' 'K221' 'N10' 'P031' 'M726' 'G121' 'Q224' 'K831'\n",
      " 'I459' 'G710' 'P579' 'C950' 'B59' 'A047' 'G003' 'S097' 'P243' 'Q759'\n",
      " 'E550' 'J110' 'Q310' 'T802' 'J040' 'G319' 'D572' 'I258' 'I248' 'S269'\n",
      " 'P701']\n",
      "Column 'econdp_2': [1 2 0 6 3 4 5]\n",
      "Column 'econds_2': [2 1 0]\n",
      "Column 'enicon_2': ['P285' 'Q249' '01Q6' 'B349' 'P072' 'Q213' 'P073' 'R579' '01R9' '01I6'\n",
      " '01Q8' '01P0' 'P282' '01J1' 'P369' '01P2' 'M480' 'W75' 'Q897' 'P011'\n",
      " 'D689' 'P293' 'Q245' 'P209' '01J8' 'Q913' 'P269' 'J984' 'P021' 'I272'\n",
      " '01Q0' 'P070' 'P219' 'R068' 'V892' 'A419' 'Q790' 'P523' 'P543' 'Q893'\n",
      " 'P77' 'T179' 'Q336' 'P220' 'N19' '01A0' 'Q049' 'I958' 'R092' 'A090'\n",
      " 'I279' 'J841' 'Q300' '01A3' 'P280' 'Q917' '1' 'R688' 'K566' '01Q9' 'D899'\n",
      " 'Q899' 'Q212' 'Q606' 'A415' '01Q2' 'P250' 'V874' 'P291' 'P969' 'P271'\n",
      " 'P378' 'Q211' 'S399' 'P240' '01I4' 'P290' 'Q042' 'W80' 'C919' 'P614'\n",
      " 'I288' 'Q613' 'P522' 'P013' 'P529' 'I615' 'Y09' 'Q318' 'J969' 'X30'\n",
      " 'Q878' 'P010' 'I471' 'R99' 'P239' 'P549' 'V877' 'P159' 'C349' 'P916'\n",
      " 'Q283' 'I461' 'I959' 'P783' 'P015' 'Q614' 'K449' 'J960' 'R568' 'Q601'\n",
      " 'P288' 'E872' 'P059' 'P229' 'R95' '01Q7' 'Q927' 'P364' 'T71' '01E4'\n",
      " 'Q234' 'I498' 'I514' 'E713' 'P012' 'Y34' 'P251' 'T817' 'P832' 'Q928'\n",
      " 'N390' 'Q431' 'P027' 'B348' 'Q688' '01A4' 'Q390' 'Q359' 'Q230' 'Q909'\n",
      " 'I456' 'N288' 'D682' 'P249' 'G039' 'K631' 'Q602' 'P025' 'Q200' 'J152'\n",
      " 'Y839' 'F982' 'Y21' 'Q642' 'P912' '01G9' 'P018' 'G936' 'I429' 'Q204'\n",
      " 'P002' 'Y11' 'W79' 'E878' 'Q262' 'K668' 'Q043' 'R570' '01P8' 'G129'\n",
      " 'P292' 'A401' 'Q789' 'P375' 'K729' 'R578' 'P241' 'Q203' 'P000' 'W74'\n",
      " 'Q000' 'A099' 'P780' 'R090' 'Q792' 'Y20' 'J209' 'J690' 'J120' 'P022'\n",
      " 'D761' 'I469' 'K318' 'B342' 'A081' 'Q795' 'Q039' 'Q279' 'P210' 'Q611'\n",
      " 'E875' 'P253' 'I500' 'P232' 'P284' 'J961' '01P9' 'E039' 'E880' 'J189'\n",
      " 'Q894' '01J4' 'I119' 'T149' 'Q02' 'Q246' 'S069' 'Q771' 'Q780' 'Q874'\n",
      " 'T818' 'Q257' 'J42' 'T403' '01J2' 'K766' 'P071' 'I678' 'P960' 'Q898'\n",
      " 'P039' 'J40' 'W84' 'J150' '01Q3' 'I898' 'Q369' 'S061' 'N179' '01G4'\n",
      " 'G008' 'G931' 'J219' 'I458' 'Q794' 'E722' '01I5' 'E86' 'G934' 'Q619'\n",
      " 'P005' '01P3' 'I510' 'J371' 'Q321' '01G1' 'I509' 'P003' 'R599' 'I209'\n",
      " 'I420' 'G002' 'P524' 'P60' 'W78' 'Y079' 'G709' 'P358' 'P360' 'C64' 'Q339'\n",
      " 'Q772' 'I871' 'P942' 'Q255' 'I518' 'R060' 'P720' 'J069' 'J869' 'J849'\n",
      " 'G712' 'I248' 'I422' 'P017' 'K559' 'Q232' 'P026' 'E889' 'K638' 'Q324'\n",
      " 'J988' 'P016' 'E230' 'Q678' 'P741' 'J980' '01P7' 'I64' 'S099' 'P279'\n",
      " 'G919' 'R509' 'E725' 'P368' 'Q605' 'J398' 'K768' '01G0' 'N12' 'P90'\n",
      " 'K659' 'P049' 'I301' 'Q048' 'P033' 'Q248' 'P023' 'W83' 'P548' 'W65'\n",
      " 'P261' 'Q059' 'Q999' 'G319' 'A498' 'Q251' 'X92' 'P392' 'M726' 'I609'\n",
      " 'P281' 'P038' 'P044' 'Q793' 'X85' 'Q349' 'T809' 'J101' 'G409' 'Q458'\n",
      " 'J860' 'W67' 'Q224' 'K550' 'G935' 'Q938' 'Y836' 'X00' 'T598' 'D582'\n",
      " 'D649' 'P236' 'I10' 'P704' 'I319' 'Q030' 'Q743' 'P362' 'Q250' 'I99'\n",
      " 'P399' 'D65' 'Q998' 'Q220' 'Q256' 'R701' 'Q438' '01E8' 'T436' 'K904'\n",
      " 'R048' 'D619' 'Q210' 'K561' 'R278' 'P528' 'A418' 'V090' '01G7' 'Q809'\n",
      " 'D432' 'A403' 'I519' 'Q019' 'Q750' 'I823' 'Q639' 'I472' 'X47' 'K358'\n",
      " 'Q429' 'I259' 'Q254' 'Q229' 'Q872' 'P130' 'M844' 'I517' 'G629' 'V446'\n",
      " 'I639' 'Q935' 'N328' 'N189' 'P526' 'A413' 'P298' 'I499' 'E031' 'B49'\n",
      " 'P592' 'E752' 'P024' 'Q201' 'I620' 'P115' 'R628' 'V031' 'Q929' 'I490'\n",
      " 'Q392' 'S299' 'Q320' 'W69' 'P833' 'K562' 'Q231' 'G809' 'B199' 'P398'\n",
      " 'S199' 'P234' 'A329' 'G009' 'J942' 'R298' 'D471' 'Q018' 'Q225' 'Q439'\n",
      " 'B009' 'Q799' 'Q939' 'Q056' 'D151' 'P035' 'W06' 'G253' '01J9' 'P504'\n",
      " 'Q273' 'P701' 'Q111' 'E711' 'T07' 'E871' 'J930' 'N320' 'V489' 'D561'\n",
      " '01E7' 'I788' 'Q969' 'K070' 'J985' 'P352' 'V819' 'Q870' 'T828' 'P034'\n",
      " 'B99' 'Q031' 'A490' 'Q410' 'D685' 'R571' 'M622' 'X44' 'N343' 'R162'\n",
      " 'R638' '01N1' 'N369' 'P036' 'Q282' 'Q226' 'I442' '01K2' 'P968' 'I709'\n",
      " 'J939' 'Q432' 'J80' 'E46' 'J22' 'S269' 'D696' 'G404' '01E5' '01B3' 'J129'\n",
      " 'X599' 'I249' 'P042' 'J989' 'Q315' 'P008' 'P702' 'N289' 'D489' 'I779'\n",
      " 'N049' 'J00' 'K219' 'P230' 'Y848' 'K661' 'J986' 'E877' 'Q079' 'Y831'\n",
      " 'X91' 'E831' '01D4' 'X95' 'S350' '01R0' 'T740' 'I619' 'Q423' 'T751'\n",
      " 'N185' 'Q240' 'P964' 'Y840' 'G98' 'P041' 'Q391' 'J180' 'A499' 'L022'\n",
      " 'W76' 'P508' 'D801' 'G938' 'S224' 'G711' 'I424' 'V030' 'J121' 'Q871'\n",
      " 'P819' 'S065' 'Q046' 'D695' 'R001' 'Q038' 'Q604' 'Y433' 'T748' 'K769'\n",
      " 'R230' 'Y08' '01R5' 'I370' '01K5' 'K831' 'Y14' 'N139' 'G111' 'G001'\n",
      " 'E343' 'C925' 'V436' 'Q219' 'Q221' 'E744' 'R11' 'D821' 'R64' 'Q400'\n",
      " 'P289' 'E161' 'E143' 'K760' 'J90' 'Q333' 'W20' 'R064' 'S361' 'Y04' 'T450'\n",
      " 'C910' 'T670' 'D481' 'J210' 'I629' 'G908' 'J439' '01M3' 'E162' 'A080'\n",
      " 'I313' 'P769' 'J81' 'G932' 'D480' 'K902' 'B004' '01P5' 'R739' 'Q808'\n",
      " '01C7' '01Q4' 'J154' 'P544' 'T749' 'C749' 'J155' 'Q044' '01A8' 'E770'\n",
      " 'P910' 'Q645' 'G419' 'Y071' 'Y12' 'D181' 'Q442' 'S066' 'R13' 'W31' 'R748'\n",
      " 'R098' 'Y069' 'J040' 'Q433' 'I270' 'J450' 'Y061' 'Q759' '01I2' 'G918'\n",
      " 'I251' 'Q798' '01G8' 'P051' 'P019' '01E3' 'D591' 'A409' 'G969' 'S019'\n",
      " '01I9' 'P020' 'D735' 'V439' 'Q288' 'Q891' 'P393' 'Y832' 'Q322' 'P359'\n",
      " 'Q242' 'I260' 'R402' 'Y430' 'A509' 'T811' 'I822' 'T860' 'Q263' 'K529'\n",
      " 'Q348' 'G318' 'S062' 'A481' 'I059' 'B341' 'K37' 'X97' 'M246' 'H919'\n",
      " 'Q264' 'R91' 'P914' 'S029' '01G3' 'E870' 'P150' 'V092' 'G003' 'A491'\n",
      " 'P394' 'G939' 'E701' 'B379' 'H669' 'Y078' '01I7' 'X09' 'T790' 'B449'\n",
      " 'T857' 'E740' 'P748' 'R02' 'A084' 'P351' 'S223' 'K740' 'P031' 'Q915'\n",
      " 'J158' 'J041' 'B340' 'J448' 'Q643' 'V499' '01N3' '01J0' 'J111' 'A021'\n",
      " 'K761' 'S097' 'Q600' 'Q959' 'A402' 'Q620' 'C929' 'Q239' 'R601' 'V486'\n",
      " 'P361' 'I269' 'R629' 'A410' 'J208' 'E742' 'D849' 'P781' 'J151' 'K567'\n",
      " 'P120' 'I749' 'V476' 'P509' 'Q742' 'X94' 'Q338' 'Q430' 'J218' 'D376'\n",
      " 'Y834' 'R198' 'D728' 'L299' 'K650' 'Q890' 'Y01' 'I219' 'J159' 'E268'\n",
      " 'Y03' 'X99' 'D694' '01D5' 'Y00' 'J128' 'J153' 'R18' 'I710' 'P158' 'Y830'\n",
      " 'R98' 'C793' 'R609' '01R6' 'Q189' 'K720' 'A599' '01R1' 'Q774' 'I829'\n",
      " 'G049' 'D370' 'A879' 'I633' 'E830' 'J950' 'T862' 'E841' 'P200' 'S423'\n",
      " 'I773' 'Y33' 'K223' 'I890' 'X41' 'J852' 'B179' 'G042' '01K7' 'D487'\n",
      " '01K9' 'K920' 'F79' 'P545' 'I741' 'P030' '01N2' 'D818' 'A412' 'P043'\n",
      " 'D571' 'P363' 'S420' 'D819' 'T58' 'T141' 'P112' 'Q040' 'R190' 'S278'\n",
      " 'Q791' 'T981' 'P252' 'Q931' 'B377' 'Y484' 'G961' 'R222' 'Q233' 'N309'\n",
      " 'Q012' 'Q447' 'K922' 'Q933' 'Q873' 'R680' 'Q332' 'J981' 'W54' 'E876'\n",
      " 'R900' 'C920' 'X42' 'T827' 'V890' 'Q753' 'R931' '01R7' 'I459' 'J122'\n",
      " 'Q068' 'P001' 'N998' 'Q269' 'G473' 'T029' 'V887' 'Q222' 'D573' 'E849'\n",
      " 'T758' 'Y883' 'C795' 'V536' 'P201' 'T864' 'R34' 'C80' 'Q310' 'T402'\n",
      " '01I3' 'X37' 'K228' 'I38' 'N137' 'R58' 'Q773' 'R788' 'Q228' 'K296' 'K759'\n",
      " 'V496' 'E833' 'D469' 'Q782' 'M009' 'J029' 'D180' 'K929' 'Q446' 'I739'\n",
      " 'G968' 'J840' 'G121' '01C9' 'T810' 'B24' 'B948' 'I258' 'L988' 'T099'\n",
      " 'P700' 'Y05' 'Y841' 'I400' 'Q699' 'Q419' 'M303' 'P081']\n",
      "Column 'econdp_3': [2 3 0 6 4 1 5]\n",
      "Column 'econds_3': [1 0 2 3]\n",
      "Column 'enicon_3': ['R688' 'R011' '01Q6' ... 'E778' 'E835' 'Q411']\n",
      "Column 'econdp_4': [3 0 6 4 1 2 5]\n",
      "Column 'econds_4': [1 0 2 3 4]\n",
      "Column 'enicon_4': ['P369' '03Q2' '01Q6' '02R9' '02P2' 'P073' '01P0' '03A0' '01R9' '01I6'\n",
      " '01Q8' 'Q913' '01J1' '02P3' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '02A4' 'P220' '01J8' 'P011' '02Q9' 'P072' '02A0' 'A419' '03J6' '01Q0'\n",
      " 'P209' '3' 'Q790' '01P3' '02V8' 'J984' '03Q8' '03P2' '01P7' '02P7' '03R9'\n",
      " '03Q6' 'P298' 'P020' '01A0' '03Q3' 'Q040' '01P5' 'R99' 'P285' 'Q359'\n",
      " '01A3' '02D6' '03I2' 'Q917' 'J80' '1' 'K729' 'E872' 'P522' 'P780' '01Q9'\n",
      " '02P9' '02P0' 'P044' '02D8' '01Q2' 'K750' 'P549' '2' 'P269' '02E8' '02R0'\n",
      " 'P059' '02R5' 'P070' '03Y0' 'P293' 'P362' '03Q9' '01I4' 'P960' '02N1'\n",
      " '02Q0' '03P6' 'Q213' '02Q6' 'I959' 'P614' 'Q688' '02I6' '02Y0' '02Q3'\n",
      " 'Q606' 'R579' 'Q039' 'N320' 'Q249' 'I272' 'G919' '03Q0' 'P523' 'Q433'\n",
      " '03Q7' 'N19' 'R068' 'E841' '02P8' '03A4' 'Q613' 'J961' '01P9' 'I509'\n",
      " '03E8' 'Q369' '03P9' 'E875' 'S199' '03P0' 'A090' '01Q7' '03G9' '03W7'\n",
      " '01E4' 'Q390' 'T149' '03P7' '02E7' 'P038' 'Y834' 'K720' '02Q4' '03B3'\n",
      " 'R278' 'Q043' '01A4' 'Q897' 'E722' 'I615' '03Y3' 'Q410' 'I694' '02I4'\n",
      " 'R688' '03Y2' '02B3' '03K6' '02G9' 'N138' 'P027' 'Q336' 'Q000' 'K659'\n",
      " 'J988' 'A498' 'K668' 'P010' 'R629' 'P701' 'H919' 'P546' '01G9' 'B348'\n",
      " '03V8' '03I4' 'Q212' 'P051' 'P832' 'D432' 'Q201' '03Y1' 'T179' '03I6'\n",
      " '02B4' '01P8' '02G1' 'Q223' '03P3' '03P5' '02K5' 'Q423' 'P352' 'Q909'\n",
      " 'I64' 'Q251' 'Q019' 'X41' 'Q049' 'T751' 'Q210' 'Q899' 'Q804' 'Q250'\n",
      " 'P941' 'P015' 'Q030' '03I3' 'R628' 'I99' '02K4' 'T273' 'N179' 'D70'\n",
      " 'G473' 'P77' 'K318' 'Q282' 'P021' '03P8' '01Q3' 'J860' 'J439' 'T71'\n",
      " '02J1' '01J4' '02I1' 'P239' 'J189' 'Q750' 'Q234' 'S399' '01J2' '03K4'\n",
      " 'J969' '02K6' '03W8' 'A415' 'Q793' 'S223' 'P364' '01G4' 'P360' 'Q675'\n",
      " '01I5' 'Q315' 'Q898' 'P039' '01G1' 'I469' 'F982' '02I2' '02J2' 'G809'\n",
      " 'P012' '02P6' 'X85' '03G7' 'I629' '02W8' 'P229' 'Q239' 'P288' 'P60'\n",
      " 'I319' 'C64' '03J0' '02J8' 'Q225' 'P023' 'P90' '02G7' 'Q871' 'K562'\n",
      " 'Q278' 'P399' 'E710' '03Q4' 'R090' 'Q872' 'Q254' 'E880' 'K639' 'Q602'\n",
      " 'Q255' 'P024' 'Q878' 'Q079' 'C719' 'Q258' '03K7' '01G0' '02G0' 'J980'\n",
      " 'Q639' 'A490' 'R570' 'Q211' 'P912' 'K831' 'K913' 'S058' '03G3' 'P251'\n",
      " 'Q614' '02X9' 'E713' 'P529' 'Q928' 'E752' '03J9' 'R568' 'Q203' 'G129'\n",
      " '02J9' '03G1' 'T510' 'Q048' 'Q794' 'E230' 'P081' 'D720' 'Q444' 'Q230'\n",
      " 'P290' 'D689' 'Q645' 'T598' 'R160' 'I288' 'D489' 'P722' 'Q442' 'Q333'\n",
      " 'H669' 'Q890' '02Y2' 'P219' 'I678' 'P029' 'Q601' 'W65' '02I5' 'Q02'\n",
      " 'M622' 'P271' 'Q248' '01E8' 'Q780' 'G008' 'Q870' '02X3' '03W1' 'P769'\n",
      " '03R2' 'R298' 'P504' '02V0' '01G7' '02D4' 'J982' 'Q743' 'Q320' 'Q934'\n",
      " '03I5' '02I8' 'G98' 'B49' 'P009' 'Q031' 'Q642' 'Q611' 'G934' 'P013' 'D45'\n",
      " '03C9' 'I251' 'E742' 'Q678' 'X599' 'I424' 'P080' 'Q321' 'Q262' 'P022'\n",
      " 'N302' 'P528' 'Q256' 'D761' 'E889' 'P968' 'J218' 'Q828' 'P700' 'Q999'\n",
      " 'R098' 'D619' 'C749' 'P241' 'D571' 'Q392' 'Q431' 'V892' '02Y3' 'I519'\n",
      " '01P6' 'P000' 'G936' 'Q219' 'D589' 'V486' '02A3' 'P704' 'I422' 'J939'\n",
      " 'W84' '03D4' 'G952' 'P279' 'P036' 'I898' 'P005' 'P916' 'Q231' 'I289'\n",
      " 'R609' 'Q246' 'G049' '03N1' 'E031' 'K766' 'B259' 'W75' 'W04' '03D1'\n",
      " '02W0' 'J985' 'G319' '01J9' 'Q233' 'J122' 'K760' 'Y079' 'D821' 'P240'\n",
      " '01E7' 'P280' 'Q969' 'Q228' 'Q759' 'P613' 'P234' '03B4' 'Q322' 'Q059'\n",
      " 'B341' 'I871' 'P351' 'R58' '03J3' '03D5' 'K550' 'Q438' 'Y34' '02N3'\n",
      " '02P1' '03I8' 'P592' 'Q318' 'R908' 'Q042' '01N1' 'R001' 'I802' '01K2'\n",
      " 'T868' 'Q789' 'R18' '03I7' 'I609' 'Q822' '03E4' 'Q792' 'J069' 'V877'\n",
      " '02J4' 'P250' '01E5' 'T450' '01B3' 'I471' 'I517' '02X5' 'P291' '02C6'\n",
      " 'Q349' 'G931' 'P003' 'P042' 'J450' 'G419' 'P38' 'Q605' 'Q643' '02J0'\n",
      " 'Q200' '02Y8' '02I3' 'P548' '02B0' '01D4' 'D65' '03X9' 'T141' 'T814'\n",
      " '01R0' 'T740' 'D758' 'R34' 'P028' 'Q419' 'D849' 'P236' 'B342' 'K590'\n",
      " 'P043' 'Q799' 'P231' '03B0' 'G002' 'P253' 'P017' 'D696' '02B2' 'D682'\n",
      " 'I421' 'P524' 'S099' 'B340' 'K070' 'P071' 'J930' 'K768' 'P588' 'P398'\n",
      " 'E274' 'R634' 'J348' '03J1' 'I639' '03G0' '01R5' '03D6' 'R17' '01K5'\n",
      " 'Q893' 'D480' 'I458' 'T436' 'R601' 'J13' 'B349' '02E3' 'Y839' '03E3'\n",
      " 'P252' 'Q929' 'E232' 'P781' '03E1' '02K7' 'D694' 'J205' 'P910' 'K638'\n",
      " 'Q798' 'E86' 'P375' 'R95' 'D487' '02C9' 'S729' 'A099' 'Q549' 'T099' 'C80'\n",
      " 'X44' 'I10' '03X4' 'P965' 'A080' '02V4' 'P018' 'K769' 'Q339' 'P034'\n",
      " 'Q348' '01M3' 'P289' 'Q649' 'P008' 'G709' '03J2' '02D7' 'J387' '02R7'\n",
      " '02E4' 'H905' 'Q680' 'K566' '01C7' '01Q4' 'P210' 'P159' 'K902' 'T07'\n",
      " 'E849' 'N390' 'Q264' '01K4' '01A8' '03K5' 'Y069' 'Q772' 'I249' 'Q620'\n",
      " 'R638' '02Y1' '03V4' 'Y09' 'P543' 'Q782' 'R238' 'Q933' 'S242' 'I518'\n",
      " 'J81' 'W78' 'Q038' 'P112' 'I400' 'E878' 'I350' 'G039' 'D695' 'K631'\n",
      " 'E725' 'K559' 'Q360' 'I500' '03M8' 'P284' '01I2' 'S129' 'P809' '02K8'\n",
      " '01G8' '01E3' 'G918' 'Q939' '03E7' '01I9' '02B9' '02D1' 'P368' 'G409'\n",
      " 'K529' 'P550' 'J180' 'P049' '02Y4' 'P016' 'P788' '03B9' '03Y8' 'P702'\n",
      " 'R233' 'D759' 'S028' 'W80' 'Q300' '4' 'T749' 'I779' '02R2' 'V476' '02C7'\n",
      " 'R509' '02Q5' 'I741' '02K3' 'P292' 'J111' 'A499' 'G935' 'P026' 'K650'\n",
      " 'P035' 'J960' '01G3' 'J849' 'P002' 'Q112' 'P378' 'B250' 'Q742' 'J210'\n",
      " 'Q935' 'N289' 'Q938' 'K469' 'T741' 'Q753' 'Q998' 'Q932' 'D582' '01I7'\n",
      " '03C7' 'R529' 'Q011' '02D5' 'K721' 'G122' 'T828' 'B464' 'G938' 'Q232'\n",
      " 'S069' 'Q778' 'Q600' 'R13' 'R633' 'P783' 'K561' 'Q204' '02R1' 'S065'\n",
      " 'S066' 'J129' 'I459' '01N3' '01J0' 'I429' 'Q143' 'B378' 'S299' 'Q776'\n",
      " 'S369' 'R092' 'W79' 'Q984' 'Y08' 'G712' '02X0' 'Q873' 'P526' 'S301'\n",
      " 'K661' 'Q046' 'J042' 'Q240' 'J09' 'K228' '03D7' 'E835' 'Q402' 'Q270'\n",
      " 'P599' 'J159' 'M245' '02W6' '03B2' '02G4' 'D692' 'T189' 'N288' '03P1'\n",
      " '02I7' 'E877' 'A870' 'K922' 'P025' 'K219' 'N185' 'W22' 'E278' 'Y605'\n",
      " '02E2' 'N133' '03K2' 'Q819' 'Q771' '03K9' 'T813' 'Q411' 'Q809' '01P1'\n",
      " 'N139' 'Q795' 'D573' 'S029' 'Y848' 'K746' 'S363' 'G508' 'I050' 'Q224'\n",
      " '01D5' 'Q229' 'N47' '02M6' 'J155' 'Q791' 'Q338' 'C920' 'Q283' 'T748'\n",
      " 'E343' 'Y832' 'E778' 'P158' 'S064' 'E870' 'M439' '03C4' '01R6' 'P718'\n",
      " '03J4' 'Q105' '02A5' '01R1' 'Q268' 'Q619' 'D649' 'Q226' '02A8' 'X92'\n",
      " 'Q892' 'J209' 'Y20' 'Q623' 'P961' 'B379' 'V436' 'J121' '01K7' '01K9'\n",
      " 'P134' '01N2' '03G4' 'D66' 'G932' 'M869' '03X0' 'P001' 'R048' 'J14'\n",
      " 'R161' 'W44' 'I499' 'Q749' 'T818' 'T981' 'Q330' 'K567' 'D471' 'G318'\n",
      " 'I313' 'D500' 'N189' 'T679' 'T509' 'D899' '02E1' 'J386' 'D685' 'J981'\n",
      " 'G838' 'P363' 'J448' 'S273' '02C8' 'K660' 'W33' '02R6' '01J3' 'J90'\n",
      " '02W5' 'Q044' '03Q5' 'C959' 'Q238' 'Q699' '03A5' 'Q012' 'T406' '03M3'\n",
      " 'I700' '02H6' '01R7' 'R02' 'P048' 'G009' 'X590' 'P249' '03J8' 'Q621'\n",
      " 'Q259' 'S068' 'Q257' 'Q764' 'Q891' 'Q927' 'G629' 'Q220' 'T860' 'V031'\n",
      " 'Q773' 'P281' 'B009' 'I829' 'I709' 'T402' 'P230' '01I3' 'S268' 'R060'\n",
      " 'R578' 'Q263' 'C229' 'I420' '03M6' 'Q279' 'M898' 'P235' '03R7' 'I740'\n",
      " 'J219' 'P030' 'Q447' '02K9' 'R400' 'Q241' 'Y14' 'J152' 'B99' 'R740'\n",
      " 'P261' 'A402' 'I48' 'H540' '01C9' 'K767' '01B2' 'Y061' 'P004' 'P929'\n",
      " 'K449' 'P969' '03E5' '02L9' 'J00' 'P154' 'S202' 'P558' 'I515' 'J40'\n",
      " 'E569' 'S224']\n",
      "Column 'econdp_5': [0 6 3 4 1 2 5]\n",
      "Column 'econds_5': [0 2 3 1 4 5]\n",
      "Column 'enicon_5': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' 'P299' '3' 'B349' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' 'P220' 'P073' 'P614' '01A0' '03Q3' 'R568' '01P5' '04J8' '4' '01A3'\n",
      " 'Q248' '02D6' '03I2' 'P251' '03J8' '1' 'N19' '04E8' '03P3' '01Q9' '02P9'\n",
      " 'Q613' '02D8' 'P072' '01Q2' 'P059' '04A0' 'P001' '2' '02E8' '02R0' '02R5'\n",
      " '03Y0' '04Q7' '03Q9' '01I4' 'I959' '02N1' '02Q0' '03P6' 'Q255' '02Q6'\n",
      " '04P0' '02I6' '02Y0' '02Q3' '04Q6' 'Q897' 'R688' 'P780' '03P1' 'P015'\n",
      " '04P9' '03Q0' 'P960' 'Q150' '03Q7' '03K5' 'E875' 'P369' 'P293' '02P8'\n",
      " '03A4' '04Q3' '01P9' 'Q998' '03E8' 'Q359' '03P9' 'D70' 'R048' '01Q7'\n",
      " '03G9' '03W7' '01E4' 'Q764' '04I5' '02E7' 'Q249' 'K721' '02Q4' '03B3'\n",
      " 'Q044' 'Q899' '01A4' 'P352' '03Y3' 'Q909' 'Q423' '02I4' 'I64' '03Y2'\n",
      " 'P209' '02B3' 'Q211' '03K6' '02G9' '04Q0' '04P8' 'J398' '04B3' 'J09'\n",
      " 'E872' 'Q250' 'P022' 'M898' '01G9' 'J189' '03V8' '03I4' '03I5' '04G5'\n",
      " '04Q2' '03Y1' '03I6' '02B4' 'J984' 'P027' 'P020' '01P8' '02G1' 'P250'\n",
      " 'E889' '02K5' 'P039' 'R068' '03P8' 'Q999' '04W7' 'J961' 'Q369' 'Q210'\n",
      " 'A090' 'G938' '03I3' 'Q321' 'P010' 'R090' 'K631' 'P023' '02K4' 'G419'\n",
      " 'Q600' 'Q283' '04I6' 'Q392' 'P60' 'P285' '01Q3' 'Q390' 'R99' 'J80' '02J1'\n",
      " '01J4' '02I1' '04Q8' '04J1' 'Q750' '04Y0' '01J2' '03K4' 'G931' '02K6'\n",
      " '03W8' 'A410' 'P024' 'J156' 'S273' 'P269' '01G4' 'P011' '03E7' '01I5'\n",
      " '04A4' 'P229' 'P070' '01G1' 'J969' 'I471' '02I2' 'D689' '02J2' 'D821'\n",
      " '02P6' 'S224' '03G7' 'P012' 'Q201' '02W8' 'Q229' '03I8' 'P968' 'P289'\n",
      " 'D696' 'P291' 'I330' '04C6' '04P2' '03J0' '02J8' 'R263' 'K639' 'K729'\n",
      " 'Q939' '02G7' 'P832' '04Q4' 'P044' 'E343' 'Q262' 'P523' '03Q4' 'R628'\n",
      " 'I422' 'Q792' '04P7' 'I802' 'I822' '04G9' 'P034' 'Q913' '03C7' 'D376'\n",
      " 'E232' '03K7' '01G0' '02G0' 'Q790' 'K768' 'N179' 'R18' 'P543' '04P5'\n",
      " 'T741' '03G3' 'A419' '02X9' '04M7' '04I7' 'Q872' 'I517' 'Q410' 'Q539'\n",
      " '03J9' 'I615' '02J9' '03G1' 'X45' 'R278' 'P522' 'P051' '04K6' 'P701'\n",
      " 'Q234' 'Q040' 'K746' 'I442' 'Q602' 'P021' '03X0' '04D5' 'P292' 'K829'\n",
      " '04H6' '02Y2' 'Q213' 'P290' 'G473' 'J939' 'E833' 'P398' 'T751' '02I5'\n",
      " 'P038' 'I749' 'T814' 'P000' '01E8' 'G919' 'Q859' 'I829' 'T179' 'R579'\n",
      " 'P916' '02X3' '03W1' '03R2' 'Q320' 'Q928' '02V0' '01G7' 'D489' 'M622'\n",
      " '02D4' 'P548' 'K929' 'I709' '04I2' '02I8' '04B4' 'R633' 'P271' '03C9'\n",
      " 'Q203' '04K7' 'Q038' 'P005' 'Q431' 'Q230' 'Q893' 'Q969' 'N133' 'G809'\n",
      " 'G918' 'D849' 'Q349' 'Q212' '04D7' 'I219' 'Q070' 'J90' 'D471' 'G934'\n",
      " 'E86' 'T796' 'Q336' 'P378' '02Y3' 'I370' '01P6' 'Q030' 'D728' '02A3'\n",
      " 'L989' 'I509' 'R011' 'Q780' '03D4' 'Q188' 'Q860' 'P008' 'P028' 'P910'\n",
      " 'P616' 'P90' 'N898' '03N1' 'I272' 'T71' '04W0' '03D1' 'Y09' '02W0' 'P280'\n",
      " '01J9' 'Q048' 'Q935' '01E7' '04K0' 'R571' '03B4' 'Q265' 'J988' 'A415'\n",
      " 'E722' '03J3' 'P549' '03D5' 'A481' 'K598' 'T509' '02N3' '02P1' 'J690'\n",
      " '01N1' 'I498' '01K2' '03I7' 'Y848' '04E4' '03E4' 'J22' '04V8' 'A499'\n",
      " 'Q251' '04P6' '02J4' '01E5' 'T450' 'G039' '01B3' '02X5' 'E039' '02C6'\n",
      " '04I1' 'Q620' 'B341' 'E161' '03N2' 'J40' '02J0' 'N189' '02Y8' 'R001'\n",
      " 'Q748' 'P529' 'N390' 'K769' 'P524' 'T07' '02I3' '04N1' '04D6' 'P399'\n",
      " '02B0' '01D4' '03X9' '04X9' 'Y839' '04K4' '01R0' 'P969' 'Q189' '04D4'\n",
      " '03Q1' '04D8' 'Q391' 'P77' 'B259' 'P920' 'P002' 'Q898' '03B0' '03G0'\n",
      " 'Q871' 'S199' 'T149' 'X590' '02B2' 'J960' 'Q226' 'Q225' 'P026' 'E878'\n",
      " 'V436' 'B348' 'Q639' 'Q059' 'Q233' 'Q245' 'P219' 'N049' '03K3' 'I639'\n",
      " 'J348' '03J1' 'Q049' '01R5' 'S099' '04I3' '01K5' 'P704' '04I4' '04R9'\n",
      " 'Q917' 'R34' 'K219' '02E3' 'K315' 'E559' '03E3' 'R740' 'Q046' 'Q688'\n",
      " '03E1' '02K7' 'I518' 'K070' 'I500' 'Q288' 'H351' '02C9' 'T512' '04K5'\n",
      " 'R509' 'T402' '03X4' '02V4' 'P018' 'E46' 'Q179' 'I99' '01M3' 'A490'\n",
      " 'R298' 'P049' '03J2' '02D7' '02R7' 'Q270' '02E4' 'D181' 'K227' '01C7'\n",
      " '01Q4' 'P030' '04P1' 'Q419' 'E841' 'Q223' '01K4' '01A8' '04I8' 'G935'\n",
      " 'R13' 'Q793' '04Y2' 'K228' 'A401' '02Y1' '03V4' 'J989' 'N288' 'Q039'\n",
      " 'Q254' 'P364' 'Q878' 'D65' 'P042' 'R570' 'S223' 'Q749' '03M8' '01I2'\n",
      " 'Q256' '02K8' '01G8' '01E3' 'K904' '01I9' '02B9' 'J860' '02D1' 'Q894'\n",
      " 'K638' '02Y4' 'Q743' '03B9' '03Y8' 'P393' 'P545' '04Y8' 'D820' 'Q447'\n",
      " 'R58' 'T435' 'I739' 'I510' 'K409' '02R2' 'G968' '02C7' '02Q5' 'P709'\n",
      " '02K3' 'M246' 'Q300' '01G3' 'P741' 'I10' 'Q130' 'E870' 'Q606' 'D899'\n",
      " 'R162' 'D480' 'Q933' '04G7' 'Q200' '04J2' 'E274' '01I7' 'K828' 'K561'\n",
      " '02D5' 'Q442' 'I778' 'Y831' 'E213' '04G4' 'I898' 'Q246' 'I469' 'Y34'\n",
      " 'D819' 'I633' 'I788' 'P559' 'X85' 'P013' 'P599' 'H669' '02R1' 'S066'\n",
      " 'S029' '04G1' 'I429' '01N3' '01J0' 'P239' 'Q938' 'P279' 'Q031' 'Q141'\n",
      " 'T748' 'W78' 'J218' '02X0' 'Y14' '04C9' 'G008' '03D7' 'E109' 'K439'\n",
      " 'K449' 'P351' 'Q02' 'Y846' 'Q668' '05I4' 'R092' '02W6' '03B2' '02G4'\n",
      " 'R75' 'A498' 'R060' '03X5' '02I7' 'P819' 'B377' 'D649' '04W2' 'P912'\n",
      " '02E2' 'K318' '03K2' '03K9' 'G713' 'J980' '01P1' 'Q798' 'P071' '04N2'\n",
      " 'S062' 'S362' '01D5' '02M6' 'J152' '04W8' '04X5' 'D694' '04E7' 'X599'\n",
      " 'S061' 'D619' '03C4' 'P240' '01R6' '03J4' 'H358' '02A5' '01R1' 'K265'\n",
      " 'Q614' 'W75' 'S368' 'I620' 'Q809' 'G936' '02A8' 'S065' 'Q891' '04Y1'\n",
      " 'T749' '04G0' 'Y20' 'D370' 'P081' 'N321' '04B1' '01K7' '01K9' '01N2'\n",
      " '03G4' '04R2' 'Q789' 'M629' 'J219' 'P588' 'J940' 'Q768' 'J158' 'R578'\n",
      " 'C64' 'T189' 'Q339' 'J930' 'Q000' 'P043' 'X30' 'W84' 'Q564' 'G711' 'M869'\n",
      " 'Q204' 'I38' 'Q929' 'R601' '02E1' 'P288' '04X4' 'J841' 'Q224' 'P253'\n",
      " 'I288' 'P929' 'R95' '02C8' 'P035' '02R6' 'I289' '01J3' 'K831' '02W5'\n",
      " '03Q5' 'P278' 'Q970' 'K559' 'R160' 'P702' '03A5' 'I421' 'Q228' 'P298'\n",
      " 'Q240' 'R198' '03M3' '02H6' '01R7' 'Q257' 'Q382' 'I629' 'K918' 'G009'\n",
      " 'Y832' 'G129' 'Q611' 'G600' 'P504' '04E2' 'Q771' '02N2' 'J129' 'I248'\n",
      " 'S069' '01I3' 'D685' 'I459' 'S423' 'R609' 'Q322' 'C780' 'Q232' 'Q777'\n",
      " '03M6' 'P230' '03R7' 'B99' '02K9' 'W33' 'T510' 'X47' 'J210' 'I279' 'Q043'\n",
      " 'J81' 'K902' '01C9' '01B2' 'K661' 'E43' 'G049' '03E5' '02L9' 'P700'\n",
      " 'P961' 'Y079' 'Q279' 'Q558' 'H919' 'T090' 'J069' 'I050' 'P284']\n",
      "Column 'econdp_6': [0 3 6 4 1 2 5]\n",
      "Column 'econds_6': [0 3 1 5 4 2 6]\n",
      "Column 'enicon_6': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' 'I279' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' 'E875' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' 'I959' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' 'Q614' '02D8'\n",
      " '01Q2' 'Q438' '04P7' 'P006' '2' '02E8' '02R0' '02R5' '03Y0' 'Q909' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' 'P070' '04P9' 'P012' '03P1' 'P072' '03Q0' '05Q9'\n",
      " '03Q7' '03K5' '5' '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' 'Q042' '03P9'\n",
      " 'P614' 'Q913' '01Q7' '03G9' '03W7' '01E4' '05Q2' '04I5' '02E7' 'Q250'\n",
      " 'P369' 'E713' '02Q4' '03B3' '05J9' 'P059' '01A4' '03Y3' '05C9' '02I4'\n",
      " 'P90' '03Y2' '02B3' 'Q210' '03K6' '02G9' '04P8' 'K229' '04B3' 'P209'\n",
      " 'J984' 'D65' 'Q359' '05Q8' 'P021' 'P073' '01G9' 'I424' 'J154' '03V8'\n",
      " '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' 'I272' '01P8'\n",
      " 'Q369' '02G1' '02K5' 'P010' '03P8' '03J1' 'Q917' '04W7' '05A4' 'Q211'\n",
      " 'R688' '05P9' '03I3' 'Q390' 'R34' '02K4' 'J969' 'Q012' '04I6' '01Q3'\n",
      " 'J80' '02J1' '01J4' '02I1' '04Q8' 'P220' 'R18' '04J1' 'P051' 'Q263'\n",
      " 'K904' '04Y0' '01J2' '05K7' '03K4' 'I469' '02K6' '03W8' '05I8' 'T149'\n",
      " 'D696' '01G4' '03E7' '01I5' '04A4' 'Q898' '01G1' 'B348' '02I2' '02J2'\n",
      " 'K720' '02P6' '05Y0' '03G7' 'N19' '05Q3' '02W8' 'I429' 'P291' '03I8'\n",
      " 'R568' 'I729' 'K550' '05W7' '04C6' '03J0' '02J8' 'Q790' '02G7' 'K760'\n",
      " '04Q4' '03J9' 'P251' '04N1' '03Q4' '05P2' 'K868' '05Q7' '05E8' 'R99'\n",
      " 'Q200' '05P8' 'D689' 'I709' 'I48' '05I4' '04G9' 'J860' '03C7' 'G08'\n",
      " '03K7' '01G0' '02G0' 'Q564' '04P6' '05A0' '05I6' 'Q423' 'S372' '04P5'\n",
      " 'Y833' 'I64' '03G3' '02X9' '04M7' '04I7' 'Q749' 'B349' 'Q600' 'Q264'\n",
      " '04E7' 'Q213' 'E872' '02J9' '03G1' 'Q212' 'T509' '04D6' 'Q201' '04K6'\n",
      " 'R048' 'Q031' 'P158' 'K409' '03X0' '04D5' '05Q4' 'P285' 'Q048' '04H6'\n",
      " '05P7' '02Y2' 'R17' '05J3' '05P3' 'K729' '02I5' 'P271' '05P6' 'J961'\n",
      " 'Q401' '01E8' 'T436' 'R601' 'W80' 'Q792' '02X3' '03W1' 'P290' '03R2'\n",
      " 'D682' '05P5' 'K768' '02V0' '01G7' '02D4' 'J986' 'Q928' '04I2' '02I8'\n",
      " 'P60' '04B4' 'K219' '04I8' 'P280' 'Q111' 'A419' '04Q1' '03C9' 'Q203'\n",
      " '04K7' 'P229' '05G9' 'Q249' 'P529' 'Q233' 'Q204' 'Q268' 'P011' 'P543'\n",
      " 'Q336' 'P832' 'P015' 'Q231' '04D7' 'P77' 'P780' 'I313' '04W8' 'Q251'\n",
      " 'J398' '02Y3' '01P6' 'Q256' 'D649' 'Q039' 'Q219' 'R162' '02A3' 'Q688'\n",
      " 'D432' 'Q392' '03D4' 'P960' 'P219' 'Q872' 'R570' '03N1' 'H052' 'A090'\n",
      " '04W0' '03D1' 'R579' 'P292' '02W0' 'I422' 'P599' '01J9' 'K759' 'P023'\n",
      " 'K659' 'R629' '01E7' '04K0' 'J960' '03B4' '05D5' '04C8' '03J3' '03D5'\n",
      " 'B377' '05X4' '02N3' '02P1' 'Q799' '01N1' 'R092' '01K2' '03I7' 'D820'\n",
      " 'P549' '04E4' '03E4' 'P027' '04V8' 'Q242' 'G938' 'P038' '02J4' '01E5'\n",
      " 'X44' '04G0' '01B3' '02X5' 'E274' '02C6' 'P522' '04I1' '05Y8' 'R441'\n",
      " 'Q000' '03N2' '02J0' '02Y8' 'P961' 'Q059' '02I3' 'P005' '02B0' '01D4'\n",
      " 'A490' '03X9' '04X9' 'I519' '04K4' '01R0' 'P024' 'N179' 'P293' 'P042'\n",
      " 'P523' '04D4' '03Q1' '04D8' 'P034' 'N289' 'R198' 'P704' '03B0' '03G0'\n",
      " 'G919' '05R9' 'Q999' '02B2' 'Q255' '04I4' 'P351' 'E870' 'E878' '03K3'\n",
      " '01R5' 'P269' '04I3' '01K5' '04R9' '05B3' '02E3' 'Y839' 'Q878' '03E3'\n",
      " 'Q899' 'E230' 'Q333' '03E1' '02K7' 'Q678' 'Q766' 'P284' '02C9' 'X89'\n",
      " '04K5' '03X4' '02V4' 'T730' '01M3' 'R068' '03J2' 'Q897' '02D7' '02R7'\n",
      " 'B379' 'Q645' '02E4' '01C7' '01Q4' '04P1' '05K9' '05D6' '01K4' '01A8'\n",
      " 'T179' 'Q248' 'Q262' '04Y2' 'P281' 'P524' '02Y1' '03V4' 'P071' 'P968'\n",
      " 'G934' 'P039' 'I678' 'P288' 'A099' 'Q921' 'E46' 'K631' 'Q431' 'I823'\n",
      " 'P240' 'S822' '03M8' '01I2' '02K8' '01G8' '01E3' '05K2' '01I9' '02B9'\n",
      " '05K6' '02D1' 'I99' '05G0' 'P018' 'G911' '02Y4' '05A5' 'J155' '03B9'\n",
      " '03Y8' 'E668' '04Y8' 'Y09' 'M311' 'Q793' 'E880' 'E161' 'G318' 'T430'\n",
      " 'K566' '02R2' '02C7' 'C80' '02Q5' '02K3' 'Q893' 'R298' 'Q179' 'E349'\n",
      " 'J981' '01G3' 'P002' 'Q040' 'J041' 'H540' 'D487' '04G7' 'J930' '04J2'\n",
      " 'K661' 'I788' '01I7' 'P364' '02D5' 'N288' 'E232' '05G1' 'P528' 'D735'\n",
      " 'K559' '04G4' 'E889' '05Y3' 'Q459' 'R11' 'T71' 'I808' 'I611' 'R02' '02R1'\n",
      " '05X5' 'S065' '04G1' '01N3' 'A412' '01J0' 'P362' 'K831' 'Q019' 'J189'\n",
      " 'Q058' 'R628' 'P910' '02X0' 'T450' '04C9' 'Q038' '03D7' 'G049' 'P000'\n",
      " 'Q437' 'I471' 'P043' '02W6' 'P509' '03B2' 'Q998' '02G4' 'Q873' 'P398'\n",
      " '03X5' '02I7' '05A8' 'B49' 'Q288' 'E149' '04W2' 'T812' '02E2' 'Q929'\n",
      " 'D70' '03K2' '03K9' '01P1' '04N2' 'P375' 'S361' 'S369' '01D5' '02M6'\n",
      " '04X5' 'Q02' 'P239' 'R060' 'T749' 'I829' 'Q809' '03C4' '01R6' 'T810'\n",
      " '03J4' '02A5' '01R1' 'K758' 'P279' 'N200' 'T141' 'P360' 'I269' '02A8'\n",
      " 'H350' 'E031' 'I509' '04Y1' 'P252' 'T142' 'I629' 'E86' 'Q794' '04B1'\n",
      " '01K7' '01K9' '01N2' '03G4' '05K4' '04R2' 'R230' '05E4' 'D821' '05M6'\n",
      " 'I350' 'Q798' 'N139' 'P368' 'E871' 'P020' 'P298' '05N3' 'P250' 'D685'\n",
      " 'P044' 'Q254' '05Y2' '05G7' 'Q070' 'I615' 'A410' 'I442' '02E1' '05K0'\n",
      " 'A499' '04X4' 'Q606' 'J988' '05P1' '02C8' 'R064' 'P013' '02R6' '01J3'\n",
      " '02W5' '03Q5' '05B0' 'D695' 'D761' 'Q043' '05D7' 'Q624' '03A5' 'R91'\n",
      " '05K5' 'P025' 'R13' '03M3' '02H6' 'I749' 'Q935' '01R7' 'D181' 'P702'\n",
      " 'Q225' 'G419' 'G918' 'T855' 'T751' 'Q234' 'Q257' 'I10' '04G6' '04E2'\n",
      " 'E639' 'I710' 'I639' '02N2' '6' 'K403' 'I38' '01I3' '05M7' 'Q230' '03M6'\n",
      " 'Q315' 'P741' '03R7' '05M0' '02K9' 'Y15' 'P399' 'Q224' 'J152' 'F069'\n",
      " '04X0' '01C9' '01B2' 'T099' 'P521' 'Y20' '03E5' '02L9' 'R943' 'S301'\n",
      " 'Y34']\n",
      "Column 'econdp_7': [0 3 6 4 1 2 5]\n",
      "Column 'econds_7': [0 3 6 4 1 2 5 7]\n",
      "Column 'enicon_7': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' 'P220' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' 'P073' '02D8'\n",
      " '01Q2' 'J984' '04P7' 'P042' '2' '02E8' '02R0' '02R5' '03Y0' '04Q7' '03Q9'\n",
      " '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0' '02Q3'\n",
      " '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' 'P614' '05Q9' '03Q7' 'P209'\n",
      " '03K5' '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' 'Q213' '01Q7'\n",
      " '03G9' '03W7' '01E4' '05Q2' '04I5' '02E7' 'D821' '02Q4' '03B3' '05J9'\n",
      " '01A4' 'P285' '03Y3' '05C9' '02I4' '03Y2' '02B3' 'Q251' '03K6' '02G9'\n",
      " '04P8' 'P001' '04B3' '05P3' 'I272' 'A419' '05Q8' 'A490' '01G9' 'I514'\n",
      " 'J159' '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4'\n",
      " 'Q249' '01P8' 'Q359' '02G1' 'I959' '02K5' 'P011' '03P8' '03J1' '04W7'\n",
      " 'Q172' 'P369' '05A4' 'Q564' '05P9' '03I3' 'Q909' 'P960' '02K4' 'Q254'\n",
      " 'I678' '04I6' '04D6' '01Q3' 'P293' '02J1' '01J4' '02I1' '04Q8' '05P5'\n",
      " 'D696' '04J1' 'Q764' 'N19' '06Q2' '04Y0' '01J2' '05K7' '03K4' 'T887'\n",
      " '02K6' '03W8' 'P022' '05I8' 'Y09' '01G4' '03E7' '01I5' '04A4' 'P044'\n",
      " 'P229' '01G1' 'B341' '02I2' '06G0' '02J2' 'N179' '02P6' '05Y0' '03G7'\n",
      " '05P2' '05Q3' '02W8' 'I739' '03I8' 'Q390' 'P291' 'Q899' '05W7' '04C6'\n",
      " '03J0' '02J8' '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8' '04N1'\n",
      " '03Q4' '06J9' '05E8' 'P043' 'P288' 'I288' '04G9' '03C7' 'D181' '03K7'\n",
      " '01G0' '02G0' 'Q423' '04P6' '05A0' '05I6' '05P6' 'X599' '04P5' 'K632'\n",
      " 'I629' 'P780' '03G3' 'J860' '02X9' '04M7' '04I7' 'P081' 'Q433' '06K7'\n",
      " '04E7' 'Q898' 'Q250' '02J9' '03G1' '06Q3' '06X8' '04K6' '06D7' 'K550'\n",
      " '03X0' '04D5' 'D689' '05Q4' 'P912' '04H6' 'Q668' '02Y2' 'T71' '05J3'\n",
      " '06P2' '02I5' '06G4' 'Q984' '06P8' '01E8' 'X41' 'J189' 'R633' 'P072'\n",
      " '06Q8' '02X3' '03W1' '03R2' 'I64' 'B948' '02V0' '01G7' 'R99' '02D4'\n",
      " '06I8' 'I471' '04I2' '02I8' 'P523' '04B4' 'P284' '04I8' 'Q000' '04Q1'\n",
      " '03C9' '04K7' '05G9' '06Q6' 'P015' 'I10' 'I871' 'R739' 'R048' '05D6'\n",
      " 'J81' 'P90' 'Q913' '06A0' '04D7' 'P012' 'P529' 'P051' '04W8' 'Q999'\n",
      " 'K639' '02Y3' 'Q231' '01P6' 'Q201' 'H351' 'Q631' 'Q234' '06P0' 'P251'\n",
      " 'G938' '02A3' 'G122' '03D4' '06P9' '06I2' '03N1' 'Q256' 'T813' '04W0'\n",
      " '03D1' '02W0' 'P60' '06G3' '01J9' 'S099' 'Q336' '01E7' '04K0' 'J961'\n",
      " '03B4' '05D5' '04C8' '03J3' '03D5' '05X4' '02N3' '02P1' 'E872' 'P769'\n",
      " '01N1' '01K2' '03I7' 'R688' '06A4' '04E4' '03E4' '04V8' 'G919' '02J4'\n",
      " 'F982' 'P239' '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8'\n",
      " '03N2' '06M7' '02J0' '02Y8' 'A509' '06N3' 'P269' '02I3' 'P399' '02B0'\n",
      " '01D4' 'J150' '03X9' '04X9' '04K4' '01R0' 'P017' '06P5' '04D4' '03Q1'\n",
      " '04D8' 'P250' '03B0' '03G0' '05R9' '02B2' '04I4' '05J8' 'E878' 'Q688'\n",
      " 'Q270' 'K631' '06P3' '03K3' '01R5' '04I3' '01K5' '04R9' '06D4' 'P704'\n",
      " 'J960' '05B3' '02E3' 'Q255' '03E3' 'K768' '03E1' '02K7' 'P070' 'R17'\n",
      " 'Q039' '02C9' 'T524' '04K5' 'D649' '03X4' '02V4' 'Y069' '01M3' 'P000'\n",
      " 'Q911' '06W7' '03J2' 'Q211' '02D7' '02R7' 'Q134' '02E4' 'I442' '01C7'\n",
      " '01Q4' 'P280' '05K9' '01K4' '01A8' 'E870' 'R568' '06K2' 'W80' 'A090'\n",
      " 'P027' '04Y2' 'P599' 'N288' '02Y1' 'P522' '03V4' 'P059' 'P290' 'K567'\n",
      " 'P701' 'M622' 'Q897' '06G9' '06P1' 'P549' 'Q878' 'N189' '06Y8' 'Q210'\n",
      " 'T149' '03M8' '01I2' 'K805' '02K8' '01G8' '01E3' '05K2' '01I9' '02B9'\n",
      " '05K6' 'R090' '02D1' '05G0' '02Y4' '05A5' 'Q431' '03B9' '03Y8' '04Y8'\n",
      " 'J386' 'T426' 'I500' '02R2' '02C7' '02Q5' '02K3' '05M2' 'Q649' '01G3'\n",
      " '06Q7' '04J0' 'P271' 'E031' 'E222' 'N133' 'I898' 'I425' 'P279' '04G7'\n",
      " '04J2' 'R609' '01I7' 'K668' 'P916' '02D5' 'N170' '05G1' 'Q262' 'D471'\n",
      " '04G4' 'E274' 'J041' '05Y3' 'R634' 'Q792' '02R1' '05X5' 'S066' '04G1'\n",
      " '01N3' 'R34' '01J0' 'I615' 'W79' 'Q240' 'I517' 'R161' '06E7' '02X0'\n",
      " '04C9' '03D7' 'D735' 'J969' 'P702' '02W6' '03B2' '02G4' '03X5' '02I7'\n",
      " '06P6' '05A8' 'E86' 'Q794' 'I429' '04W2' '04Y6' '02E2' '03K2' '06D8'\n",
      " '03K9' 'P253' '01P1' 'Q230' '04N2' 'S360' 'S370' '01D5' '02M6' '04X5'\n",
      " '06I7' 'P016' 'Y079' 'P521' 'N258' '03C4' '01R6' '03J4' '02A5' '01R1'\n",
      " '06G7' '05X9' '06D6' '02A8' 'K070' '04Y1' 'B348' '06Y0' 'G931' 'Q288'\n",
      " 'P021' '04B1' '01K7' '01K9' '01N2' '03G4' '05K4' '04R2' '05E4' 'Y848'\n",
      " '05M6' 'Q212' 'R230' 'R068' '05N3' 'E209' 'R13' 'K831' 'P528' 'Q645'\n",
      " '05Y2' 'P003' '05G7' 'G934' '02E1' 'I709' '05K0' '04X4' 'R629' '05P1'\n",
      " '02C8' 'P292' '02R6' 'R579' '01J3' '02W5' '03Q5' '05B0' '05D4' '05W8'\n",
      " 'P711' '05D7' '03A5' 'T818' '05K5' 'Q321' 'G409' '03M3' '05J4' '02H6'\n",
      " 'P832' '06N1' 'I619' '01R7' 'Q043' '06B4' 'J90' 'P550' 'K720' 'P281'\n",
      " 'R092' 'J80' 'Y832' 'P77' 'P071' 'F79' 'Q300' 'R18' 'G319' '04G6' '04E2'\n",
      " 'Q923' 'Q070' 'G709' 'I371' '02N2' 'Q871' 'I351' '01I3' 'R000' 'P298'\n",
      " 'W33' '05M7' '03M6' 'Q248' '03R7' '05M0' '02K9' 'T483' 'P219' 'R278'\n",
      " 'Q369' '06J2' 'J439' '04X0' '01C9' '01B2' 'T740' '03E5' '02L9' '06R9'\n",
      " 'P039' 'P363' 'S009' 'I515' 'Q349' 'K922' 'S269']\n",
      "Column 'econdp_8': [0 3 6 4 1 2 5 7]\n",
      "Column 'econds_8': [0 3 6 7 4 1 2 5]\n",
      "Column 'enicon_8': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' 'N19' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' 'I442' '02Q4' '03B3' '05J9' '01A4'\n",
      " 'D689' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' 'Q913' '03K6' '02G9'\n",
      " '04P8' 'P073' '04B3' 'I615' '07A4' '05Q8' '06J9' '01G9' 'P529' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " 'Q939' '02G1' '02K5' '03P8' '03J1' 'I959' '04W7' 'Q431' 'P285' '05A4'\n",
      " 'Q369' '05P9' '03I3' '06Q3' 'P832' '02K4' 'Q614' 'K902' '04I6' '04D6'\n",
      " '01Q3' '7' 'P051' '02J1' '01J4' '02I1' '04Q8' '05P5' 'P961' '04J1' 'Q766'\n",
      " 'J969' '06Q2' '04Y0' '01J2' '05K7' '03K4' 'Y579' '02K6' '03W8' 'P000'\n",
      " '05I8' '06Y0' '01G4' '03E7' '01I5' '04A4' 'P614' '01G1' '02I2' '06G0'\n",
      " '02J2' 'P209' '02P6' '05Y0' '03G7' 'D696' '05P2' '05Q3' '02W8' 'D728'\n",
      " '03I8' 'Q392' '07Q0' '05W7' '04C6' '03J0' '02J8' '05Q7' '02G7' '06I4'\n",
      " '05I4' '04Q4' '03J9' '05P8' '04N1' '03Q4' '05E8' '06Q7' '07D8' '04G9'\n",
      " '03C7' '06D3' '03K7' '01G0' '02G0' '04P6' '05A0' '05I6' 'R628' '05P6'\n",
      " '06P9' '04P5' '07P7' '06A0' '03G3' 'J81' '02X9' '04M7' '04I7' 'N133'\n",
      " '06Q8' '07Q2' '06K7' 'J219' '04E7' '07P2' '02J9' '03G1' '06X8' '04K6'\n",
      " '06D7' 'K639' '03X0' '04D5' '05Q4' 'Q213' '04H6' 'Q210' 'Q250' '02Y2'\n",
      " '06W7' '05J3' '02I5' '07P0' '06P7' '06G4' 'Y838' '06P8' '01E8' 'I272'\n",
      " 'P960' '07Q7' 'R100' '02X3' '03W1' '03R2' 'I451' 'I639' '02V0' '01G7'\n",
      " '02D4' '06I8' 'R99' '04I2' '02I8' 'P525' '04B4' 'J111' '04I8' '04Q1'\n",
      " '03C9' '04K7' '05G9' 'Y831' 'Q255' 'I64' '05D6' 'K449' '06K6' 'P704'\n",
      " 'Q200' '04D7' 'G934' '04W8' 'I38' 'P90' 'X599' '02Y3' '01P6' 'Q044'\n",
      " 'A419' 'R568' '06P0' '02A3' '03D4' '06P3' 'P059' 'N898' '06I2' '03N1'\n",
      " 'K831' 'Y833' '04W0' '03D1' 'E669' '02W0' 'P220' '06P5' '06G3' '01J9'\n",
      " '06Y3' 'T179' '01E7' '04K0' '03B4' '05D5' '04C8' '03J3' '03D5' '05X4'\n",
      " '02N3' '02P1' '07Q3' 'I517' '01N1' '01K2' '03I7' '06A4' '04E4' '03E4'\n",
      " '04V8' '02J4' 'R278' '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1'\n",
      " '05Y8' 'P072' '03N2' '06M7' '02J0' '02Y8' '06W8' '06N3' '02I3' '02B0'\n",
      " 'P369' '01D4' 'B340' '03X9' '04X9' '04K4' '01R0' '04D4' '03Q1' '04D8'\n",
      " 'P292' '03B0' '03G0' '05R9' '02B2' '04I4' '05J8' 'Q897' 'K219' '03K3'\n",
      " '01R5' '04I3' '01K5' 'P60' '04R9' '06D4' '05B3' '02E3' 'Q211' 'Q999'\n",
      " '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0' 'E873' 'P523' '02C9' 'T749'\n",
      " '04K5' '03X4' '02V4' '01M3' '03J2' '02D7' '02R7' '02E4' '01C7' '01Q4'\n",
      " '05K9' '01K4' '01A8' '06K2' '07G9' 'N179' '04Y2' '07P9' '02Y1' '03V4'\n",
      " 'P025' 'P003' 'K729' '06G9' 'R688' 'E889' '06P1' 'N288' 'I829' 'D619'\n",
      " 'J961' 'E877' '07P6' '06Y8' 'P912' 'E039' 'I709' '03M8' '01I2' 'A090'\n",
      " '02K8' '01G8' '01E3' '05K2' '01I9' '02B9' '05K6' 'Q764' '02D1' '05G0'\n",
      " '02Y4' '05A5' '03B9' '03Y8' '04Y8' 'T481' 'Q249' '06K4' '02R2' '02C7'\n",
      " '02Q5' '02K3' '05M2' '01G3' 'P021' '04J0' 'Q899' '07K5' 'M419' '06I5'\n",
      " '04G7' '04J2' 'P011' 'L989' '01I7' '02D5' '07P5' '05G1' 'Q256' 'J988'\n",
      " 'I469' '04G4' 'J209' 'J050' '05Y3' 'J380' 'I619' '02R1' '05X5' 'S368'\n",
      " '04G1' '01N3' '01J0' '06B4' 'S099' 'E878' '06E7' '02X0' '04C9' '07Q8'\n",
      " 'P269' '03D7' 'J989' 'P293' 'Q048' 'J984' 'Q631' '02W6' '03B2' '02G4'\n",
      " '03X5' '02I7' '06P6' '07D4' '05A8' 'Q423' 'R570' '04W2' '04Y6' '02E2'\n",
      " '03K2' '06D8' '03K9' '01P1' '04N2' '07Y0' 'S378' '01D5' '02M6' '04X5'\n",
      " '06I7' '05P1' '03C4' '01R6' '03J4' '02A5' '01R1' '06G7' '05X9' '06D6'\n",
      " '02A8' '04Y1' 'P027' '04B1' '01K7' '01K9' '01N2' '03G4' '05K4' '04R2'\n",
      " '07K2' '05E4' '05M6' 'Q893' 'Q257' 'K071' '07E2' 'Q169' '05N3' '07Q9'\n",
      " 'P290' 'Q049' 'R601' 'M898' '05Y2' 'D65' '07V8' 'P049' '05G7' 'I510'\n",
      " 'Q749' 'Q219' 'Q433' 'Q410' '02E1' 'E550' 'R34' '05K0' 'R160' '04X4'\n",
      " '02C8' '06E8' '02R6' '01J3' '02W5' '03Q5' 'P219' '05B0' '05D4' 'P280'\n",
      " '05W8' 'P042' '05D7' 'P522' '03A5' 'Y839' '05K5' 'Q390' 'R53' 'P239'\n",
      " 'E880' 'P968' '03M3' '05J4' '02H6' '04D1' 'E274' '01R7' 'K768' 'P071'\n",
      " 'P015' 'D589' 'I614' 'Q909' 'K720' '04G6' '04E2' 'E875' 'E872' 'I424'\n",
      " '02N2' '01I3' 'J986' 'P070' '05M7' '03M6' '07E8' 'P288' '03R7' '05M0'\n",
      " '02K9' 'T509' 'D694' 'P916' 'Q359' '06J2' 'R068' '04X0' '01C9' 'P250'\n",
      " '01B2' 'J180' '07P8' '03E5' '02L9' 'T71' '06R9' 'S090' 'Q439' 'T149']\n",
      "Column 'econdp_9': [0 3 6 4 1 2 5 7 8]\n",
      "Column 'econds_9': [0 3 6 8 4 1 2 5 7]\n",
      "Column 'enicon_9': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' 'P291' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' '08Q2' '02Q4' '03B3' '05J9' '01A4'\n",
      " 'R740' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' '07Q9' '03K6' '02G9'\n",
      " '04P8' 'Q392' '04B3' 'Q211' '07A4' '05Q8' '06J9' '01G9' '08P2' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " 'Q750' '02G1' 'P070' '02K5' '03P8' '03J1' 'P369' '04W7' 'Q250' 'P614'\n",
      " '05A4' 'Q359' '05P9' '03I3' '06Q3' 'G419' '02K4' '08Q6' 'I288' '04I6'\n",
      " '04D6' '01Q3' '7' '02J1' '01J4' '02I1' '04Q8' '05P5' '04J1' '06Q2' '04Y0'\n",
      " '01J2' '05K7' '03K4' 'K562' '02K6' '03W8' '05I8' '06Y0' '01G4' '03E7'\n",
      " '01I5' '04A4' 'P969' '01G1' '02I2' '06G0' '02J2' 'I959' '02P6' '05Y0'\n",
      " '03G7' '07P2' '05P2' '05Q3' '02W8' '08A3' '03I8' 'Q423' '07Q0' '05W7'\n",
      " '04C6' '03J0' '02J8' '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8'\n",
      " '04N1' '03Q4' '05E8' '06Q7' '07D8' '04G9' '03C7' '06D3' '03K7' '01G0'\n",
      " '02G0' '04P6' '05A0' '05I6' '05P6' '06P9' '04P5' '07P7' '06A0' '03G3'\n",
      " 'D696' '02X9' '04M7' '04I7' '06Q8' '07Q2' '06K7' 'J960' '04E7' '02J9'\n",
      " '03G1' '06X8' '04K6' '06D7' 'K409' '03X0' '04D5' '05Q4' 'Q333' '04H6'\n",
      " '02Y2' '06W7' '05J3' '02I5' '07P0' '06P7' '06G4' 'K550' '06P8' '01E8'\n",
      " 'M329' 'Q790' '07P6' '07Q7' '02X3' '03W1' '07P5' '03R2' '8' '08Q9' '02V0'\n",
      " '01G7' '07P3' '02D4' '06I8' '04I2' '02I8' '04B4' '04I8' '04Q1' '03C9'\n",
      " '04K7' '05G9' 'Q251' 'Q262' '05D6' 'P278' '08Q7' '06K6' '07Q3' 'Q898'\n",
      " '04D7' '04W8' '08P9' 'D70' '07Q4' '02Y3' '01P6' 'Q231' 'I620' '06P0'\n",
      " 'P524' '02A3' '03D4' '06P3' 'S730' '06I2' '03N1' 'J81' 'T814' '04W0'\n",
      " '03D1' 'D561' '02W0' '06P5' '06G3' '01J9' '06Y3' '08Q3' 'W80' '01E7'\n",
      " '04K0' '03B4' '05D5' '04C8' '03J3' '03D5' '05X4' '02N3' '02P1' '08D6'\n",
      " '01N1' '01K2' '03I7' 'I872' '06A4' '04E4' '03E4' '04V8' '02J4' 'F89'\n",
      " '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8' 'Q764' '03N2'\n",
      " '06M7' '02J0' '02Y8' '06W8' '06N3' '02I3' '02B0' '01D4' 'A410' '03X9'\n",
      " '04X9' '04K4' '01R0' '04D4' '03Q1' '04D8' '03B0' '03G0' '05R9' '02B2'\n",
      " '04I4' '05J8' 'R02' 'E889' '03K3' '01R5' '04I3' '01K5' '04R9' '06D4'\n",
      " '05B3' '02E3' 'K831' '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0' '02C9'\n",
      " '07Y0' '04K5' '03X4' '02V4' '01M3' '03J2' 'P072' '02D7' '02R7' 'I898'\n",
      " '02E4' '01C7' '01Q4' '05K9' '01K4' '01A8' '06K2' '07G9' '04Y2' '07P9'\n",
      " 'E878' '02Y1' '03V4' 'P780' '07I5' '08P5' 'I99' '06G9' 'R55' 'P288'\n",
      " '06P1' '07P8' 'I519' '06Y8' '07Q6' 'P90' '08X5' '03M8' '01I2' '02K8'\n",
      " '01G8' '01E3' '05K2' '01I9' '02B9' '05K6' 'Q749' '02D1' '05G0' 'N390'\n",
      " '02Y4' '05A5' '03B9' '03Y8' '04Y8' 'T403' 'Q210' '06K4' '02R2' '02C7'\n",
      " '02Q5' '02K3' 'Q203' '05M2' 'K729' '01G3' 'A401' 'P832' '04J0' 'I279'\n",
      " '08P8' '08D8' '07K5' 'G824' '06I5' '08A4' 'P027' '04G7' '04J2' 'P364'\n",
      " '01I7' '02D5' '05G1' 'Q893' '04G4' 'J041' '05Y3' 'Q256' '02R1' '05X5'\n",
      " '04G1' '01N3' '01J0' '06B4' 'Q248' '06E7' '02X0' '04C9' '07Q8' 'P704'\n",
      " 'B182' '03D7' 'E039' 'Q043' '02W6' '03B2' '02G4' '03X5' '02I7' '06P6'\n",
      " '07D4' '05A8' 'Q528' '06E1' '04W2' '04Y6' '02E2' 'Q130' '03K2' '06D8'\n",
      " '03K9' '01P1' '04N2' 'S360' '01D5' 'P010' '02M6' '04X5' '06I7' '05P1'\n",
      " '03C4' '01R6' '03J4' '02A5' '01R1' '06G7' '05X9' '06D6' '02A8' '04Y1'\n",
      " 'Q246' 'G932' 'P073' 'Q897' '04B1' '01K7' '01K9' '01N2' '03G4' '05K4'\n",
      " '04R2' '07K2' '05E4' '05M6' 'A419' '07E2' 'Q111' '05N3' '08E8' 'R18'\n",
      " 'P60' 'I615' '05Y2' '07V8' '05G7' 'P285' 'R568' 'Q602' '02E1' 'Q780'\n",
      " '05K0' '04X4' 'P548' '02C8' '06E8' '08I5' '02R6' 'R579' '01J3' '02W5'\n",
      " '03Q5' 'P209' '05B0' '05D4' 'P229' '05W8' 'H544' 'R068' '05D7' '08P0'\n",
      " '03A5' '05K5' 'P523' '08Q0' '03M3' 'R688' '05J4' '02H6' '04D1' '01R7'\n",
      " 'N289' 'I471' '08I6' 'Q212' '07J9' 'K922' 'I500' '04G6' '04E2' 'J80'\n",
      " 'P081' '02N2' '01I3' 'R629' 'P279' '05M7' '03M6' '07E8' '03R7' '05M0'\n",
      " '02K9' 'P043' '08P6' 'P809' 'G919' '06J2' 'E274' 'A415' '04X0' '01C9'\n",
      " '01B2' 'D649' 'D728' '03E5' '02L9' 'Y20' '06R9' 'P023' 'P293' 'Y34'\n",
      " 'Q134']\n",
      "Column 'econdp_10': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'econds_10': [0 3 6 4 1 2 5 8 9 7]\n",
      "Column 'enicon_10': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' '08P3' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' '08Q2' '02Q4' '03B3' '05J9' '01A4'\n",
      " 'K720' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' '07Q9' '03K6' '02G9'\n",
      " '04P8' 'K228' '04B3' '08B3' '07A4' '05Q8' '06J9' '01G9' '08P2' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " 'Q043' '02G1' '07P3' '02K5' '03P8' '03J1' '05P5' '04W7' '08I2' '07P7'\n",
      " '05A4' '06Q2' '05P9' '03I3' '06Q3' 'K729' '02K4' '08Q6' '9' '04I6' '04D6'\n",
      " '01Q3' '7' '02J1' '01J4' '02I1' '04Q8' '04J1' 'Q233' '04Y0' '01J2' '05K7'\n",
      " '03K4' 'K639' '02K6' '03W8' '05I8' '06Y0' '01G4' '03E7' '01I5' '04A4'\n",
      " 'P015' '01G1' '02I2' '06G0' '02J2' 'P60' '02P6' '05Y0' '03G7' '07P2'\n",
      " '05P2' '05Q3' '02W8' '08A3' '03I8' '07Q0' '05W7' '04C6' '03J0' '02J8'\n",
      " '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8' '04N1' '03Q4' '05E8'\n",
      " '06Q7' '07D8' '04G9' '03C7' '06D3' '03K7' '01G0' '02G0' '04P6' '05A0'\n",
      " '05I6' '09K7' '05P6' '06P9' '04P5' '06A0' '03G3' '08J8' '02X9' '04M7'\n",
      " '04I7' '06Q8' '07Q2' '06K7' '04E7' '02J9' '03G1' '06X8' '04K6' '06D7'\n",
      " '03X0' '04D5' '05Q4' '04H6' '02Y2' '06W7' '05J3' '02I5' '07P0' '06P7'\n",
      " '06G4' '09A0' '06P8' '01E8' 'P044' '08Q7' '07P6' '07Q7' '02X3' '03W1'\n",
      " '07P5' '03R2' '8' '08Q9' '02V0' '01G7' '02D4' '06I8' '04I2' '02I8' '04B4'\n",
      " '04I8' '04Q1' '03C9' '04K7' '05G9' '09Q2' '05D6' 'J969' '06K6' '07Q3'\n",
      " 'R090' '04D7' '04W8' '08P9' 'P704' '07Q4' '02Y3' '01P6' 'Q549' 'Q878'\n",
      " '06P0' '09Q7' '02A3' '03D4' '06P3' 'X599' '06I2' '03N1' 'J960' '04W0'\n",
      " '03D1' '02W0' '06P5' '06G3' '01J9' '06Y3' '08Q3' '01E7' '04K0' '03B4'\n",
      " '05D5' '04C8' '03J3' '03D5' '05X4' '02N3' '02P1' '08D6' '01N1' '01K2'\n",
      " '03I7' '09D8' '06A4' '04E4' '03E4' '04V8' '02J4' '09Q0' '01E5' '04G0'\n",
      " '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8' 'Q000' '03N2' '06M7' '02J0'\n",
      " '02Y8' '06W8' '06N3' '02I3' '02B0' 'P219' '01D4' 'N19' '03X9' '04X9'\n",
      " '04K4' '01R0' '04D4' '03Q1' '04D8' '03B0' '03G0' '05R9' '02B2' '04I4'\n",
      " '05J8' 'J961' '09P2' '03K3' '01R5' '04I3' '01K5' 'R34' '04R9' '06D4'\n",
      " '05B3' '02E3' 'R13' '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0' '02C9'\n",
      " '07Y0' '04K5' '03X4' '02V4' '01M3' '03J2' '02D7' '02R7' '02E4' '01C7'\n",
      " '01Q4' '05K9' '01K4' '01A8' '06K2' '07G9' 'J860' '04Y2' '07P9' '02Y1'\n",
      " '03V4' 'D689' '07I5' '08P5' 'N179' '06G9' 'P022' 'Q899' '06P1' '07P8'\n",
      " 'J980' '06Y8' '07Q6' '08X5' '03M8' '01I2' '02K8' '01G8' '01E3' '05K2'\n",
      " '01I9' '02B9' '05K6' '09Q6' '02D1' '05G0' '02Y4' '05A5' '03B9' '03Y8'\n",
      " '04Y8' '06K4' '02R2' '02C7' '02Q5' '02K3' '05M2' '01G3' 'Q250' '04J0'\n",
      " '08P0' '08P8' '08D8' '07K5' 'Q02' '06I5' '08A4' '04G7' '04J2' '01I7'\n",
      " 'N288' '08N1' '02D5' '05G1' 'P285' '04G4' 'I469' '06J0' '05Y3' '02R1'\n",
      " '05X5' '04G1' '01N3' '01J0' '06B4' 'Q204' '06E7' '02X0' '04C9' '07Q8'\n",
      " 'I288' '03D7' 'P073' '02W6' '03B2' '02G4' '03X5' '02I7' '06P6' '07D4'\n",
      " '05A8' 'P209' '06E1' '04W2' '04Y6' '02E2' '03K2' '06D8' '03K9' '01P1'\n",
      " '04N2' 'T141' '01D5' 'P038' '02M6' '04X5' '06I7' '05P1' '03C4' '01R6'\n",
      " '03J4' '02A5' '01R1' '06G7' '05X9' '06D6' '02A8' '04Y1' '04B1' '01K7'\n",
      " '01K9' '01N2' '03G4' '05K4' '04R2' '07K2' '05E4' '05M6' '07E2' 'Q210'\n",
      " '05N3' '08E8' '08J9' '05Y2' '07V8' '05G7' 'K768' '02E1' 'M844' '05K0'\n",
      " '04X4' 'E875' '02C8' '06E8' '08I5' '02R6' 'R688' '01J3' '02W5' '03Q5'\n",
      " '05B0' '05D4' 'P251' 'P523' '05W8' 'Q668' '05D7' '03A5' '05K5' 'Q315'\n",
      " 'P522' 'D696' 'I959' '08Q0' '03M3' '05J4' '02H6' '04D1' '01R7' 'P290'\n",
      " 'E274' '08I6' '07J9' '04G6' '04E2' 'P701' '02N2' '01I3' 'F79' '05M7'\n",
      " '03M6' '07E8' '03R7' '05M0' '02K9' '09J1' '08P6' 'P134' '08J2' '06J2'\n",
      " 'Q249' '04X0' '01C9' '01B2' '03E5' '02L9' '09Y2' '06R9' '09Y3']\n",
      "Column 'econdp_11': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'econds_11': [0 3 6 4 1 2 5 7 9 8]\n",
      "Column 'enicon_11': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' '08P3' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' '08Q2' '02Q4' '03B3' '05J9' '01A4'\n",
      " '10P3' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' '07Q9' '03K6' '02G9'\n",
      " '04P8' 'Q410' '04B3' '08B3' '07A4' '05Q8' '06J9' '01G9' '08P2' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " '09Q9' '02G1' '07P3' '02K5' '03P8' '03J1' '05P5' '04W7' '08I2' '07P7'\n",
      " '05A4' '06Q2' '05P9' '03I3' '06Q3' 'P285' '02K4' '08Q6' '9' '04I6' '04D6'\n",
      " '01Q3' '7' '02J1' '01J4' '02I1' '04Q8' '04J1' '08Q0' '04Y0' '01J2' '05K7'\n",
      " '03K4' 'H351' '02K6' '03W8' '05I8' '06Y0' '01G4' '03E7' '01I5' '04A4'\n",
      " '07D8' '01G1' '02I2' '06G0' '02J2' '09Q2' '02P6' '05Y0' '03G7' '07P2'\n",
      " '05P2' '05Q3' '02W8' '08A3' '03I8' '08P7' '07Q0' '05W7' '04C6' '03J0'\n",
      " '02J8' '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8' '04N1' '03Q4'\n",
      " '05E8' '06Q7' '04G9' '03C7' '06D3' '03K7' '01G0' '02G0' '04P6' '05A0'\n",
      " '05I6' '09K7' '05P6' '06P9' '04P5' '06A0' '03G3' '08J8' '02X9' '04M7'\n",
      " '04I7' '06Q8' '07Q2' '06K7' '04E7' '02J9' '03G1' '06X8' '04K6' '06D7'\n",
      " '03X0' '04D5' '05Q4' '04H6' '02Y2' '06W7' '05J3' '02I5' '07P0' '06P7'\n",
      " '06G4' '09A0' '06P8' '01E8' '08P0' '08Q7' '07P6' '07Q7' '02X3' '03W1'\n",
      " '07P5' '03R2' '8' '08Q9' '02V0' '01G7' '02D4' '06I8' '04I2' '02I8' '04B4'\n",
      " '04I8' '04Q1' '03C9' '04K7' '05G9' '05D6' '06K6' '07Q3' '04D7' '04W8'\n",
      " '08P9' '07Q4' '02Y3' '01P6' 'D696' '06P0' '09Q7' '02A3' '03D4' '06P3'\n",
      " '06I2' '03N1' 'N179' '04W0' '03D1' '02W0' '06P5' '06G3' '01J9' '06Y3'\n",
      " '08Q3' '01E7' '04K0' '03B4' '05D5' '04C8' '03J3' '03D5' '05X4' '02N3'\n",
      " '02P1' '08D6' '01N1' '01K2' '03I7' '09D8' '06A4' '04E4' '03E4' '04V8'\n",
      " '02J4' '09Q0' '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8'\n",
      " '03N2' '06M7' '02J0' '02Y8' '06W8' '06N3' '02I3' '02B0' '01D4' 'K768'\n",
      " '03X9' '04X9' '04K4' '01R0' '04D4' '03Q1' '04D8' '03B0' '03G0' '05R9'\n",
      " '02B2' '04I4' '05J8' '09P2' '03K3' '01R5' '04I3' '01K5' '09P5' '04R9'\n",
      " '06D4' '05B3' '02E3' '10Q3' '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0'\n",
      " '02C9' '07Y0' '04K5' '03X4' '02V4' '01M3' '03J2' '02D7' '02R7' '02E4'\n",
      " '01C7' '01Q4' '05K9' '01K4' '01A8' '06K2' '07G9' 'D689' '04Y2' '07P9'\n",
      " '02Y1' '03V4' 'K746' '07I5' '08P5' '10P6' '06G9' 'P059' '06P1' '07P8'\n",
      " 'R068' '06Y8' '07Q6' '08X5' '03M8' '01I2' '02K8' '01G8' '01E3' '05K2'\n",
      " '01I9' '02B9' '05K6' '09Q6' '02D1' '05G0' '02Y4' '05A5' '03B9' '03Y8'\n",
      " '04Y8' '06K4' '02R2' '02C7' '02Q5' '02K3' '05M2' '01G3' '08D8' '04J0'\n",
      " '08P8' '07K5' '10J2' '06I5' '08A4' '04G7' '04J2' '01I7' 'P960' '08N1'\n",
      " '02D5' '05G1' 'Y442' '04G4' 'R001' '06J0' '05Y3' '02R1' '05X5' '04G1'\n",
      " '01N3' '01J0' '06B4' 'Q259' '06E7' '02X0' '04C9' '07Q8' '03D7' 'Q909'\n",
      " '02W6' '03B2' '02G4' '03X5' '02I7' '06P6' '07D4' '05A8' '06E1' '04W2'\n",
      " '04Y6' '02E2' '03K2' '06D8' '03K9' '01P1' '04N2' '10X9' '01D5' 'P271'\n",
      " '02M6' '04X5' '06I7' '05P1' '03C4' '01R6' '03J4' '02A5' '01R1' '06G7'\n",
      " '05X9' '06D6' '02A8' '04Y1' '04B1' '01K7' '01K9' '01N2' '03G4' '05K4'\n",
      " '04R2' '07K2' '05E4' '05M6' '07E2' 'P369' '05N3' '08E8' '08J9' '05Y2'\n",
      " '07V8' '05G7' 'R18' '02E1' '09J9' '05K0' '04X4' '09P8' '02C8' '06E8'\n",
      " '08I5' '02R6' 'P780' '01J3' '02W5' '03Q5' '05B0' '05D4' 'P072' 'P027'\n",
      " '05W8' '10Q9' 'I959' '05D7' '03A5' '05K5' '08E7' 'P832' '03M3' '05J4'\n",
      " '02H6' '04D1' '01R7' 'R579' '10I4' 'Q211' '08I6' '07J9' '08Q8' 'N19'\n",
      " '04G6' '04E2' '10A0' '02N2' '01I3' 'P614' '05M7' '03M6' '07E8' '03R7'\n",
      " '05M0' '02K9' '09J1' '08P6' '08J2' '06J2' '09A4' '04X0' '01C9' '01B2'\n",
      " 'K831' 'P071' '03E5' '02L9' '09Y2' '06R9' '09Y3']\n",
      "Column 'econdp_12': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'econds_12': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'enicon_12': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' '08P3' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' '08Q2' '02Q4' '03B3' '05J9' '01A4'\n",
      " '10P3' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' '07Q9' '03K6' '02G9'\n",
      " '04P8' 'Q423' '04B3' '08B3' '07A4' '05Q8' '06J9' '01G9' '08P2' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " '09Q9' '02G1' '07P3' '02K5' '03P8' '03J1' '05P5' '04W7' '08I2' '07P7'\n",
      " '05A4' '06Q2' '05P9' '03I3' '06Q3' '11P3' '02K4' '08Q6' '9' '04I6' '04D6'\n",
      " '01Q3' '7' '02J1' '01J4' '02I1' '04Q8' '04J1' '08Q0' '04Y0' '01J2' '05K7'\n",
      " '03K4' 'I469' '02K6' '03W8' '05I8' '06Y0' '01G4' '03E7' '01I5' '04A4'\n",
      " '07D8' '01G1' '02I2' '06G0' '02J2' '09Q2' '02P6' '05Y0' '03G7' '07P2'\n",
      " '05P2' '05Q3' '02W8' '08A3' '03I8' '08P7' '07Q0' '05W7' '04C6' '03J0'\n",
      " '02J8' '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8' '04N1' '03Q4'\n",
      " '05E8' '06Q7' '04G9' '03C7' '06D3' '03K7' '01G0' '02G0' '04P6' '05A0'\n",
      " '05I6' '09K7' '05P6' '06P9' '04P5' '06A0' '03G3' '08J8' '02X9' '04M7'\n",
      " '04I7' '06Q8' '07Q2' '06K7' '04E7' '02J9' '03G1' '06X8' '04K6' '06D7'\n",
      " '03X0' '04D5' '05Q4' '04H6' '02Y2' '06W7' '05J3' '02I5' '07P0' '06P7'\n",
      " '06G4' '09A0' '06P8' '01E8' '08P0' '08Q7' '07P6' '07Q7' '02X3' '03W1'\n",
      " '07P5' '03R2' '8' '08Q9' '02V0' '01G7' '02D4' '06I8' '04I2' '02I8' '04B4'\n",
      " '04I8' '04Q1' '03C9' '04K7' '05G9' '05D6' '06K6' '07Q3' '04D7' '04W8'\n",
      " '08P9' '07Q4' '02Y3' '01P6' '11Q9' '06P0' '09Q7' '02A3' '03D4' '06P3'\n",
      " '06I2' '03N1' '10Q2' '04W0' '03D1' '02W0' '06P5' '06G3' '01J9' '06Y3'\n",
      " '08Q3' '01E7' '04K0' '03B4' '05D5' '04C8' '03J3' '03D5' '05X4' '02N3'\n",
      " '02P1' '08D6' '01N1' '01K2' '03I7' '09D8' '06A4' '04E4' '03E4' '04V8'\n",
      " '02J4' '09Q0' '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8'\n",
      " '03N2' '06M7' '02J0' '02Y8' '06W8' '06N3' '02I3' '02B0' '01D4' 'I429'\n",
      " '03X9' '04X9' '04K4' '01R0' '04D4' '03Q1' '04D8' '03B0' '03G0' '05R9'\n",
      " '02B2' '04I4' '05J8' '09P2' '03K3' '01R5' '04I3' '01K5' '09P5' '04R9'\n",
      " '06D4' '05B3' '02E3' '10Q3' '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0'\n",
      " '02C9' '07Y0' '04K5' '03X4' '02V4' '01M3' '03J2' '02D7' '02R7' '02E4'\n",
      " '01C7' '01Q4' '05K9' '01K4' '01A8' '06K2' '07G9' 'Q249' '04Y2' '07P9'\n",
      " '02Y1' '03V4' '10P0' '07I5' '08P5' '10P6' '06G9' 'P072' '06P1' '07P8'\n",
      " '06Y8' '07Q6' '08X5' '03M8' '01I2' '02K8' '01G8' '01E3' '05K2' '01I9'\n",
      " '02B9' '05K6' '09Q6' '02D1' '05G0' '02Y4' '05A5' '03B9' '03Y8' '04Y8'\n",
      " '06K4' '02R2' '02C7' '02Q5' '02K3' '05M2' '01G3' '08D8' '04J0' '08P8'\n",
      " '07K5' '10J2' '06I5' '08A4' '04G7' '04J2' '01I7' 'I959' '08N1' '02D5'\n",
      " '05G1' 'D695' '04G4' 'I441' '06J0' '05Y3' '02R1' '05X5' '04G1' '01N3'\n",
      " '01J0' '06B4' 'Q230' '06E7' '02X0' '04C9' '07Q8' '03D7' 'P271' '02W6'\n",
      " '03B2' '02G4' '03X5' '02I7' '06P6' '07D4' '05A8' '06E1' '04W2' '04Y6'\n",
      " '02E2' '03K2' '06D8' '03K9' '01P1' '04N2' '10X9' '01D5' 'A490' '02M6'\n",
      " '04X5' '06I7' '05P1' '03C4' '01R6' '03J4' '02A5' '01R1' '06G7' '05X9'\n",
      " '06D6' '02A8' '04Y1' '04B1' '01K7' '01K9' '01N2' '03G4' '05K4' '04R2'\n",
      " '07K2' '05E4' '05M6' '07E2' '05N3' '08E8' '08J9' '05Y2' '07V8' '05G7'\n",
      " 'A090' '02E1' '09J9' '05K0' '04X4' '09P8' '02C8' '06E8' '08I5' '02R6'\n",
      " '01J3' '02W5' '03Q5' '05B0' '05D4' '11P6' 'N289' '05W8' '10Q9' '06K5'\n",
      " '05D7' '03A5' '05K5' '08E7' '03M3' '05J4' '02H6' '04D1' '01R7' '08Q8'\n",
      " '10I4' '11A0' '08I6' '07J9' 'P251' '04G6' '04E2' '10A0' '02N2' '01I3'\n",
      " '05M7' '03M6' '07E8' '03R7' '05M0' '02K9' '09J1' '08P6' '08J2' '06J2'\n",
      " '09A4' 'Q210' '04X0' '01C9' '01B2' '09K5' '03E5' '02L9' '09Y2' '06R9'\n",
      " '09Y3']\n",
      "Column 'econdp_13': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'econds_13': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'enicon_13': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' '08P3' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' '08Q2' '02Q4' '03B3' '05J9' '01A4'\n",
      " '10P3' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' '07Q9' '03K6' '02G9'\n",
      " '04P8' '10P0' '04B3' '08B3' '07A4' '05Q8' '06J9' '01G9' '08P2' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " '09Q9' '02G1' '07P3' '02K5' '03P8' '03J1' '05P5' '04W7' '08I2' '07P7'\n",
      " '05A4' '06Q2' '05P9' '03I3' '06Q3' '11P3' '02K4' '08Q6' '9' '04I6' '04D6'\n",
      " '01Q3' '7' '02J1' '01J4' '02I1' '04Q8' '04J1' '08Q0' '04Y0' '01J2' '05K7'\n",
      " '03K4' '09E8' '02K6' '03W8' '05I8' '06Y0' '01G4' '03E7' '01I5' '04A4'\n",
      " '07D8' '01G1' '02I2' '06G0' '02J2' '09Q2' '02P6' '05Y0' '03G7' '07P2'\n",
      " '05P2' '05Q3' '02W8' '08A3' '03I8' '08P7' '07Q0' '05W7' '04C6' '03J0'\n",
      " '02J8' '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8' '04N1' '03Q4'\n",
      " '05E8' '06Q7' '04G9' '03C7' '06D3' '03K7' '01G0' '02G0' '04P6' '05A0'\n",
      " '05I6' '09K7' '05P6' '06P9' '04P5' '06A0' '03G3' '08J8' '02X9' '04M7'\n",
      " '04I7' '06Q8' '07Q2' '06K7' '04E7' '02J9' '03G1' '06X8' '04K6' '06D7'\n",
      " '03X0' '04D5' '05Q4' '04H6' '02Y2' '06W7' '05J3' '02I5' '07P0' '06P7'\n",
      " '06G4' '09A0' '06P8' '01E8' '08P0' '08Q7' '07P6' '07Q7' '02X3' '03W1'\n",
      " '07P5' '03R2' '8' '08Q9' '02V0' '01G7' '02D4' '06I8' '04I2' '02I8' '04B4'\n",
      " '04I8' '04Q1' '03C9' '04K7' '05G9' '05D6' '06K6' '07Q3' '04D7' '04W8'\n",
      " '08P9' '07Q4' '02Y3' '01P6' '11Q9' '06P0' '09Q7' '02A3' '03D4' '06P3'\n",
      " '06I2' '03N1' '10Q2' '04W0' '03D1' '02W0' '06P5' '06G3' '01J9' '06Y3'\n",
      " '08Q3' '01E7' '04K0' '03B4' '05D5' '04C8' '03J3' '03D5' '05X4' '02N3'\n",
      " '02P1' '08D6' '01N1' '01K2' '03I7' '09D8' '06A4' '04E4' '03E4' '04V8'\n",
      " '02J4' '09Q0' '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8'\n",
      " '03N2' '06M7' '02J0' '02Y8' '06W8' '06N3' '02I3' '02B0' '01D4' '11B3'\n",
      " '03X9' '04X9' '04K4' '01R0' '04D4' '03Q1' '04D8' '03B0' '03G0' '05R9'\n",
      " '02B2' '04I4' '05J8' '09P2' '03K3' '01R5' '04I3' '01K5' '09P5' '04R9'\n",
      " '06D4' '05B3' '02E3' '10Q3' '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0'\n",
      " '02C9' '07Y0' '04K5' '03X4' '02V4' '01M3' '03J2' '02D7' '02R7' '02E4'\n",
      " '01C7' '01Q4' '05K9' '01K4' '01A8' '06K2' '07G9' '10P2' '04Y2' '07P9'\n",
      " '02Y1' '03V4' '07I5' '08P5' '10P6' '06G9' '09P0' '06P1' '07P8' '06Y8'\n",
      " '07Q6' '08X5' '03M8' '01I2' '02K8' '01G8' '01E3' '05K2' '01I9' '02B9'\n",
      " '05K6' '09Q6' '02D1' '05G0' '02Y4' '05A5' '03B9' '03Y8' '04Y8' '06K4'\n",
      " '02R2' '02C7' '02Q5' '02K3' '05M2' '01G3' '08D8' '04J0' '08P8' '07K5'\n",
      " '10J2' '06I5' '08A4' '04G7' '04J2' '01I7' '08N1' '02D5' '05G1' '12Q2'\n",
      " '04G4' '11Q2' '06J0' '05Y3' '02R1' '05X5' '04G1' '01N3' '01J0' '06B4'\n",
      " '11Q4' '06E7' '02X0' '04C9' '07Q8' '03D7' '02W6' '03B2' '02G4' '03X5'\n",
      " '02I7' '06P6' '07D4' '05A8' '06E1' '04W2' '04Y6' '02E2' '03K2' '06D8'\n",
      " '03K9' '01P1' '04N2' '10X9' '01D5' 'K768' '02M6' '04X5' '06I7' '05P1'\n",
      " '03C4' '01R6' '03J4' '02A5' '01R1' '06G7' '05X9' '06D6' '02A8' '04Y1'\n",
      " '04B1' '01K7' '01K9' '01N2' '03G4' '05K4' '04R2' '07K2' '05E4' '05M6'\n",
      " '07E2' '05N3' '08E8' '08J9' '05Y2' '07V8' '05G7' '02E1' '09J9' '05K0'\n",
      " '04X4' '09P8' '02C8' '06E8' '08I5' '02R6' '01J3' '02W5' '03Q5' '05B0'\n",
      " '05D4' '11P6' '05W8' '10Q9' '06K5' '05D7' '03A5' '05K5' '08E7' '03M3'\n",
      " '05J4' '02H6' '04D1' '01R7' '08Q8' '10I4' '11A0' '08I6' '07J9' 'P968'\n",
      " '04G6' '04E2' '10A0' '02N2' '01I3' '05M7' '03M6' '07E8' '03R7' '05M0'\n",
      " '02K9' '09J1' '08P6' '08J2' '06J2' '09A4' 'Q250' '04X0' '01C9' '01B2'\n",
      " '11P2' '09K5' '03E5' '02L9' '09Y2' '06R9' '09Y3']\n",
      "Column 'econdp_14': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'econds_14': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'enicon_14': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' '08P3' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' '08Q2' '02Q4' '03B3' '05J9' '01A4'\n",
      " '10P3' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' '07Q9' '03K6' '02G9'\n",
      " '04P8' '10P0' '04B3' '08B3' '07A4' '05Q8' '06J9' '01G9' '08P2' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " '09Q9' '02G1' '07P3' '02K5' '03P8' '03J1' '05P5' '04W7' '08I2' '07P7'\n",
      " '05A4' '06Q2' '05P9' '03I3' '06Q3' '11P3' '02K4' '08Q6' '9' '04I6' '04D6'\n",
      " '01Q3' '7' '02J1' '01J4' '02I1' '04Q8' '04J1' '08Q0' '04Y0' '01J2' '05K7'\n",
      " '03K4' '09E8' '02K6' '03W8' '05I8' '06Y0' '01G4' '03E7' '01I5' '04A4'\n",
      " '07D8' '01G1' '02I2' '06G0' '02J2' '09Q2' '02P6' '05Y0' '03G7' '07P2'\n",
      " '05P2' '05Q3' '02W8' '08A3' '03I8' '08P7' '07Q0' '05W7' '04C6' '03J0'\n",
      " '02J8' '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8' '04N1' '03Q4'\n",
      " '05E8' '06Q7' '04G9' '03C7' '06D3' '03K7' '01G0' '02G0' '04P6' '05A0'\n",
      " '05I6' '09K7' '05P6' '06P9' '04P5' '06A0' '03G3' '08J8' '02X9' '04M7'\n",
      " '04I7' '06Q8' '07Q2' '06K7' '04E7' '02J9' '03G1' '06X8' '04K6' '06D7'\n",
      " '03X0' '04D5' '05Q4' '04H6' '02Y2' '06W7' '05J3' '02I5' '07P0' '06P7'\n",
      " '06G4' '09A0' '06P8' '01E8' '08P0' '08Q7' '07P6' '07Q7' '02X3' '03W1'\n",
      " '07P5' '03R2' '8' '08Q9' '02V0' '01G7' '02D4' '06I8' '04I2' '02I8' '04B4'\n",
      " '04I8' '04Q1' '03C9' '04K7' '05G9' '05D6' '06K6' '07Q3' '04D7' '04W8'\n",
      " '08P9' '07Q4' '02Y3' '01P6' '11Q9' '06P0' '09Q7' '02A3' '03D4' '06P3'\n",
      " '06I2' '03N1' '10Q2' '04W0' '03D1' '02W0' '06P5' '06G3' '01J9' '06Y3'\n",
      " '08Q3' '01E7' '04K0' '03B4' '05D5' '04C8' '03J3' '03D5' '05X4' '02N3'\n",
      " '02P1' '08D6' '01N1' '01K2' '03I7' '09D8' '06A4' '04E4' '03E4' '04V8'\n",
      " '02J4' '09Q0' '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8'\n",
      " '03N2' '06M7' '02J0' '02Y8' '06W8' '06N3' '02I3' '02B0' '01D4' '11B3'\n",
      " '03X9' '04X9' '04K4' '01R0' '04D4' '03Q1' '04D8' '03B0' '03G0' '05R9'\n",
      " '02B2' '04I4' '05J8' '09P2' '03K3' '01R5' '04I3' '01K5' '09P5' '04R9'\n",
      " '06D4' '05B3' '02E3' '10Q3' '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0'\n",
      " '02C9' '07Y0' '04K5' '03X4' '02V4' '01M3' '03J2' '02D7' '02R7' '02E4'\n",
      " '01C7' '01Q4' '05K9' '01K4' '01A8' '06K2' '07G9' '10P2' '04Y2' '07P9'\n",
      " '02Y1' '03V4' '07I5' '08P5' '10P6' '06G9' '09P0' '06P1' '07P8' '06Y8'\n",
      " '07Q6' '08X5' '03M8' '01I2' '02K8' '01G8' '01E3' '05K2' '01I9' '02B9'\n",
      " '05K6' '09Q6' '02D1' '05G0' '02Y4' '05A5' '03B9' '03Y8' '04Y8' '06K4'\n",
      " '02R2' '02C7' '02Q5' '02K3' '05M2' '01G3' '08D8' '04J0' '08P8' '07K5'\n",
      " '10J2' '06I5' '08A4' '04G7' '04J2' '01I7' '08N1' '02D5' '05G1' '12Q2'\n",
      " '04G4' '11Q2' '06J0' '05Y3' '02R1' '05X5' '04G1' '01N3' '01J0' '06B4'\n",
      " '11Q4' '06E7' '02X0' '04C9' '07Q8' '03D7' '02W6' '03B2' '02G4' '03X5'\n",
      " '02I7' '06P6' '07D4' '05A8' '06E1' '04W2' '04Y6' '02E2' '03K2' '06D8'\n",
      " '03K9' '01P1' '04N2' '10X9' '01D5' '11P0' '02M6' '04X5' '06I7' '05P1'\n",
      " '03C4' '01R6' '03J4' '02A5' '01R1' '06G7' '05X9' '06D6' '02A8' '04Y1'\n",
      " '04B1' '01K7' '01K9' '01N2' '03G4' '05K4' '04R2' '07K2' '05E4' '05M6'\n",
      " '07E2' '05N3' '08E8' '08J9' '05Y2' '07V8' '05G7' '02E1' '09J9' '05K0'\n",
      " '04X4' '09P8' '02C8' '06E8' '08I5' '02R6' '01J3' '02W5' '03Q5' '05B0'\n",
      " '05D4' '11P6' '05W8' '10Q9' '06K5' '05D7' '03A5' '05K5' '08E7' '03M3'\n",
      " '05J4' '02H6' '04D1' '01R7' '08Q8' '10I4' '11A0' '08I6' '07J9' '11Q3'\n",
      " '04G6' '04E2' '10A0' '02N2' '01I3' '05M7' '03M6' '07E8' '03R7' '05M0'\n",
      " '02K9' '09J1' '08P6' '08J2' '06J2' '09A4' 'Q913' '04X0' '01C9' '01B2'\n",
      " '11P2' '09K5' '03E5' '02L9' '09Y2' '06R9' '09Y3']\n",
      "Column 'econdp_15': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'econds_15': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'enicon_15': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' '08P3' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' '08Q2' '02Q4' '03B3' '05J9' '01A4'\n",
      " '10P3' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' '07Q9' '03K6' '02G9'\n",
      " '04P8' '10P0' '04B3' '08B3' '07A4' '05Q8' '06J9' '01G9' '08P2' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " '09Q9' '02G1' '07P3' '02K5' '03P8' '03J1' '05P5' '04W7' '08I2' '07P7'\n",
      " '05A4' '06Q2' '05P9' '03I3' '06Q3' '11P3' '02K4' '08Q6' '9' '04I6' '04D6'\n",
      " '01Q3' '7' '02J1' '01J4' '02I1' '04Q8' '04J1' '08Q0' '04Y0' '01J2' '05K7'\n",
      " '03K4' '09E8' '02K6' '03W8' '05I8' '06Y0' '01G4' '03E7' '01I5' '04A4'\n",
      " '07D8' '01G1' '02I2' '06G0' '02J2' '09Q2' '02P6' '05Y0' '03G7' '07P2'\n",
      " '05P2' '05Q3' '02W8' '08A3' '03I8' '08P7' '07Q0' '05W7' '04C6' '03J0'\n",
      " '02J8' '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8' '04N1' '03Q4'\n",
      " '05E8' '06Q7' '04G9' '03C7' '06D3' '03K7' '01G0' '02G0' '04P6' '05A0'\n",
      " '05I6' '09K7' '05P6' '06P9' '04P5' '06A0' '03G3' '08J8' '02X9' '04M7'\n",
      " '04I7' '06Q8' '07Q2' '06K7' '04E7' '02J9' '03G1' '06X8' '04K6' '06D7'\n",
      " '03X0' '04D5' '05Q4' '04H6' '02Y2' '06W7' '05J3' '02I5' '07P0' '06P7'\n",
      " '06G4' '09A0' '06P8' '01E8' '08P0' '08Q7' '07P6' '07Q7' '02X3' '03W1'\n",
      " '07P5' '03R2' '8' '08Q9' '02V0' '01G7' '02D4' '06I8' '04I2' '02I8' '04B4'\n",
      " '04I8' '04Q1' '03C9' '04K7' '05G9' '05D6' '06K6' '07Q3' '04D7' '04W8'\n",
      " '08P9' '07Q4' '02Y3' '01P6' '11Q9' '06P0' '09Q7' '02A3' '03D4' '06P3'\n",
      " '06I2' '03N1' '10Q2' '04W0' '03D1' '02W0' '06P5' '06G3' '01J9' '06Y3'\n",
      " '08Q3' '01E7' '04K0' '03B4' '05D5' '04C8' '03J3' '03D5' '05X4' '02N3'\n",
      " '02P1' '08D6' '01N1' '01K2' '03I7' '09D8' '06A4' '04E4' '03E4' '04V8'\n",
      " '02J4' '09Q0' '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8'\n",
      " '03N2' '06M7' '02J0' '02Y8' '06W8' '06N3' '02I3' '02B0' '01D4' '11B3'\n",
      " '03X9' '04X9' '04K4' '01R0' '04D4' '03Q1' '04D8' '03B0' '03G0' '05R9'\n",
      " '02B2' '04I4' '05J8' '09P2' '03K3' '01R5' '04I3' '01K5' '09P5' '04R9'\n",
      " '06D4' '05B3' '02E3' '10Q3' '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0'\n",
      " '02C9' '07Y0' '04K5' '03X4' '02V4' '01M3' '03J2' '02D7' '02R7' '02E4'\n",
      " '01C7' '01Q4' '05K9' '01K4' '01A8' '06K2' '07G9' '10P2' '04Y2' '07P9'\n",
      " '02Y1' '03V4' '07I5' '08P5' '10P6' '06G9' '09P0' '06P1' '07P8' '06Y8'\n",
      " '07Q6' '08X5' '03M8' '01I2' '02K8' '01G8' '01E3' '05K2' '01I9' '02B9'\n",
      " '05K6' '09Q6' '02D1' '05G0' '02Y4' '05A5' '03B9' '03Y8' '04Y8' '06K4'\n",
      " '02R2' '02C7' '02Q5' '02K3' '05M2' '01G3' '08D8' '04J0' '08P8' '07K5'\n",
      " '10J2' '06I5' '08A4' '04G7' '04J2' '01I7' '08N1' '02D5' '05G1' '12Q2'\n",
      " '04G4' '11Q2' '06J0' '05Y3' '02R1' '05X5' '04G1' '01N3' '01J0' '06B4'\n",
      " '11Q4' '06E7' '02X0' '04C9' '07Q8' '03D7' '02W6' '03B2' '02G4' '03X5'\n",
      " '02I7' '06P6' '07D4' '05A8' '06E1' '04W2' '04Y6' '02E2' '03K2' '06D8'\n",
      " '03K9' '01P1' '04N2' '10X9' '01D5' '11P0' '02M6' '04X5' '06I7' '05P1'\n",
      " '03C4' '01R6' '03J4' '02A5' '01R1' '06G7' '05X9' '06D6' '02A8' '04Y1'\n",
      " '04B1' '01K7' '01K9' '01N2' '03G4' '05K4' '04R2' '07K2' '05E4' '05M6'\n",
      " '07E2' '05N3' '08E8' '08J9' '05Y2' '07V8' '05G7' '02E1' '09J9' '05K0'\n",
      " '04X4' '09P8' '02C8' '06E8' '08I5' '02R6' '01J3' '02W5' '03Q5' '05B0'\n",
      " '05D4' '11P6' '05W8' '10Q9' '06K5' '05D7' '03A5' '05K5' '08E7' '03M3'\n",
      " '05J4' '02H6' '04D1' '01R7' '08Q8' '10I4' '11A0' '08I6' '07J9' '11Q3'\n",
      " '04G6' '04E2' '10A0' '02N2' '01I3' '05M7' '03M6' '07E8' '03R7' '05M0'\n",
      " '02K9' '09J1' '08P6' '08J2' '06J2' '09A4' '12F0' '04X0' '01C9' '01B2'\n",
      " '11P2' '09K5' '03E5' '02L9' '09Y2' '06R9' '09Y3']\n",
      "Column 'econdp_16': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'econds_16': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'enicon_16': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' '08P3' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' '08Q2' '02Q4' '03B3' '05J9' '01A4'\n",
      " '10P3' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' '07Q9' '03K6' '02G9'\n",
      " '04P8' '10P0' '04B3' '08B3' '07A4' '05Q8' '06J9' '01G9' '08P2' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " '09Q9' '02G1' '07P3' '02K5' '03P8' '03J1' '05P5' '04W7' '08I2' '07P7'\n",
      " '05A4' '06Q2' '05P9' '03I3' '06Q3' '11P3' '02K4' '08Q6' '9' '04I6' '04D6'\n",
      " '01Q3' '7' '02J1' '01J4' '02I1' '04Q8' '04J1' '08Q0' '04Y0' '01J2' '05K7'\n",
      " '03K4' '09E8' '02K6' '03W8' '05I8' '06Y0' '01G4' '03E7' '01I5' '04A4'\n",
      " '07D8' '01G1' '02I2' '06G0' '02J2' '09Q2' '02P6' '05Y0' '03G7' '07P2'\n",
      " '05P2' '05Q3' '02W8' '08A3' '03I8' '08P7' '07Q0' '05W7' '04C6' '03J0'\n",
      " '02J8' '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8' '04N1' '03Q4'\n",
      " '05E8' '06Q7' '04G9' '03C7' '06D3' '03K7' '01G0' '02G0' '04P6' '05A0'\n",
      " '05I6' '09K7' '05P6' '06P9' '04P5' '06A0' '03G3' '08J8' '02X9' '04M7'\n",
      " '04I7' '06Q8' '07Q2' '06K7' '04E7' '02J9' '03G1' '06X8' '04K6' '06D7'\n",
      " '03X0' '04D5' '05Q4' '04H6' '02Y2' '06W7' '05J3' '02I5' '07P0' '06P7'\n",
      " '06G4' '09A0' '06P8' '01E8' '08P0' '08Q7' '07P6' '07Q7' '02X3' '03W1'\n",
      " '07P5' '03R2' '8' '08Q9' '02V0' '01G7' '02D4' '06I8' '04I2' '02I8' '04B4'\n",
      " '04I8' '04Q1' '03C9' '04K7' '05G9' '05D6' '06K6' '07Q3' '04D7' '04W8'\n",
      " '08P9' '07Q4' '02Y3' '01P6' '11Q9' '06P0' '09Q7' '02A3' '03D4' '06P3'\n",
      " '06I2' '03N1' '10Q2' '04W0' '03D1' '02W0' '06P5' '06G3' '01J9' '06Y3'\n",
      " '08Q3' '01E7' '04K0' '03B4' '05D5' '04C8' '03J3' '03D5' '05X4' '02N3'\n",
      " '02P1' '08D6' '01N1' '01K2' '03I7' '09D8' '06A4' '04E4' '03E4' '04V8'\n",
      " '02J4' '09Q0' '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8'\n",
      " '03N2' '06M7' '02J0' '02Y8' '06W8' '06N3' '02I3' '02B0' '01D4' '11B3'\n",
      " '03X9' '04X9' '04K4' '01R0' '04D4' '03Q1' '04D8' '03B0' '03G0' '05R9'\n",
      " '02B2' '04I4' '05J8' '09P2' '03K3' '01R5' '04I3' '01K5' '09P5' '04R9'\n",
      " '06D4' '05B3' '02E3' '10Q3' '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0'\n",
      " '02C9' '07Y0' '04K5' '03X4' '02V4' '01M3' '03J2' '02D7' '02R7' '02E4'\n",
      " '01C7' '01Q4' '05K9' '01K4' '01A8' '06K2' '07G9' '10P2' '04Y2' '07P9'\n",
      " '02Y1' '03V4' '07I5' '08P5' '10P6' '06G9' '09P0' '06P1' '07P8' '06Y8'\n",
      " '07Q6' '08X5' '03M8' '01I2' '02K8' '01G8' '01E3' '05K2' '01I9' '02B9'\n",
      " '05K6' '09Q6' '02D1' '05G0' '02Y4' '05A5' '03B9' '03Y8' '04Y8' '06K4'\n",
      " '02R2' '02C7' '02Q5' '02K3' '05M2' '01G3' '08D8' '04J0' '08P8' '07K5'\n",
      " '10J2' '06I5' '08A4' '04G7' '04J2' '01I7' '08N1' '02D5' '05G1' '12Q2'\n",
      " '04G4' '11Q2' '06J0' '05Y3' '02R1' '05X5' '04G1' '01N3' '01J0' '06B4'\n",
      " '11Q4' '06E7' '02X0' '04C9' '07Q8' '03D7' '02W6' '03B2' '02G4' '03X5'\n",
      " '02I7' '06P6' '07D4' '05A8' '06E1' '04W2' '04Y6' '02E2' '03K2' '06D8'\n",
      " '03K9' '01P1' '04N2' '10X9' '01D5' '11P0' '02M6' '04X5' '06I7' '05P1'\n",
      " '03C4' '01R6' '03J4' '02A5' '01R1' '06G7' '05X9' '06D6' '02A8' '04Y1'\n",
      " '04B1' '01K7' '01K9' '01N2' '03G4' '05K4' '04R2' '07K2' '05E4' '05M6'\n",
      " '07E2' '05N3' '08E8' '08J9' '05Y2' '07V8' '05G7' '02E1' '09J9' '05K0'\n",
      " '04X4' '09P8' '02C8' '06E8' '08I5' '02R6' '01J3' '02W5' '03Q5' '05B0'\n",
      " '05D4' '11P6' '05W8' '10Q9' '06K5' '05D7' '03A5' '05K5' '08E7' '03M3'\n",
      " '05J4' '02H6' '04D1' '01R7' '08Q8' '10I4' '11A0' '08I6' '07J9' '11Q3'\n",
      " '04G6' '04E2' '10A0' '02N2' '01I3' '05M7' '03M6' '07E8' '03R7' '05M0'\n",
      " '02K9' '09J1' '08P6' '08J2' '06J2' '09A4' '12F0' '04X0' '01C9' '01B2'\n",
      " '11P2' '09K5' '03E5' '02L9' '09Y2' '06R9' '09Y3']\n",
      "Column 'econdp_17': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'econds_17': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'enicon_17': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' '08P3' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' '08Q2' '02Q4' '03B3' '05J9' '01A4'\n",
      " '10P3' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' '07Q9' '03K6' '02G9'\n",
      " '04P8' '10P0' '04B3' '08B3' '07A4' '05Q8' '06J9' '01G9' '08P2' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " '09Q9' '02G1' '07P3' '02K5' '03P8' '03J1' '05P5' '04W7' '08I2' '07P7'\n",
      " '05A4' '06Q2' '05P9' '03I3' '06Q3' '11P3' '02K4' '08Q6' '9' '04I6' '04D6'\n",
      " '01Q3' '7' '02J1' '01J4' '02I1' '04Q8' '04J1' '08Q0' '04Y0' '01J2' '05K7'\n",
      " '03K4' '09E8' '02K6' '03W8' '05I8' '06Y0' '01G4' '03E7' '01I5' '04A4'\n",
      " '07D8' '01G1' '02I2' '06G0' '02J2' '09Q2' '02P6' '05Y0' '03G7' '07P2'\n",
      " '05P2' '05Q3' '02W8' '08A3' '03I8' '08P7' '07Q0' '05W7' '04C6' '03J0'\n",
      " '02J8' '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8' '04N1' '03Q4'\n",
      " '05E8' '06Q7' '04G9' '03C7' '06D3' '03K7' '01G0' '02G0' '04P6' '05A0'\n",
      " '05I6' '09K7' '05P6' '06P9' '04P5' '06A0' '03G3' '08J8' '02X9' '04M7'\n",
      " '04I7' '06Q8' '07Q2' '06K7' '04E7' '02J9' '03G1' '06X8' '04K6' '06D7'\n",
      " '03X0' '04D5' '05Q4' '04H6' '02Y2' '06W7' '05J3' '02I5' '07P0' '06P7'\n",
      " '06G4' '09A0' '06P8' '01E8' '08P0' '08Q7' '07P6' '07Q7' '02X3' '03W1'\n",
      " '07P5' '03R2' '8' '08Q9' '02V0' '01G7' '02D4' '06I8' '04I2' '02I8' '04B4'\n",
      " '04I8' '04Q1' '03C9' '04K7' '05G9' '05D6' '06K6' '07Q3' '04D7' '04W8'\n",
      " '08P9' '07Q4' '02Y3' '01P6' '11Q9' '06P0' '09Q7' '02A3' '03D4' '06P3'\n",
      " '06I2' '03N1' '10Q2' '04W0' '03D1' '02W0' '06P5' '06G3' '01J9' '06Y3'\n",
      " '08Q3' '01E7' '04K0' '03B4' '05D5' '04C8' '03J3' '03D5' '05X4' '02N3'\n",
      " '02P1' '08D6' '01N1' '01K2' '03I7' '09D8' '06A4' '04E4' '03E4' '04V8'\n",
      " '02J4' '09Q0' '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8'\n",
      " '03N2' '06M7' '02J0' '02Y8' '06W8' '06N3' '02I3' '02B0' '01D4' '11B3'\n",
      " '03X9' '04X9' '04K4' '01R0' '04D4' '03Q1' '04D8' '03B0' '03G0' '05R9'\n",
      " '02B2' '04I4' '05J8' '09P2' '03K3' '01R5' '04I3' '01K5' '09P5' '04R9'\n",
      " '06D4' '05B3' '02E3' '10Q3' '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0'\n",
      " '02C9' '07Y0' '04K5' '03X4' '02V4' '01M3' '03J2' '02D7' '02R7' '02E4'\n",
      " '01C7' '01Q4' '05K9' '01K4' '01A8' '06K2' '07G9' '10P2' '04Y2' '07P9'\n",
      " '02Y1' '03V4' '07I5' '08P5' '10P6' '06G9' '09P0' '06P1' '07P8' '06Y8'\n",
      " '07Q6' '08X5' '03M8' '01I2' '02K8' '01G8' '01E3' '05K2' '01I9' '02B9'\n",
      " '05K6' '09Q6' '02D1' '05G0' '02Y4' '05A5' '03B9' '03Y8' '04Y8' '06K4'\n",
      " '02R2' '02C7' '02Q5' '02K3' '05M2' '01G3' '08D8' '04J0' '08P8' '07K5'\n",
      " '10J2' '06I5' '08A4' '04G7' '04J2' '01I7' '08N1' '02D5' '05G1' '12Q2'\n",
      " '04G4' '11Q2' '06J0' '05Y3' '02R1' '05X5' '04G1' '01N3' '01J0' '06B4'\n",
      " '11Q4' '06E7' '02X0' '04C9' '07Q8' '03D7' '02W6' '03B2' '02G4' '03X5'\n",
      " '02I7' '06P6' '07D4' '05A8' '06E1' '04W2' '04Y6' '02E2' '03K2' '06D8'\n",
      " '03K9' '01P1' '04N2' '10X9' '01D5' '11P0' '02M6' '04X5' '06I7' '05P1'\n",
      " '03C4' '01R6' '03J4' '02A5' '01R1' '06G7' '05X9' '06D6' '02A8' '04Y1'\n",
      " '04B1' '01K7' '01K9' '01N2' '03G4' '05K4' '04R2' '07K2' '05E4' '05M6'\n",
      " '07E2' '05N3' '08E8' '08J9' '05Y2' '07V8' '05G7' '02E1' '09J9' '05K0'\n",
      " '04X4' '09P8' '02C8' '06E8' '08I5' '02R6' '01J3' '02W5' '03Q5' '05B0'\n",
      " '05D4' '11P6' '05W8' '10Q9' '06K5' '05D7' '03A5' '05K5' '08E7' '03M3'\n",
      " '05J4' '02H6' '04D1' '01R7' '08Q8' '10I4' '11A0' '08I6' '07J9' '11Q3'\n",
      " '04G6' '04E2' '10A0' '02N2' '01I3' '05M7' '03M6' '07E8' '03R7' '05M0'\n",
      " '02K9' '09J1' '08P6' '08J2' '06J2' '09A4' '12F0' '04X0' '01C9' '01B2'\n",
      " '11P2' '09K5' '03E5' '02L9' '09Y2' '06R9' '09Y3']\n",
      "Column 'econdp_18': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'econds_18': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'enicon_18': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' '08P3' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' '08Q2' '02Q4' '03B3' '05J9' '01A4'\n",
      " '10P3' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' '07Q9' '03K6' '02G9'\n",
      " '04P8' '10P0' '04B3' '08B3' '07A4' '05Q8' '06J9' '01G9' '08P2' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " '09Q9' '02G1' '07P3' '02K5' '03P8' '03J1' '05P5' '04W7' '08I2' '07P7'\n",
      " '05A4' '06Q2' '05P9' '03I3' '06Q3' '11P3' '02K4' '08Q6' '9' '04I6' '04D6'\n",
      " '01Q3' '7' '02J1' '01J4' '02I1' '04Q8' '04J1' '08Q0' '04Y0' '01J2' '05K7'\n",
      " '03K4' '09E8' '02K6' '03W8' '05I8' '06Y0' '01G4' '03E7' '01I5' '04A4'\n",
      " '07D8' '01G1' '02I2' '06G0' '02J2' '09Q2' '02P6' '05Y0' '03G7' '07P2'\n",
      " '05P2' '05Q3' '02W8' '08A3' '03I8' '08P7' '07Q0' '05W7' '04C6' '03J0'\n",
      " '02J8' '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8' '04N1' '03Q4'\n",
      " '05E8' '06Q7' '04G9' '03C7' '06D3' '03K7' '01G0' '02G0' '04P6' '05A0'\n",
      " '05I6' '09K7' '05P6' '06P9' '04P5' '06A0' '03G3' '08J8' '02X9' '04M7'\n",
      " '04I7' '06Q8' '07Q2' '06K7' '04E7' '02J9' '03G1' '06X8' '04K6' '06D7'\n",
      " '03X0' '04D5' '05Q4' '04H6' '02Y2' '06W7' '05J3' '02I5' '07P0' '06P7'\n",
      " '06G4' '09A0' '06P8' '01E8' '08P0' '08Q7' '07P6' '07Q7' '02X3' '03W1'\n",
      " '07P5' '03R2' '8' '08Q9' '02V0' '01G7' '02D4' '06I8' '04I2' '02I8' '04B4'\n",
      " '04I8' '04Q1' '03C9' '04K7' '05G9' '05D6' '06K6' '07Q3' '04D7' '04W8'\n",
      " '08P9' '07Q4' '02Y3' '01P6' '11Q9' '06P0' '09Q7' '02A3' '03D4' '06P3'\n",
      " '06I2' '03N1' '10Q2' '04W0' '03D1' '02W0' '06P5' '06G3' '01J9' '06Y3'\n",
      " '08Q3' '01E7' '04K0' '03B4' '05D5' '04C8' '03J3' '03D5' '05X4' '02N3'\n",
      " '02P1' '08D6' '01N1' '01K2' '03I7' '09D8' '06A4' '04E4' '03E4' '04V8'\n",
      " '02J4' '09Q0' '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8'\n",
      " '03N2' '06M7' '02J0' '02Y8' '06W8' '06N3' '02I3' '02B0' '01D4' '11B3'\n",
      " '03X9' '04X9' '04K4' '01R0' '04D4' '03Q1' '04D8' '03B0' '03G0' '05R9'\n",
      " '02B2' '04I4' '05J8' '09P2' '03K3' '01R5' '04I3' '01K5' '09P5' '04R9'\n",
      " '06D4' '05B3' '02E3' '10Q3' '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0'\n",
      " '02C9' '07Y0' '04K5' '03X4' '02V4' '01M3' '03J2' '02D7' '02R7' '02E4'\n",
      " '01C7' '01Q4' '05K9' '01K4' '01A8' '06K2' '07G9' '10P2' '04Y2' '07P9'\n",
      " '02Y1' '03V4' '07I5' '08P5' '10P6' '06G9' '09P0' '06P1' '07P8' '06Y8'\n",
      " '07Q6' '08X5' '03M8' '01I2' '02K8' '01G8' '01E3' '05K2' '01I9' '02B9'\n",
      " '05K6' '09Q6' '02D1' '05G0' '02Y4' '05A5' '03B9' '03Y8' '04Y8' '06K4'\n",
      " '02R2' '02C7' '02Q5' '02K3' '05M2' '01G3' '08D8' '04J0' '08P8' '07K5'\n",
      " '10J2' '06I5' '08A4' '04G7' '04J2' '01I7' '08N1' '02D5' '05G1' '12Q2'\n",
      " '04G4' '11Q2' '06J0' '05Y3' '02R1' '05X5' '04G1' '01N3' '01J0' '06B4'\n",
      " '11Q4' '06E7' '02X0' '04C9' '07Q8' '03D7' '02W6' '03B2' '02G4' '03X5'\n",
      " '02I7' '06P6' '07D4' '05A8' '06E1' '04W2' '04Y6' '02E2' '03K2' '06D8'\n",
      " '03K9' '01P1' '04N2' '10X9' '01D5' '11P0' '02M6' '04X5' '06I7' '05P1'\n",
      " '03C4' '01R6' '03J4' '02A5' '01R1' '06G7' '05X9' '06D6' '02A8' '04Y1'\n",
      " '04B1' '01K7' '01K9' '01N2' '03G4' '05K4' '04R2' '07K2' '05E4' '05M6'\n",
      " '07E2' '05N3' '08E8' '08J9' '05Y2' '07V8' '05G7' '02E1' '09J9' '05K0'\n",
      " '04X4' '09P8' '02C8' '06E8' '08I5' '02R6' '01J3' '02W5' '03Q5' '05B0'\n",
      " '05D4' '11P6' '05W8' '10Q9' '06K5' '05D7' '03A5' '05K5' '08E7' '03M3'\n",
      " '05J4' '02H6' '04D1' '01R7' '08Q8' '10I4' '11A0' '08I6' '07J9' '11Q3'\n",
      " '04G6' '04E2' '10A0' '02N2' '01I3' '05M7' '03M6' '07E8' '03R7' '05M0'\n",
      " '02K9' '09J1' '08P6' '08J2' '06J2' '09A4' '12F0' '04X0' '01C9' '01B2'\n",
      " '11P2' '09K5' '03E5' '02L9' '09Y2' '06R9' '09Y3']\n",
      "Column 'econdp_19': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'econds_19': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'enicon_19': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' '08P3' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' '08Q2' '02Q4' '03B3' '05J9' '01A4'\n",
      " '10P3' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' '07Q9' '03K6' '02G9'\n",
      " '04P8' '10P0' '04B3' '08B3' '07A4' '05Q8' '06J9' '01G9' '08P2' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " '09Q9' '02G1' '07P3' '02K5' '03P8' '03J1' '05P5' '04W7' '08I2' '07P7'\n",
      " '05A4' '06Q2' '05P9' '03I3' '06Q3' '11P3' '02K4' '08Q6' '9' '04I6' '04D6'\n",
      " '01Q3' '7' '02J1' '01J4' '02I1' '04Q8' '04J1' '08Q0' '04Y0' '01J2' '05K7'\n",
      " '03K4' '09E8' '02K6' '03W8' '05I8' '06Y0' '01G4' '03E7' '01I5' '04A4'\n",
      " '07D8' '01G1' '02I2' '06G0' '02J2' '09Q2' '02P6' '05Y0' '03G7' '07P2'\n",
      " '05P2' '05Q3' '02W8' '08A3' '03I8' '08P7' '07Q0' '05W7' '04C6' '03J0'\n",
      " '02J8' '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8' '04N1' '03Q4'\n",
      " '05E8' '06Q7' '04G9' '03C7' '06D3' '03K7' '01G0' '02G0' '04P6' '05A0'\n",
      " '05I6' '09K7' '05P6' '06P9' '04P5' '06A0' '03G3' '08J8' '02X9' '04M7'\n",
      " '04I7' '06Q8' '07Q2' '06K7' '04E7' '02J9' '03G1' '06X8' '04K6' '06D7'\n",
      " '03X0' '04D5' '05Q4' '04H6' '02Y2' '06W7' '05J3' '02I5' '07P0' '06P7'\n",
      " '06G4' '09A0' '06P8' '01E8' '08P0' '08Q7' '07P6' '07Q7' '02X3' '03W1'\n",
      " '07P5' '03R2' '8' '08Q9' '02V0' '01G7' '02D4' '06I8' '04I2' '02I8' '04B4'\n",
      " '04I8' '04Q1' '03C9' '04K7' '05G9' '05D6' '06K6' '07Q3' '04D7' '04W8'\n",
      " '08P9' '07Q4' '02Y3' '01P6' '11Q9' '06P0' '09Q7' '02A3' '03D4' '06P3'\n",
      " '06I2' '03N1' '10Q2' '04W0' '03D1' '02W0' '06P5' '06G3' '01J9' '06Y3'\n",
      " '08Q3' '01E7' '04K0' '03B4' '05D5' '04C8' '03J3' '03D5' '05X4' '02N3'\n",
      " '02P1' '08D6' '01N1' '01K2' '03I7' '09D8' '06A4' '04E4' '03E4' '04V8'\n",
      " '02J4' '09Q0' '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8'\n",
      " '03N2' '06M7' '02J0' '02Y8' '06W8' '06N3' '02I3' '02B0' '01D4' '11B3'\n",
      " '03X9' '04X9' '04K4' '01R0' '04D4' '03Q1' '04D8' '03B0' '03G0' '05R9'\n",
      " '02B2' '04I4' '05J8' '09P2' '03K3' '01R5' '04I3' '01K5' '09P5' '04R9'\n",
      " '06D4' '05B3' '02E3' '10Q3' '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0'\n",
      " '02C9' '07Y0' '04K5' '03X4' '02V4' '01M3' '03J2' '02D7' '02R7' '02E4'\n",
      " '01C7' '01Q4' '05K9' '01K4' '01A8' '06K2' '07G9' '10P2' '04Y2' '07P9'\n",
      " '02Y1' '03V4' '07I5' '08P5' '10P6' '06G9' '09P0' '06P1' '07P8' '06Y8'\n",
      " '07Q6' '08X5' '03M8' '01I2' '02K8' '01G8' '01E3' '05K2' '01I9' '02B9'\n",
      " '05K6' '09Q6' '02D1' '05G0' '02Y4' '05A5' '03B9' '03Y8' '04Y8' '06K4'\n",
      " '02R2' '02C7' '02Q5' '02K3' '05M2' '01G3' '08D8' '04J0' '08P8' '07K5'\n",
      " '10J2' '06I5' '08A4' '04G7' '04J2' '01I7' '08N1' '02D5' '05G1' '12Q2'\n",
      " '04G4' '11Q2' '06J0' '05Y3' '02R1' '05X5' '04G1' '01N3' '01J0' '06B4'\n",
      " '11Q4' '06E7' '02X0' '04C9' '07Q8' '03D7' '02W6' '03B2' '02G4' '03X5'\n",
      " '02I7' '06P6' '07D4' '05A8' '06E1' '04W2' '04Y6' '02E2' '03K2' '06D8'\n",
      " '03K9' '01P1' '04N2' '10X9' '01D5' '11P0' '02M6' '04X5' '06I7' '05P1'\n",
      " '03C4' '01R6' '03J4' '02A5' '01R1' '06G7' '05X9' '06D6' '02A8' '04Y1'\n",
      " '04B1' '01K7' '01K9' '01N2' '03G4' '05K4' '04R2' '07K2' '05E4' '05M6'\n",
      " '07E2' '05N3' '08E8' '08J9' '05Y2' '07V8' '05G7' '02E1' '09J9' '05K0'\n",
      " '04X4' '09P8' '02C8' '06E8' '08I5' '02R6' '01J3' '02W5' '03Q5' '05B0'\n",
      " '05D4' '11P6' '05W8' '10Q9' '06K5' '05D7' '03A5' '05K5' '08E7' '03M3'\n",
      " '05J4' '02H6' '04D1' '01R7' '08Q8' '10I4' '11A0' '08I6' '07J9' '11Q3'\n",
      " '04G6' '04E2' '10A0' '02N2' '01I3' '05M7' '03M6' '07E8' '03R7' '05M0'\n",
      " '02K9' '09J1' '08P6' '08J2' '06J2' '09A4' '12F0' '04X0' '01C9' '01B2'\n",
      " '11P2' '09K5' '03E5' '02L9' '09Y2' '06R9' '09Y3']\n",
      "Column 'econdp_20': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'econds_20': [0 3 6 4 1 2 5 9 7 8]\n",
      "Column 'enicon_20': ['04P3' '03Q2' '01Q6' '02R9' '02P2' '01P0' '03A0' '01R9' '01I6' '01Q8'\n",
      " '04Q9' '01J1' '02P3' '03P5' '01P2' '02Q7' '02W7' '02Q8' '02P5' '02Q2'\n",
      " '03D6' '02A4' '03P2' '01J8' '03P0' '02Q9' '03P7' '02A0' '04J9' '03J6'\n",
      " '01Q0' '02P0' '04P2' '3' '6' '01P3' '02V8' '03Q8' '01P7' '02P7' '03R9'\n",
      " '03Q6' '08P3' '01A0' '03Q3' '04Q0' '01P5' '04J8' '4' '01A3' '05P0' '02D6'\n",
      " '03I2' '05P7' '03J8' '1' '04A0' '04E8' '03P3' '01Q9' '02P9' '06Q6' '02D8'\n",
      " '01Q2' '05B9' '04P7' '06P2' '2' '02E8' '02R0' '02R5' '03Y0' '05P3' '04Q7'\n",
      " '03Q9' '01I4' '02N1' '02Q0' '03P6' '05I2' '02Q6' '04P0' '02I6' '02Y0'\n",
      " '02Q3' '04Q6' '05N1' '04P9' '04P1' '03P1' '5' '03Q0' '05Q9' '03Q7' '03K5'\n",
      " '05Q6' '02P8' '03A4' '04Q3' '01P9' '03E8' '03P9' '07A0' '01Q7' '03G9'\n",
      " '03W7' '01E4' '05Q2' '04I5' '02E7' '08Q2' '02Q4' '03B3' '05J9' '01A4'\n",
      " '10P3' '03Y3' '05C9' '02I4' '07I6' '03Y2' '02B3' '07Q9' '03K6' '02G9'\n",
      " '04P8' '10P0' '04B3' '08B3' '07A4' '05Q8' '06J9' '01G9' '08P2' '07B3'\n",
      " '03V8' '03I4' '04Q2' '03I5' '05Q0' '04G5' '03Y1' '03I6' '02B4' '01P8'\n",
      " '09Q9' '02G1' '07P3' '02K5' '03P8' '03J1' '05P5' '04W7' '08I2' '07P7'\n",
      " '05A4' '06Q2' '05P9' '03I3' '06Q3' '11P3' '02K4' '08Q6' '9' '04I6' '04D6'\n",
      " '01Q3' '7' '02J1' '01J4' '02I1' '04Q8' '04J1' '08Q0' '04Y0' '01J2' '05K7'\n",
      " '03K4' '09E8' '02K6' '03W8' '05I8' '06Y0' '01G4' '03E7' '01I5' '04A4'\n",
      " '07D8' '01G1' '02I2' '06G0' '02J2' '09Q2' '02P6' '05Y0' '03G7' '07P2'\n",
      " '05P2' '05Q3' '02W8' '08A3' '03I8' '08P7' '07Q0' '05W7' '04C6' '03J0'\n",
      " '02J8' '05Q7' '02G7' '06I4' '05I4' '04Q4' '03J9' '05P8' '04N1' '03Q4'\n",
      " '05E8' '06Q7' '04G9' '03C7' '06D3' '03K7' '01G0' '02G0' '04P6' '05A0'\n",
      " '05I6' '09K7' '05P6' '06P9' '04P5' '06A0' '03G3' '08J8' '02X9' '04M7'\n",
      " '04I7' '06Q8' '07Q2' '06K7' '04E7' '02J9' '03G1' '06X8' '04K6' '06D7'\n",
      " '03X0' '04D5' '05Q4' '04H6' '02Y2' '06W7' '05J3' '02I5' '07P0' '06P7'\n",
      " '06G4' '09A0' '06P8' '01E8' '08P0' '08Q7' '07P6' '07Q7' '02X3' '03W1'\n",
      " '07P5' '03R2' '8' '08Q9' '02V0' '01G7' '02D4' '06I8' '04I2' '02I8' '04B4'\n",
      " '04I8' '04Q1' '03C9' '04K7' '05G9' '05D6' '06K6' '07Q3' '04D7' '04W8'\n",
      " '08P9' '07Q4' '02Y3' '01P6' '11Q9' '06P0' '09Q7' '02A3' '03D4' '06P3'\n",
      " '06I2' '03N1' '10Q2' '04W0' '03D1' '02W0' '06P5' '06G3' '01J9' '06Y3'\n",
      " '08Q3' '01E7' '04K0' '03B4' '05D5' '04C8' '03J3' '03D5' '05X4' '02N3'\n",
      " '02P1' '08D6' '01N1' '01K2' '03I7' '09D8' '06A4' '04E4' '03E4' '04V8'\n",
      " '02J4' '09Q0' '01E5' '04G0' '01B3' '02X5' '02C6' '06Q9' '04I1' '05Y8'\n",
      " '03N2' '06M7' '02J0' '02Y8' '06W8' '06N3' '02I3' '02B0' '01D4' '11B3'\n",
      " '03X9' '04X9' '04K4' '01R0' '04D4' '03Q1' '04D8' '03B0' '03G0' '05R9'\n",
      " '02B2' '04I4' '05J8' '09P2' '03K3' '01R5' '04I3' '01K5' '09P5' '04R9'\n",
      " '06D4' '05B3' '02E3' '10Q3' '03E3' '07C9' '06N1' '03E1' '02K7' '06Q0'\n",
      " '02C9' '07Y0' '04K5' '03X4' '02V4' '01M3' '03J2' '02D7' '02R7' '02E4'\n",
      " '01C7' '01Q4' '05K9' '01K4' '01A8' '06K2' '07G9' '10P2' '04Y2' '07P9'\n",
      " '02Y1' '03V4' '07I5' '08P5' '10P6' '06G9' '09P0' '06P1' '07P8' '06Y8'\n",
      " '07Q6' '08X5' '03M8' '01I2' '02K8' '01G8' '01E3' '05K2' '01I9' '02B9'\n",
      " '05K6' '09Q6' '02D1' '05G0' '02Y4' '05A5' '03B9' '03Y8' '04Y8' '06K4'\n",
      " '02R2' '02C7' '02Q5' '02K3' '05M2' '01G3' '08D8' '04J0' '08P8' '07K5'\n",
      " '10J2' '06I5' '08A4' '04G7' '04J2' '01I7' '08N1' '02D5' '05G1' '12Q2'\n",
      " '04G4' '11Q2' '06J0' '05Y3' '02R1' '05X5' '04G1' '01N3' '01J0' '06B4'\n",
      " '11Q4' '06E7' '02X0' '04C9' '07Q8' '03D7' '02W6' '03B2' '02G4' '03X5'\n",
      " '02I7' '06P6' '07D4' '05A8' '06E1' '04W2' '04Y6' '02E2' '03K2' '06D8'\n",
      " '03K9' '01P1' '04N2' '10X9' '01D5' '11P0' '02M6' '04X5' '06I7' '05P1'\n",
      " '03C4' '01R6' '03J4' '02A5' '01R1' '06G7' '05X9' '06D6' '02A8' '04Y1'\n",
      " '04B1' '01K7' '01K9' '01N2' '03G4' '05K4' '04R2' '07K2' '05E4' '05M6'\n",
      " '07E2' '05N3' '08E8' '08J9' '05Y2' '07V8' '05G7' '02E1' '09J9' '05K0'\n",
      " '04X4' '09P8' '02C8' '06E8' '08I5' '02R6' '01J3' '02W5' '03Q5' '05B0'\n",
      " '05D4' '11P6' '05W8' '10Q9' '06K5' '05D7' '03A5' '05K5' '08E7' '03M3'\n",
      " '05J4' '02H6' '04D1' '01R7' '08Q8' '10I4' '11A0' '08I6' '07J9' '11Q3'\n",
      " '04G6' '04E2' '10A0' '02N2' '01I3' '05M7' '03M6' '07E8' '03R7' '05M0'\n",
      " '02K9' '09J1' '08P6' '08J2' '06J2' '09A4' '12F0' '04X0' '01C9' '01B2'\n",
      " '11P2' '09K5' '03E5' '02L9' '09Y2' '06R9' '09Y3']\n",
      "Column 'ranum': [ 4  3  1  2  6  8  5  7 10  9 11 12]\n",
      "Column 'record': ['P369' 'Q249' 'Q602' 'R95' 'P280' 'Q213' 'P039' 'A090' 'R99' 'I678'\n",
      " 'Q897' 'P072' 'Q913' 'J189' 'P549' 'P239' 'P018' 'Q789' 'W75' 'P011'\n",
      " 'P522' 'D689' 'P293' 'Q245' 'A419' 'P220' 'J849' 'P77' 'J984' 'P021'\n",
      " 'J690' 'Q000' 'P070' 'P271' 'P364' 'V892' 'P251' 'P010' 'P523' 'J840'\n",
      " 'P269' 'Q893' 'Q042' 'Q614' 'P548' 'P209' 'P298' 'P291' 'Q336' 'Q043'\n",
      " 'P543' 'P368' 'P073' 'P219' 'Q917' 'A391' 'P240' 'I272' 'P780' 'J80'\n",
      " 'E872' 'Q211' 'P916' 'Q613' 'D899' 'Q771' 'Q248' 'Q212' 'B99' 'Q606'\n",
      " 'P026' 'V874' 'P969' 'D761' 'E875' 'R092' 'R579' 'Y09' 'P362' 'Q790'\n",
      " 'I469' 'P290' 'N19' 'A099' 'C919' 'P614' 'P352' 'P013' 'P529' 'I615'\n",
      " 'Q318' 'D849' 'X30' 'Q878' 'P059' 'Q899' 'P960' 'P159' 'V877' 'C349'\n",
      " 'Q283' 'P234' 'P015' 'A415' 'K550' 'Q601' 'J129' 'P832' 'P288' 'Q234'\n",
      " 'P005' 'P398' 'Q279' 'J961' 'E889' 'J14' 'Q798' 'Q927' 'G934' 'E46'\n",
      " 'I498' 'I514' 'E713' 'P038' 'Q799' 'G709' 'I279' 'Q431' 'P027' 'B348'\n",
      " 'Q688' 'Q870' 'P236' 'Y34' 'C959' 'Q230' 'Q909' 'I456' 'I64' 'D682' 'Y20'\n",
      " 'Q792' 'Q774' 'Q929' 'P008' 'A022' 'K631' 'G931' 'Q898' 'P012' 'Q02'\n",
      " 'P001' 'Q039' 'Y21' 'Q642' 'P020' 'P912' 'G938' 'Q049' 'P521' 'P360'\n",
      " 'I429' 'Q204' 'P002' 'I515' 'G529' 'Y11' 'W79' 'B49' 'Q935' 'P378' 'G129'\n",
      " 'P292' 'A401' 'P375' 'Q638' 'P241' 'Q203' 'P023' 'Q251' 'J101' 'W74'\n",
      " 'B342' 'Q201' 'P941' 'I370' 'Q321' 'J980' 'Q210' 'J120' 'P022' 'K449'\n",
      " 'J180' 'Q605' 'P60' 'A379' 'A081' 'Q795' 'Q054' 'Q611' 'P253' 'Q282'\n",
      " 'Q330' 'G009' 'A402' 'C629' 'Q894' 'J40' 'I119' 'P229' 'P968' 'Q246'\n",
      " 'P279' 'Q780' 'Q257' 'K566' 'J219' 'K766' 'P071' 'Q262' 'K403' 'E848'\n",
      " 'K659' 'W84' 'I898' 'G419' 'E722' 'Q619' 'Q250' 'Q256' 'Q231' 'I209'\n",
      " 'G002' 'P524' 'W78' 'Q339' 'Y079' 'P358' 'Q772' 'I871' 'P035' 'P942'\n",
      " 'Q255' 'Q225' 'C64' 'J069' 'J869' 'P90' 'G712' 'I422' 'P017' 'Q433'\n",
      " 'Q999' 'Q019' 'P250' 'Q438' 'Q324' 'Q743' 'P000' 'Q872' 'E880' 'P016'\n",
      " 'Q678' 'Q200' 'P024' 'Q793' 'P285' 'I499' 'C719' 'E725' 'D376' 'P612'\n",
      " 'Q258' 'K768' 'G039' 'N12' 'G008' 'Q639' 'Q892' 'I517' 'P049' 'A490'\n",
      " 'I619' 'I620' 'Q858' 'N189' 'P033' 'W83' 'W65' 'Q059' 'G319' 'J860' 'X92'\n",
      " 'P392' 'M726' 'I788' 'I609' 'K729' 'Q928' 'E752' 'P284' 'Q038' 'Q871'\n",
      " 'X85' 'Q349' 'Q048' 'P232' 'Q933' 'G003' 'B349' 'K638' 'Q458' 'D720'\n",
      " 'Q333' 'W67' 'Q444' 'X00' 'Y26' 'Q268' 'D582' 'Q442' 'I120' 'I319' 'H669'\n",
      " 'Q254' 'J152' 'J386' 'P399' 'I518' 'Q998' 'W80' 'I629' 'K904' 'Q228'\n",
      " 'D432' 'W19' 'K358' 'R278' 'P528' 'P504' 'V090' 'Q809' 'A410' 'J982'\n",
      " 'J42' 'I420' 'Q412' 'P044' 'I823' 'X47' 'I424' 'G049' 'Q182' 'G318'\n",
      " 'D748' 'G629' 'V446' 'Q232' 'K668' 'Q379' 'D70' 'Q447' 'P361' 'Q764'\n",
      " 'P031' 'D821' 'Q220' 'Q224' 'V031' 'C749' 'Q263' 'Q392' 'Q320' 'W69'\n",
      " 'I428' 'J181' 'Q223' 'P833' 'J988' 'J371' 'D589' 'V486' 'A329' 'D471'\n",
      " 'K562' 'Q018' 'P289' 'G952' 'P028' 'P351' 'J128' 'P249' 'N898' 'B009'\n",
      " 'N179' 'Q939' 'Q056' 'B259' 'P158' 'W04' 'D151' 'J850' 'W06' 'Q874'\n",
      " 'P526' 'J969' 'Q273' 'E711' 'E871' 'J930' 'Q970' 'V489' 'D560' 'E724'\n",
      " 'Q969' 'K070' 'Q794' 'Q030' 'Q079' 'J209' 'V819' 'P914' 'P034' 'C80'\n",
      " 'J398' 'Q031' 'E86' 'Q410' 'D685' 'X44' 'N343' 'P112' 'I890' 'P910'\n",
      " 'D693' 'N139' 'P036' 'Q240' 'Q648' 'K219' 'J210' 'I709' 'D820' 'P964'\n",
      " 'P210' 'I442' 'J22' 'Q242' 'P509' 'W76' 'E561' 'I409' 'Q229' 'X599'\n",
      " 'P006' 'A493' 'P042' 'G98' 'K902' 'I10' 'Y839' 'P702' 'P003' 'N289'\n",
      " 'D489' 'J00' 'P230' 'Y848' 'P030' 'N390' 'K661' 'E149' 'J218' 'X91'\n",
      " 'E831' 'A498' 'B340' 'X95' 'R090' 'Y069' 'D649' 'J981' 'Q759' 'G409'\n",
      " 'Q159' 'Q040' 'P051' 'P041' 'Q643' 'A499' 'J154' 'L022' 'G937' 'P783'\n",
      " 'J960' 'I519' 'Q012' 'P592' 'B201' 'G711' 'Q226' 'I421' 'G729' 'V030'\n",
      " 'J121' 'D181' 'V436' 'Q046' 'I458' 'P261' 'Q604' 'I400' 'E877' 'K318'\n",
      " 'Y08' 'Q315' 'J13' 'Q819' 'D610' 'I219' 'Q934' 'Y14' 'K559' 'Q620' 'G919'\n",
      " 'G111' 'E343' 'Q390' 'E348' 'C925' 'Q219' 'Q221' 'D65' 'E232' 'Q400'\n",
      " 'E161' 'Q915' 'K565' 'W20' 'A084' 'Y04' 'I471' 'D487' 'C910' 'Q549' 'Y33'\n",
      " 'P965' 'A080' 'D480' 'J841' 'Y00' 'E250' 'G908' 'M303' 'I313' 'P769'\n",
      " 'Q649' 'K561' 'R568' 'J90' 'R739' 'Q808' 'C920' 'C716' 'I509' 'P701'\n",
      " 'P082' 'I251' 'Q264' 'G120' 'A879' 'E878' 'E770' 'K740' 'I99' 'G128'\n",
      " 'Q623' 'Y071' 'I639' 'Y12' 'W31' 'J939' 'G911' 'Q348' 'Y833' 'M622'\n",
      " 'E744' 'B378' 'Q423' 'B399' 'I270' 'J450' 'B332' 'Y061' 'M841' 'I288'\n",
      " 'P809' 'G918' 'K859' 'G809' 'P019' 'D591' 'A403' 'G404' 'K769' 'Q938'\n",
      " 'V439' 'Q288' 'Q891' 'P393' 'P560' 'G060' 'W73' 'N049' 'R402' 'Y430'\n",
      " 'A509' 'J041' 'R048' 'C951' 'J155' 'Y836' 'I822' 'Y832' 'D759' 'P009'\n",
      " 'A86' 'J100' 'J81' 'D806' 'V476' 'P025' 'Q564' 'K37' 'X97' 'M246' 'R068'\n",
      " 'J111' 'P501' 'D410' 'I269' 'M889' 'I249' 'P550' 'V092' 'P613' 'I501'\n",
      " 'Q439' 'P394' 'I425' 'P610' 'P788' 'A370' 'Q932' 'B379' 'Y078' 'E870'\n",
      " 'I741' 'Q645' 'X09' 'K720' 'R98' 'G122' 'N258' 'G936' 'C717' 'I513'\n",
      " 'Q411' 'A409' 'Q778' 'E230' 'P53' 'J158' 'A491' 'I461' 'Q070' 'R11'\n",
      " 'B449' 'D580' 'V499' 'N320' 'A021' 'K761' 'Q600' 'Q959' 'Q873' 'C929'\n",
      " 'Q239' 'E874' 'P029' 'J09' 'K228' 'G001' 'D696' 'Q402' 'Q391' 'R629'\n",
      " 'E849' 'P359' 'P599' 'Q668' 'P559' 'P961' 'J208' 'I472' 'I059' 'B007'\n",
      " 'D619' 'E742' 'J151' 'P545' 'E740' 'K567' 'K598' 'P120' 'A051' 'I749'\n",
      " 'A870' 'B377' 'Q631' 'W22' 'I490' 'I633' 'Y605' 'X94' 'Q338' 'Q430'\n",
      " 'K255' 'Q829' 'D819' 'E782' 'L299' 'K529' 'C222' 'D758' 'P150' 'Q206'\n",
      " 'Y01' 'N288' 'K746' 'P700' 'Y03' 'P283' 'X99' 'D694' 'Q773' 'K402' 'I500'\n",
      " 'R298' 'J122' 'Q791' 'I710' 'P525' 'P363' 'Q758' 'E778' 'J459' 'J989'\n",
      " 'K767' 'C499' 'R628' 'Q978' 'R02' 'A599' 'R18' 'B258' 'A412' 'Q740'\n",
      " 'E830' 'M318' 'P918' 'G042' 'I773' 'K223' 'P372' 'X41' 'J851' 'B179'\n",
      " 'K741' 'K922' 'P781' 'K593' 'J150' 'M629' 'C762' 'P043' 'E723' 'E274'\n",
      " 'E320' 'Q233' 'Q776' 'A047' 'W44' 'I899' 'K404' 'Q931' 'X590' 'J387'\n",
      " 'Q280' 'P252' 'G961' 'J159' 'Q332' 'P611' 'E785' 'P38' 'J449' 'J156'\n",
      " 'J399' 'W54' 'Q044' 'Q559' 'E876' 'D760' 'I829' 'Q060' 'X42' 'B341'\n",
      " 'G473' 'V890' 'M319' 'J439' 'Q513' 'R570' 'R784' 'J050' 'G403' 'V887'\n",
      " 'Q222' 'D573' 'E840' 'Q621' 'V536' 'Q675' 'B250' 'Q911' 'G628' 'I679'\n",
      " 'G935' 'Q310' 'G939' 'E803' 'X37' 'K221' 'C229' 'N10' 'Q777' 'G121'\n",
      " 'R788' 'K296' 'I740' 'K759' 'V496' 'Q782' 'M009' 'J029' 'R609' 'D180'\n",
      " 'K929' 'G710' 'P579' 'D469' 'F069' 'C950' 'B206' 'P929' 'P243' 'P139'\n",
      " 'E550' 'L988' 'J110' 'R688' 'Y05' 'I739' 'J040' 'D572' 'I258' 'E835'\n",
      " 'I779']\n",
      "Column 'record_1': ['P369' 'Q249' 'Q602' 'R95' 'P280' 'Q213' 'P039' 'A090' 'R99' 'I678'\n",
      " 'Q897' 'P072' 'Q913' 'J189' 'P549' 'P239' 'P018' 'Q789' 'W75' 'P011'\n",
      " 'P522' 'D689' 'P293' 'Q245' 'A419' 'P220' 'J849' 'P77' 'J984' 'P021'\n",
      " 'J690' 'Q000' 'P070' 'P271' 'P364' 'V892' 'P251' 'P010' 'P523' 'J840'\n",
      " 'P269' 'Q893' 'Q042' 'Q614' 'P548' 'P209' 'P298' 'P291' 'Q336' 'Q043'\n",
      " 'P543' 'P368' 'P073' 'P219' 'Q917' 'A391' 'P240' 'I272' 'P780' 'J80'\n",
      " 'E872' 'Q211' 'P916' 'Q613' 'D899' 'Q771' 'Q248' 'Q212' 'B99' 'Q606'\n",
      " 'P026' 'V874' 'P969' 'D761' 'E875' 'R092' 'R579' 'Y09' 'P362' 'Q790'\n",
      " 'I469' 'P290' 'N19' 'A099' 'C919' 'P614' 'P352' 'P013' 'P529' 'I615'\n",
      " 'Q318' 'D849' 'X30' 'Q878' 'P059' 'Q899' 'P960' 'P159' 'V877' 'C349'\n",
      " 'Q283' 'P234' 'P015' 'A415' 'K550' 'Q601' 'J129' 'P832' 'P288' 'Q234'\n",
      " 'P005' 'P398' 'Q279' 'J961' 'E889' 'J14' 'Q798' 'Q927' 'G934' 'E46'\n",
      " 'I498' 'I514' 'E713' 'P038' 'Q799' 'G709' 'I279' 'Q431' 'P027' 'B348'\n",
      " 'Q688' 'Q870' 'P236' 'Y34' 'C959' 'Q230' 'Q909' 'I456' 'I64' 'D682' 'Y20'\n",
      " 'Q792' 'Q774' 'Q929' 'P008' 'A022' 'K631' 'G931' 'Q898' 'P012' 'Q02'\n",
      " 'P001' 'Q039' 'Y21' 'Q642' 'P020' 'P912' 'G938' 'Q049' 'P521' 'P360'\n",
      " 'I429' 'Q204' 'P002' 'I515' 'G529' 'Y11' 'W79' 'B49' 'Q935' 'P378' 'G129'\n",
      " 'P292' 'A401' 'P375' 'Q638' 'P241' 'Q203' 'P023' 'Q251' 'J101' 'W74'\n",
      " 'B342' 'Q201' 'P941' 'I370' 'Q321' 'J980' 'Q210' 'J120' 'P022' 'K449'\n",
      " 'J180' 'Q605' 'P60' 'A379' 'A081' 'Q795' 'Q054' 'Q611' 'P253' 'Q282'\n",
      " 'Q330' 'G009' 'A402' 'C629' 'Q894' 'J40' 'I119' 'P229' 'P968' 'Q246'\n",
      " 'P279' 'Q780' 'Q257' 'K566' 'J219' 'K766' 'P071' 'Q262' 'K403' 'E848'\n",
      " 'K659' 'W84' 'I898' 'G419' 'E722' 'Q619' 'Q250' 'Q256' 'Q231' 'I209'\n",
      " 'G002' 'P524' 'W78' 'Q339' 'Y079' 'P358' 'Q772' 'I871' 'P035' 'P942'\n",
      " 'Q255' 'Q225' 'C64' 'J069' 'J869' 'P90' 'G712' 'I422' 'P017' 'Q433'\n",
      " 'Q999' 'Q019' 'P250' 'Q438' 'Q324' 'Q743' 'P000' 'Q872' 'E880' 'P016'\n",
      " 'Q678' 'Q200' 'P024' 'Q793' 'P285' 'I499' 'C719' 'E725' 'D376' 'P612'\n",
      " 'Q258' 'K768' 'G039' 'N12' 'G008' 'Q639' 'Q892' 'I517' 'P049' 'A490'\n",
      " 'I619' 'I620' 'Q858' 'N189' 'P033' 'W83' 'W65' 'Q059' 'G319' 'J860' 'X92'\n",
      " 'P392' 'M726' 'I788' 'I609' 'K729' 'Q928' 'E752' 'P284' 'Q038' 'Q871'\n",
      " 'X85' 'Q349' 'Q048' 'P232' 'Q933' 'G003' 'B349' 'K638' 'Q458' 'D720'\n",
      " 'Q333' 'W67' 'Q444' 'X00' 'Y26' 'Q268' 'D582' 'Q442' 'I120' 'I319' 'H669'\n",
      " 'Q254' 'J152' 'J386' 'P399' 'I518' 'Q998' 'W80' 'I629' 'K904' 'Q228'\n",
      " 'D432' 'W19' 'K358' 'R278' 'P528' 'P504' 'V090' 'Q809' 'A410' 'J982'\n",
      " 'J42' 'I420' 'Q412' 'P044' 'I823' 'X47' 'I424' 'G049' 'Q182' 'G318'\n",
      " 'D748' 'G629' 'V446' 'Q232' 'K668' 'Q379' 'D70' 'Q447' 'P361' 'Q764'\n",
      " 'P031' 'D821' 'Q220' 'Q224' 'V031' 'C749' 'Q263' 'Q392' 'Q320' 'W69'\n",
      " 'I428' 'J181' 'Q223' 'P833' 'J988' 'J371' 'D589' 'V486' 'A329' 'D471'\n",
      " 'K562' 'Q018' 'P289' 'G952' 'P028' 'P351' 'J128' 'P249' 'N898' 'B009'\n",
      " 'N179' 'Q939' 'Q056' 'B259' 'P158' 'W04' 'D151' 'J850' 'W06' 'Q874'\n",
      " 'P526' 'J969' 'Q273' 'E711' 'E871' 'J930' 'Q970' 'V489' 'D560' 'E724'\n",
      " 'Q969' 'K070' 'Q794' 'Q030' 'Q079' 'J209' 'V819' 'P914' 'P034' 'C80'\n",
      " 'J398' 'Q031' 'E86' 'Q410' 'D685' 'X44' 'N343' 'P112' 'I890' 'P910'\n",
      " 'D693' 'N139' 'P036' 'Q240' 'Q648' 'K219' 'J210' 'I709' 'D820' 'P964'\n",
      " 'P210' 'I442' 'J22' 'Q242' 'P509' 'W76' 'E561' 'I409' 'Q229' 'X599'\n",
      " 'P006' 'A493' 'P042' 'G98' 'K902' 'I10' 'Y839' 'P702' 'P003' 'N289'\n",
      " 'D489' 'J00' 'P230' 'Y848' 'P030' 'N390' 'K661' 'E149' 'J218' 'X91'\n",
      " 'E831' 'A498' 'B340' 'X95' 'R090' 'Y069' 'D649' 'J981' 'Q759' 'G409'\n",
      " 'Q159' 'Q040' 'P051' 'P041' 'Q643' 'A499' 'J154' 'L022' 'G937' 'P783'\n",
      " 'J960' 'I519' 'Q012' 'P592' 'B201' 'G711' 'Q226' 'I421' 'G729' 'V030'\n",
      " 'J121' 'D181' 'V436' 'Q046' 'I458' 'P261' 'Q604' 'I400' 'E877' 'K318'\n",
      " 'Y08' 'Q315' 'J13' 'Q819' 'D610' 'I219' 'Q934' 'Y14' 'K559' 'Q620' 'G919'\n",
      " 'G111' 'E343' 'Q390' 'E348' 'C925' 'Q219' 'Q221' 'D65' 'E232' 'Q400'\n",
      " 'E161' 'Q915' 'K565' 'W20' 'A084' 'Y04' 'I471' 'D487' 'C910' 'Q549' 'Y33'\n",
      " 'P965' 'A080' 'D480' 'J841' 'Y00' 'E250' 'G908' 'M303' 'I313' 'P769'\n",
      " 'Q649' 'K561' 'R568' 'J90' 'R739' 'Q808' 'C920' 'C716' 'I509' 'P701'\n",
      " 'P082' 'I251' 'Q264' 'G120' 'A879' 'E878' 'E770' 'K740' 'I99' 'G128'\n",
      " 'Q623' 'Y071' 'I639' 'Y12' 'W31' 'J939' 'G911' 'Q348' 'Y833' 'M622'\n",
      " 'E744' 'B378' 'Q423' 'B399' 'I270' 'J450' 'B332' 'Y061' 'M841' 'I288'\n",
      " 'P809' 'G918' 'K859' 'G809' 'P019' 'D591' 'A403' 'G404' 'K769' 'Q938'\n",
      " 'V439' 'Q288' 'Q891' 'P393' 'P560' 'G060' 'W73' 'N049' 'R402' 'Y430'\n",
      " 'A509' 'J041' 'R048' 'C951' 'J155' 'Y836' 'I822' 'Y832' 'D759' 'P009'\n",
      " 'A86' 'J100' 'J81' 'D806' 'V476' 'P025' 'Q564' 'K37' 'X97' 'M246' 'R068'\n",
      " 'J111' 'P501' 'D410' 'I269' 'M889' 'I249' 'P550' 'V092' 'P613' 'I501'\n",
      " 'Q439' 'P394' 'I425' 'P610' 'P788' 'A370' 'Q932' 'B379' 'Y078' 'E870'\n",
      " 'I741' 'Q645' 'X09' 'K720' 'R98' 'G122' 'N258' 'G936' 'C717' 'I513'\n",
      " 'Q411' 'A409' 'Q778' 'E230' 'P53' 'J158' 'A491' 'I461' 'Q070' 'R11'\n",
      " 'B449' 'D580' 'V499' 'N320' 'A021' 'K761' 'Q600' 'Q959' 'Q873' 'C929'\n",
      " 'Q239' 'E874' 'P029' 'J09' 'K228' 'G001' 'D696' 'Q402' 'Q391' 'R629'\n",
      " 'E849' 'P359' 'P599' 'Q668' 'P559' 'P961' 'J208' 'I472' 'I059' 'B007'\n",
      " 'D619' 'E742' 'J151' 'P545' 'E740' 'K567' 'K598' 'P120' 'A051' 'I749'\n",
      " 'A870' 'B377' 'Q631' 'W22' 'I490' 'I633' 'Y605' 'X94' 'Q338' 'Q430'\n",
      " 'K255' 'Q829' 'D819' 'E782' 'L299' 'K529' 'C222' 'D758' 'P150' 'Q206'\n",
      " 'Y01' 'N288' 'K746' 'P700' 'Y03' 'P283' 'X99' 'D694' 'Q773' 'K402' 'I500'\n",
      " 'R298' 'J122' 'Q791' 'I710' 'P525' 'P363' 'Q758' 'E778' 'J459' 'J989'\n",
      " 'K767' 'C499' 'R628' 'Q978' 'R02' 'A599' 'R18' 'B258' 'A412' 'Q740'\n",
      " 'E830' 'M318' 'P918' 'G042' 'I773' 'K223' 'P372' 'X41' 'J851' 'B179'\n",
      " 'K741' 'K922' 'P781' 'K593' 'J150' 'M629' 'C762' 'P043' 'E723' 'E274'\n",
      " 'E320' 'Q233' 'Q776' 'A047' 'W44' 'I899' 'K404' 'Q931' 'X590' 'J387'\n",
      " 'Q280' 'P252' 'G961' 'J159' 'Q332' 'P611' 'E785' 'P38' 'J449' 'J156'\n",
      " 'J399' 'W54' 'Q044' 'Q559' 'E876' 'D760' 'I829' 'Q060' 'X42' 'B341'\n",
      " 'G473' 'V890' 'M319' 'J439' 'Q513' 'R570' 'R784' 'J050' 'G403' 'V887'\n",
      " 'Q222' 'D573' 'E840' 'Q621' 'V536' 'Q675' 'B250' 'Q911' 'G628' 'I679'\n",
      " 'G935' 'Q310' 'G939' 'E803' 'X37' 'K221' 'C229' 'N10' 'Q777' 'G121'\n",
      " 'R788' 'K296' 'I740' 'K759' 'V496' 'Q782' 'M009' 'J029' 'R609' 'D180'\n",
      " 'K929' 'G710' 'P579' 'D469' 'F069' 'C950' 'B206' 'P929' 'P243' 'P139'\n",
      " 'E550' 'L988' 'J110' 'R688' 'Y05' 'I739' 'J040' 'D572' 'I258' 'E835'\n",
      " 'I779']\n",
      "Column 'record_2': ['P285' 'I469' '1' 'B349' 'P290' 'P073' 'J969' '2' 'P219' 'P282' 'P523'\n",
      " 'P220' 'M480' 'T71' 'P250' 'R090' 'P269' 'I429' 'P072' 'P209' 'P008'\n",
      " 'Q249' 'A419' 'I272' 'T07' 'Q251' 'I959' 'T179' '3' 'E875' 'J961' 'P293'\n",
      " 'Q040' 'I958' 'J841' 'R688' 'Q210' 'P012' 'P368' 'K729' 'I519' 'P522'\n",
      " 'Q336' 'P044' 'R99' 'K750' 'A415' 'E872' 'P369' 'P001' 'P291' 'B377'\n",
      " 'P059' 'C749' 'P916' 'P240' 'Q212' 'Q111' 'I509' 'I288' 'P280' 'S069'\n",
      " 'P832' 'I279' 'Q606' 'T670' 'P251' 'I471' 'P77' 'P239' 'N320' 'P022'\n",
      " 'Q899' 'G919' 'C793' 'I461' 'E889' 'R092' 'P783' 'K449' 'R068' 'E841'\n",
      " 'A499' 'P229' 'J984' 'P288' 'Q079' 'Q059' 'N19' 'T149' 'P284' 'D70'\n",
      " 'J939' 'S099' 'P027' 'P529' 'D689' 'A090' 'P292' 'J42' 'D821' 'D181'\n",
      " 'Q928' 'J156' 'P011' 'I615' 'Q359' 'K768' 'G938' 'G934' 'J154' 'Q917'\n",
      " 'P210' 'A029' 'K659' 'N138' 'P039' 'P614' 'P025' 'J398' 'A498' 'D65'\n",
      " 'F982' 'T751' 'I629' 'P010' 'N185' 'P968' 'P021' 'A402' 'A490' 'G419'\n",
      " 'Q000' 'I424' 'G936' 'I500' 'Q211' 'D432' 'T436' 'E878' 'Q262' 'P524'\n",
      " 'K668' 'Q043' 'P521' 'P020' 'R579' 'Q789' 'P90' 'P960' 'I64' 'P000' 'B99'\n",
      " 'P271' 'T432' 'E86' 'Q792' 'I518' 'J209' 'R570' 'P015' 'K566' 'J180' '4'\n",
      " 'I99' 'G931' 'P024' 'K318' 'B342' 'G473' 'P232' 'J860' 'P018' 'E039'\n",
      " 'E880' 'D696' 'Q250' 'I829' 'S299' 'T403' 'J181' 'J81' 'J40' 'Q909'\n",
      " 'A410' 'S061' 'K559' 'N179' 'E232' 'J219' 'I458' 'P023' 'I219' 'I510'\n",
      " 'J371' 'B341' 'P003' 'E274' 'J840' 'Q257' 'I420' 'G809' 'G08' 'R571'\n",
      " 'S224' 'G129' 'P360' 'C64' 'D728' 'I678' 'P038' 'I269' 'Q790' 'P969'\n",
      " 'P60' 'G120' 'I319' 'Q213' 'K550' 'Q02' 'J129' 'I330' 'K070' 'C780'\n",
      " 'P720' 'J849' 'I248' 'I898' 'Q230' 'P013' 'P741' 'E710' 'K638' 'Q042'\n",
      " 'J152' 'J988' 'I422' 'K639' 'G318' 'E230' 'I802' 'I709' 'P034' 'P071'\n",
      " 'J189' 'N288' 'R098' 'I301' 'K766' 'P548' 'N328' 'S040' 'S020' 'P261'\n",
      " 'P364' 'Q911' 'I442' 'Q793' 'K265' 'M628' 'D749' 'R628' 'I459' 'J930'\n",
      " 'P051' 'Q234' 'Q602' 'G935' 'K409' 'T300' 'T210' 'C719' 'D649' 'N289'\n",
      " 'P704' 'P253' 'J980' 'Q999' 'Q030' 'P780' 'P029' 'I749' 'P611' 'M329'\n",
      " 'E46' 'J690' 'K720' 'J960' 'G008' 'K561' 'A418' 'B948' 'S079' 'E803'\n",
      " 'A403' 'Q264' 'Q913' 'G910' 'G98' 'Q639' 'I472' 'T599' 'Q245' 'Q031'\n",
      " 'N139' 'D45' 'Q419' 'I251' 'E742' 'D582' 'P005' 'I10' 'P109' 'K562'\n",
      " 'G039' 'M844' 'N133' 'I639' 'G918' 'D849' 'Q300' 'I501' 'A413' 'I499'\n",
      " 'E031' 'B49' 'D761' 'I313' 'P112' 'Q791' 'D471' 'B348' 'D571' 'I38'\n",
      " 'I370' 'H351' 'Q255' 'G711' 'B199' 'G122' 'P612' 'P249' 'Q998' 'R34'\n",
      " 'P036' 'R509' 'P139' 'H052' 'Q611' 'G002' 'D561' 'G839' 'G253' 'P701'\n",
      " 'E877' 'E833' 'P042' 'I517' 'T405' 'Q771' 'Q898' 'I871' 'R568' 'E722'\n",
      " 'K598' 'P912' 'T450' 'D589' 'N369' 'P549' 'Q231' 'P702' 'Q200' 'J069'\n",
      " 'J150' 'I609' 'J942' 'P399' 'T099' 'R629' 'F89' 'J041' 'P546' 'I249'\n",
      " 'J80' 'T598' 'J989' 'Q369' 'I779' 'M622' 'I120' 'N049' 'G939' 'J950'\n",
      " 'N189' 'A509' 'P298' 'I259' 'R048' 'T019' 'S019' 'S320' 'D758' 'P017'\n",
      " 'Q423' 'Q240' 'P070' 'R95' 'T828' 'P006' 'K590' 'B259' 'P043' 'E871'\n",
      " 'E161' 'R560' 'P002' 'P508' 'Q439' 'D801' 'J348' 'J155' 'Q871' 'D695'\n",
      " 'B340' 'P942' 'E870' 'Q742' 'P289' 'S219' 'Q601' 'P016' 'Q987' 'R634'\n",
      " 'K219' 'K631' 'G709' 'A491' 'L988' 'P964' 'Q390' 'K831' 'T509' 'Q039'\n",
      " 'Q232' 'Q743' 'D480' 'L88' 'K315' 'E559' 'P252' 'P101' 'Q897' 'K760'\n",
      " 'E143' 'J90' 'S361' 'P528' 'D694' 'C920' 'S223' 'A099' 'D481' 'I409'\n",
      " 'T503' 'K769' 'J00' 'G319' 'J439' 'E162' 'A080' 'R298' 'G932' 'B004'\n",
      " 'J042' 'P049' 'Q410' 'H905' 'J13' 'P544' 'P299' 'Q378' 'P268' 'E790'\n",
      " 'Q927' 'Q614' 'Q645' 'Q248' 'S098' 'Q019' 'A401' 'T406' 'Q442' 'P361'\n",
      " 'P543' 'P700' 'S065' 'J151' 'I516' 'Q894' 'I822' 'I400' 'I350' 'J040'\n",
      " 'D619' 'I823' 'Q433' 'Q049' 'S029' 'Q189' 'K805' 'S068' 'G048' 'A409'\n",
      " 'E724' 'P352' 'G409' 'Q688' 'K529' 'T858' 'Q322' 'P359' 'Q242' 'I260'\n",
      " 'J121' 'J450' 'T887' 'Q379' 'N390' 'Q878' 'P788' 'I619' 'E668' 'G978'\n",
      " 'D820' 'S028' 'J386' 'J101' 'R060' 'I739' 'S090' 'R233' 'Q893' 'Q201'\n",
      " 'G968' 'P504' 'P910' 'A481' 'I059' 'Q333' 'P236' 'H919' 'G049' 'P362'\n",
      " 'P294' 'E349' 'R91' 'J22' 'Q112' 'B250' 'Q269' 'G824' 'Q872' 'Q870'\n",
      " 'K922' 'Q229' 'Q223' 'K661' 'D818' 'E701' 'H669' 'T178' 'K828' 'S212'\n",
      " 'K721' 'I890' 'E740' 'B464' 'P748' 'Q749' 'Q221' 'G042' 'J153' 'D819'\n",
      " 'G969' 'S399' 'I788' 'P781' 'I808' 'I611' 'Q204' 'P599' 'I620' 'J448'\n",
      " 'P279' 'A412' 'R198' 'B378' 'D732' 'E343' 'Q795' 'R008' 'S097' 'J380'\n",
      " 'I253' 'G248' 'G712' 'Q620' 'J128' 'G911' 'K650' 'T141' 'M436' 'T68'\n",
      " 'B182' 'E835' 'E831' 'K439' 'P281' 'S066' 'D735' 'M245' 'E321' 'D692'\n",
      " 'K088' 'P030' 'Q338' 'J108' 'Q613' 'E278' 'N324' 'E723' 'J218' 'J958'\n",
      " 'R900' 'Q203' 'G713' 'J210' 'P120' 'I514' 'Q890' 'J159' 'E268' 'D573'\n",
      " 'J120' 'D685' 'S360' 'G508' 'P592' 'P526' 'T819' 'T818' 'B59' 'T426'\n",
      " 'P035' 'T862' 'S273' 'M439' 'Q253' 'H358' 'R58' 'A084' 'P378' 'E849'\n",
      " 'Q038' 'Q226' 'D370' 'Q048' 'D489' 'Q046' 'T58' 'B379' 'P009' 'Q288'\n",
      " 'P200' 'T860' 'Q969' 'T810' 'A429' 'E669' 'R02' 'D487' 'F79' 'Q339'\n",
      " 'P351' 'P238' 'D66' 'M869' 'K071' 'T317' 'E713' 'S131' 'M418' 'M879'\n",
      " 'R190' 'S250' 'E149' 'Q935' 'T981' 'S420' 'I490' 'K567' 'P159' 'J111'\n",
      " 'D500' 'P028' 'Q643' 'Q619' 'A492' 'T404' 'A879' 'R943' 'R470' 'P365'\n",
      " 'Q233' 'T402' 'G009' 'N309' 'J440' 'R064' 'S270' 'Q447' 'Q605' 'P392'\n",
      " 'H544' 'Q238' 'I421' 'C80' 'Q321' 'D899' 'I700' 'A411' 'J122' 'E785'\n",
      " 'Q068' 'N998' 'G001' 'T029' 'I614' 'Q774' 'D739' 'T983' 'P201' 'T817'\n",
      " 'R230' 'G600' 'E639' 'I773' 'I710' 'Q224' 'D180' 'R578' 'Q348' 'I351'\n",
      " 'J385' 'B371' 'E744' 'Q228' 'D469' 'Q446' 'Q256' 'N990' 'I48' 'H540'\n",
      " 'E271' 'E43' 'P004' 'P590' 'P026' 'I258' 'P241' 'P154' 'Q699' 'M303'\n",
      " 'E569' 'I050']\n",
      "Column 'record_3': ['P290' 'R011' '1' 'P285' 'R579' '2' 'P369' '3' 'R578' 'P219' 'P269'\n",
      " 'I272' 'P072' 'I279' 'J969' 'J984' 'Q790' 'P543' 'Q257' 'W80' 'Q336'\n",
      " 'N19' 'R278' 'R092' 'Q300' 'P280' 'P293' 'Q249' 'P209' 'P77' 'R001'\n",
      " 'K566' 'P523' 'P780' 'P059' 'I469' 'P549' 'P006' 'R048' 'P378' 'P968'\n",
      " 'R99' 'S399' 'Q255' 'P522' 'P288' 'G002' 'P070' 'P368' 'I509' 'P220'\n",
      " 'P90' 'J960' 'Q442' 'P073' 'N288' 'P60' 'J961' 'Q042' 'E875' 'S199'\n",
      " 'Q213' 'P916' 'T71' 'Q039' 'T149' 'K550' 'Y34' 'P240' 'I442' 'P832'\n",
      " 'Q938' 'K720' 'E722' 'Q668' 'P529' 'I694' 'I959' 'P249' 'G039' 'P012'\n",
      " 'R570' 'Q639' 'P741' 'Q069' 'P291' 'K228' 'J152' 'B341' 'E872' 'P701'\n",
      " 'H919' 'P546' 'K729' 'P027' 'I514' 'J154' 'S099' 'Q212' 'P051' 'Q897'\n",
      " 'Q909' 'T509' 'K297' 'Q234' 'P364' 'Q201' 'Q894' 'E889' 'P039' 'Q423'\n",
      " 'Q225' 'Q200' 'Q204' 'P044' 'Q019' 'Q049' 'Q172' 'Q804' 'Q211' 'J189'\n",
      " 'P251' 'G938' 'Q030' 'P011' 'Q189' '4' 'K631' 'T273' 'N179' 'G419' 'R688'\n",
      " 'I288' 'Q012' 'Q793' 'R95' 'I500' 'Q792' 'J439' 'P018' 'P239' 'Q872'\n",
      " 'Y12' 'P960' 'G931' 'Q311' 'Q379' 'S065' 'G008' 'I499' 'Q675' 'Q899'\n",
      " 'I620' 'J386' 'Q898' 'B348' 'R599' 'P362' 'G936' 'Q264' 'P524' 'P021'\n",
      " 'I739' 'Q229' 'Q256' 'P229' 'Q602' 'I429' 'I729' 'Q043' 'Q210' 'I518'\n",
      " 'R160' 'Q913' 'W75' 'I678' 'K760' 'Q031' 'K559' 'Q232' 'E343' 'P399'\n",
      " 'P015' 'J690' 'Q270' 'J80' 'K868' 'R090' 'P043' 'J980' 'I48' 'Q079'\n",
      " 'G935' 'R509' 'G08' 'Q917' 'R739' 'A415' 'I400' 'Q048' 'R18' 'K831'\n",
      " 'D696' 'I629' 'S058' 'T751' 'T179' 'A498' 'Q613' 'E713' 'N133' 'Q250'\n",
      " 'J81' 'R068' 'T436' 'T809' 'Q279' 'R568' 'Q871' 'G409' 'Q795' 'Q224'\n",
      " 'J988' 'P115' 'T598' 'G932' 'P722' 'I639' 'J398' 'S299' 'D65' 'I319'\n",
      " 'I615' 'Q220' 'P271' 'I424' 'P000' 'Y11' 'I99' 'Q859' 'I829' 'I64' 'G049'\n",
      " 'D619' 'Q614' 'Q870' 'P769' 'D682' 'D489' 'I749' 'Q789' 'J218' 'Q228'\n",
      " 'J986' 'Q251' 'Q750' 'J111' 'I498' 'P783' 'Q203' 'Q429' 'Q038' 'P130'\n",
      " 'Q321' 'Q262' 'E871' 'P292' 'N302' 'P528' 'Q000' 'P022' 'P250' 'P298'\n",
      " 'G934' 'K767' 'G919' 'J90' 'R628' 'R098' 'P614' 'D582' 'J180' 'D70'\n",
      " 'Q999' 'Q984' 'G809' 'J159' 'P704' 'J939' 'Q040' 'Q02' 'Q188' 'Q059'\n",
      " 'Q773' 'Q439' 'Q231' 'I289' 'Q933' 'A419' 'Q851' 'E669' 'I422' 'Q699'\n",
      " 'J122' 'T749' 'Q759' 'J860' 'J930' 'Q248' 'R11' 'T758' 'T828' 'P352'\n",
      " 'P351' 'P548' 'A481' 'P504' 'M622' 'S061' 'I510' 'R162' 'D689' 'R53'\n",
      " 'I517' 'Q226' 'I872' 'Q432' 'P010' 'K562' 'J22' 'S269' 'F982' 'T450'\n",
      " 'E274' 'P612' 'Q438' 'Q315' 'R198' 'Q620' 'E161' 'J450' 'N049' 'K219'\n",
      " 'P961' 'P969' 'P781' 'E877' 'N390' 'A490' 'T141' 'T091' 'S350' 'T740'\n",
      " 'Q927' 'N185' 'P028' 'Y840' 'P034' 'N289' 'P008' 'R14' 'P920' 'Q283'\n",
      " 'P592' 'P016' 'P071' 'J069' 'P038' 'P026' 'S062' 'G918' 'K070' 'E878'\n",
      " 'S318' 'J219' 'Y433' 'P036' 'T748' 'T679' 'J158' 'P284' 'T099' 'Q447'\n",
      " 'I709' 'Q601' 'I471' 'R060' 'P210' 'A491' 'R571' 'T817' 'P375' 'E744'\n",
      " 'P361' 'E870' 'Q390' 'P279' 'P023' 'P289' 'K659' 'J205' 'P910' 'E873'\n",
      " 'K638' 'Q798' 'T818' 'X44' 'S729' 'P031' 'T670' 'T402' 'N170' 'Q339'\n",
      " 'E86' 'Q179' 'Q998' 'P049' 'W78' 'N189' 'R298' 'K902' 'K469' 'J387'\n",
      " 'B379' 'Q680' 'P030' 'P526' 'T811' 'Q935' 'J210' 'Q044' 'D761' 'Q606'\n",
      " 'T730' 'P258' 'P363' 'K318' 'I619' 'K746' 'S066' 'R13' 'R230' 'K567'\n",
      " 'Q782' 'R238' 'S242' 'Y20' 'E46' 'I269' 'Q254' 'Q230' 'J051' 'E725'\n",
      " 'J849' 'S129' 'P236' 'Q969' 'S069' 'D735' 'T810' 'I609' 'Y832' 'G911'\n",
      " 'P550' 'J209' 'V892' 'I219' 'P545' 'Y848' 'M311' 'Q753' 'J40' 'Q410'\n",
      " 'S029' 'T403' 'K529' 'P525' 'I248' 'I741' 'K766' 'P398' 'I491' 'Q261'\n",
      " 'Q070' 'T07' 'Q130' 'Q268' 'I788' 'E222' 'R58' 'D487' 'X58' 'I425' 'Q642'\n",
      " 'T741' 'K768' 'Q182' 'Q221' 'K661' 'K561' 'P253' 'P232' 'R488' 'R529'\n",
      " 'K650' 'P914' 'Q273' 'B449' 'R629' 'D471' 'E213' 'R900' 'I441' 'Q688'\n",
      " 'J869' 'K740' 'P559' 'P025' 'K20' 'H669' 'I459' 'R470' 'J989' 'P042'\n",
      " 'Q141' 'Q223' 'S297' 'Q269' 'Y08' 'I802' 'S301' 'Q643' 'J82' 'T699'\n",
      " 'Q743' 'E109' 'M139' 'T860' 'P509' 'T189' 'Q780' 'I898' 'T319' 'Q742'\n",
      " 'S068' 'W84' 'P912' 'R402' 'R601' 'Y834' 'Q893' 'Q289' 'P700' 'R064'\n",
      " 'S361' 'I050' 'Y839' 'J121' 'N47' 'G318' 'Q874' 'T025' 'D762' 'V877'\n",
      " 'Y830' 'Q873' 'R609' 'V499' 'P158' 'C229' 'M954' 'C798' 'P365' 'K265'\n",
      " 'S368' 'P020' 'Q333' 'A499' 'B49' 'S064' 'L989' 'I633' 'J950' 'P252'\n",
      " 'T862' 'Q419' 'P241' 'S423' 'N320' 'Q431' 'J852' 'P294' 'K920' 'Q392'\n",
      " 'Q359' 'S420' 'N139' 'T58' 'P521' 'E849' 'J940' 'J120' 'R91' 'E209'\n",
      " 'Q443' 'I458' 'C64' 'S278' 'T829' 'Y871' 'S528' 'Y069' 'Q349' 'P003'\n",
      " 'T424' 'P360' 'J958' 'R222' 'D685' 'J981' 'G838' 'K319' 'S273' 'K565'\n",
      " 'W33' 'R680' 'R946' 'N324' 'Q878' 'N135' 'I472' 'T406' 'Q772' 'P112'\n",
      " 'J380' 'P833' 'Q771' 'R931' 'Q758' 'I38' 'W79' 'P048' 'Q382' 'E039'\n",
      " 'D589' 'K918' 'X590' 'P721' 'Q811' 'I850' 'Y883' 'C795' 'Q259' 'T864'\n",
      " 'Q245' 'F79' 'Q633' 'R34' 'Q891' 'I10' 'I371' 'P281' 'P024' 'T465' 'S224'\n",
      " 'Q320' 'C780' 'N137' 'M898' 'P230' 'Q318' 'I409' 'Q600' 'D849' 'J123'\n",
      " 'J42' 'Q241' 'L208' 'P017' 'N309' 'R740' 'Q648' 'Q309' 'Q338' 'T802'\n",
      " 'S009' 'P558' 'Q233' 'J348']\n",
      "Column 'record_4': ['R688' '1' '2' 'P529' '3' 'P072' 'P299' 'I509' 'P220' 'P549' 'P020'\n",
      " 'R568' 'R99' 'Q359' 'P293' 'Q336' 'P251' 'P271' 'P073' 'P285' 'Q438'\n",
      " 'P042' 'Q792' 'P070' 'Q913' 'P960' 'Q213' 'P612' 'Q688' 'P916' 'Q039'\n",
      " 'P780' 'R068' 'J969' 'P369' 'P523' 'Q150' 'P209' 'P77' 'Q613' 'Q998'\n",
      " 'Q249' 'P269' 'T71' 'Q390' 'Y34' 'K566' 'K721' 'Q044' 'P291' 'E875'\n",
      " 'Q410' 'P614' 'P290' 'Q917' 'P288' 'K659' 'J988' 'I272' 'K529' 'R629'\n",
      " 'Q250' 'K831' 'J81' 'J159' 'Q268' 'Q201' 'J984' 'Q223' 'Q606' 'P219'\n",
      " 'R092' 'Q614' 'P700' 'R579' 'Q759' 'X41' 'Q210' 'Q251' 'N19' 'J152'\n",
      " 'R090' 'K729' '4' 'T300' 'R570' 'I469' 'I678' 'Q600' 'Q283' 'Q897' 'Q392'\n",
      " 'I501' 'J80' 'P284' 'J960' 'P60' 'R95' 'Q790' 'Q874' 'Q233' 'K904' 'T099'\n",
      " 'H351' 'J150' 'S223' 'N179' 'Q794' 'G409' 'R628' 'K720' 'T436' 'P250'\n",
      " 'Q909' 'P292' 'P289' 'Q899' 'R278' 'Q211' 'R060' 'Q999' 'P832' 'K562'\n",
      " 'Q278' 'Q678' 'I64' 'T149' 'I822' 'Q042' 'J980' 'Q255' 'P543' 'N12'\n",
      " 'K632' 'S099' 'W80' 'D696' 'I420' 'I517' 'P281' 'P90' 'J189' 'I959'\n",
      " 'T509' 'Y848' 'P362' 'Q048' 'P522' 'I879' 'Q040' 'Q878' 'Q230' 'P158'\n",
      " 'P298' 'K550' 'Q602' 'Q938' 'K913' 'P059' 'K829' 'P912' 'P833' 'Q764'\n",
      " 'E833' 'T751' 'Q262' 'P210' 'P038' 'Q02' 'Q256' 'R701' 'P015' 'Q870'\n",
      " 'Q232' 'Y433' 'Q248' 'Q031' 'R298' 'I451' 'Q212' 'I639' 'M622' 'Q320'\n",
      " 'K929' 'Q934' 'P398' 'K219' 'Q898' 'I615' 'P280' 'Q111' 'Q423' 'Q928'\n",
      " 'S399' 'Q431' 'I871' 'P011' 'P526' 'P028' 'Q231' 'P378' 'P592' 'Q049'\n",
      " 'J218' 'P548' 'T179' 'P241' 'E86' 'I490' 'P783' 'I620' 'J40' 'P968'\n",
      " 'L989' 'J942' 'Q872' 'P279' 'P910' 'I898' 'J981' 'Q246' 'K766' 'W75'\n",
      " 'S068' 'P000' 'J961' 'P524' 'K759' 'Q935' 'Q969' 'Q228' 'P613' 'P234'\n",
      " 'Q200' 'Y832' 'Q348' 'R58' 'B377' 'R571' 'N328' 'T462' 'E872' 'J690'\n",
      " 'R638' 'J939' 'R18' 'S299' 'G404' 'Q234' 'G919' 'Q791' 'Q349' 'Q668'\n",
      " 'P229' 'R001' 'T07' 'K639' 'J958' 'T828' 'D65' 'T141' 'T814' 'S368'\n",
      " 'R048' 'N289' 'Q189' 'Q203' 'Q419' 'Q059' 'Q391' 'J180' 'Q799' 'P231'\n",
      " 'P027' 'S199' 'S224' 'Q225' 'P819' 'S065' 'Q245' 'P588' 'Y061' 'R17'\n",
      " 'R34' 'P704' 'D689' 'Y834' 'R740' 'G936' 'P781' 'R064' 'J208' 'P352'\n",
      " 'T818' 'I629' 'T512' 'I510' 'N390' 'T424' 'I10' 'Q379' 'P034' 'T730'\n",
      " 'Q871' 'I99' 'B348' 'Q270' 'R02' 'Q793' 'Y839' 'K660' 'T740' 'K631'\n",
      " 'Q620' 'K228' 'J398' 'Q258' 'W78' 'Q038' 'P368' 'G419' 'I829' 'P364'\n",
      " 'N280' 'Q378' 'Q254' 'J22' 'S066' 'P023' 'Q639' 'J069' 'Y069' 'Q279'\n",
      " 'N185' 'P701' 'T749' 'P702' 'R233' 'T426' 'P528' 'I779' 'K559' 'Q019'\n",
      " 'K650' 'Q642' 'J849' 'P150' 'G003' 'G08' 'H540' 'N133' 'P051' 'Q753'\n",
      " 'K668' 'D695' 'Q011' 'N288' 'Q645' 'T790' 'Q442' 'I500' 'D735' 'P253'\n",
      " 'G319' 'R13' 'J380' 'X85' 'R633' 'J210' 'Q204' 'R578' 'Q929' 'P360'\n",
      " 'Q143' 'T748' 'S369' 'Q058' 'J154' 'Q890' 'P021' 'T450' 'Q046' 'J386'\n",
      " 'P361' 'R000' 'P545' 'Q605' 'R75' 'P740' 'R11' 'K768' 'K922' 'Q288'\n",
      " 'I429' 'T812' 'P616' 'R198' 'Q628' 'Q798' 'S362' 'J450' 'J155' 'S069'\n",
      " 'Q338' 'T859' 'X599' 'Q300' 'V892' 'S061' 'S064' 'D619' 'G935' 'T810'\n",
      " 'N200' 'T111' 'P399' 'J860' 'Q789' 'Y20' 'Q623' 'T142' 'Q743' 'Y830'\n",
      " 'W79' 'J42' 'P134' 'P363' 'P741' 'Q601' 'J219' 'Q768' 'J158' 'E274'\n",
      " 'E878' 'P351' 'D70' 'T189' 'Q749' 'J111' 'M898' 'T140' 'N189' 'Q070'\n",
      " 'P036' 'M869' 'P948' 'R601' 'Q893' 'E550' 'R14' 'Q795' 'P961' 'R509'\n",
      " 'J982' 'R230' 'P239' 'Q970' 'Q240' 'J439' 'E880' 'T827' 'P071' 'I619'\n",
      " 'Q043' 'I518' 'Q402' 'Q873' 'G001' 'N170' 'K902' 'Q282' 'R609' 'Q030'\n",
      " 'Q892' 'Q611' 'P039' 'V031' 'P240' 'Q773' 'I424' 'R798' 'B009' 'P030'\n",
      " 'S268' 'G918' 'I38' 'Q322' 'P235' 'J930' 'Q447' 'W33' 'R400' 'I288'\n",
      " 'J840' 'T598' 'Q323' 'R938' 'Q333' 'K767' 'P044' 'Q388' 'Q621' 'Y841'\n",
      " 'J00' 'P012' 'P521' 'S090' 'Y12' 'Y33' 'Q134' 'S269']\n",
      "Column 'record_5': ['2' '1' '3' 'Q790' 'P220' 'Q248' 'P285' 'Q614' 'R688' 'P250' 'Q909'\n",
      " 'Q255' 'R579' 'P015' 'P612' 'Q433' 'P523' 'R048' 'Q379' 'Q764' 'P073'\n",
      " 'N390' 'R278' 'K720' 'Q423' 'P90' 'Q210' 'M489' 'I615' 'K668' 'Q999'\n",
      " 'R568' 'M898' 'P209' 'J189' 'Q043' 'R578' 'P280' 'Q250' '4' 'R090' 'R092'\n",
      " 'R628' 'N19' 'I678' 'J969' 'P60' 'P072' 'P293' 'J961' 'P290' 'P369'\n",
      " 'I469' 'J152' 'Q793' 'S273' 'P364' 'P044' 'G931' 'Q213' 'N179' 'X85'\n",
      " 'Q201' 'P229' 'P291' 'Q620' 'P284' 'T71' 'R99' 'R263' 'P916' 'Q939'\n",
      " 'P701' 'Q871' 'Q254' 'J988' 'Q792' 'P362' 'J984' 'P288' 'Q390' 'P368'\n",
      " 'R570' 'Q249' 'Q230' 'S372' 'K913' 'T741' 'J81' 'Q234' 'Q899' 'J219'\n",
      " 'Q898' 'Q203' 'P239' 'Q212' 'T510' 'K746' 'Q645' 'P021' 'R160' 'R571'\n",
      " 'Q048' 'P960' 'Q890' 'Q668' 'R17' 'Q336' 'Q984' 'Q040' 'K631' 'P269'\n",
      " 'Q401' 'P375' 'R060' 'R633' 'R100' 'K768' 'P968' 'P832' 'P009' 'P522'\n",
      " 'R601' 'P549' 'X599' 'P529' 'R068' 'I509' 'Q204' 'Q969' 'N189' 'N133'\n",
      " 'P704' 'Q200' 'Q070' 'Q828' 'J180' 'J398' 'Q231' 'P614' 'Q262' 'J151'\n",
      " 'R011' 'Q602' 'Q860' 'P616' 'Q872' 'Q870' 'P039' 'T149' 'J985' 'R298'\n",
      " 'Q233' 'K760' 'K659' 'Q265' 'T509' 'P592' 'R908' 'R001' 'Q822' 'Q251'\n",
      " 'Q039' 'R34' 'X44' 'P780' 'T818' 'I959' 'P38' 'Q605' 'Q643' 'V892' 'Y831'\n",
      " 'I429' 'Y839' 'S399' 'I619' 'P77' 'Q613' 'P219' 'P292' 'X590' 'P548'\n",
      " 'Q049' 'S099' 'Q743' 'P251' 'Q688' 'Q270' 'Q642' 'E232' 'W80' 'T814'\n",
      " 'Q211' 'Q878' 'Q600' 'R64' 'R18' 'Q678' 'I500' 'T524' 'R509' 'I272'\n",
      " 'Q348' 'Q911' 'I898' 'Q419' 'Q772' 'Q938' 'T179' 'R13' 'P059' 'P025'\n",
      " 'Q897' 'Q320' 'T749' 'E875' 'R748' 'J980' 'J960' 'N288' 'P912' 'Q749'\n",
      " 'P027' 'I639' 'Y09' 'T860' 'Q278' 'P023' 'T430' 'K550' 'J111' 'Q179'\n",
      " 'Q391' 'Q300' 'J981' 'J939' 'P741' 'Q632' 'P599' 'G919' 'N289' 'Q933'\n",
      " 'Q998' 'Q059' 'E872' 'I778' 'T857' 'I99' 'Y34' 'Q246' 'J050' 'S223'\n",
      " 'Q459' 'I633' 'R11' 'R629' 'Q359' 'J80' 'T140' 'J930' 'P070' 'Q606'\n",
      " 'Q776' 'R161' 'Y14' 'Q038' 'P271' 'Q437' 'Y846' 'P702' 'R162' 'Q873'\n",
      " 'P398' 'G08' 'Q130' 'T813' 'S360' 'S363' 'Q392' 'R064' 'Y832' 'Y834'\n",
      " 'S065' 'P521' 'I829' 'Y20' 'P718' 'Q105' 'K758' 'Q02' 'T141' 'P360'\n",
      " 'Q809' 'Q891' 'Q913' 'I871' 'V436' 'N321' 'Q288' 'R230' 'Q917' 'Q169'\n",
      " 'Q601' 'J860' 'P252' 'K831' 'Q798' 'X30' 'P049' 'P524' 'T794' 'T828'\n",
      " 'I499' 'K729' 'Q789' 'P929' 'P051' 'Q928' 'Q225' 'P278' 'P711' 'I629'\n",
      " 'R91' 'P781' 'P298' 'Q321' 'Q189' 'Q639' 'R609' 'P042' 'P071' 'Q257'\n",
      " 'P249' 'Q438' 'Q766' 'Q256' 'R798' 'Q268' 'P038' 'Q228' 'S423' 'J986'\n",
      " 'P378' 'Q232' 'Q279' 'T483' 'X47' 'Q369' 'Q224' 'J439' 'I501' 'S066'\n",
      " 'T740' 'Q799' 'Q929' 'Q558' 'S202']\n",
      "Column 'record_6': ['2' '1' '3' 'R068' 'P291' 'R688' 'P290' 'P960' 'R090' 'Q250' 'T817' 'R18'\n",
      " 'N179' 'R579' 'Q211' 'J09' 'T818' 'P072' 'P285' 'R060' 'Q249' 'Q379' '4'\n",
      " 'P612' 'Q564' 'R092' 'K902' 'P293' 'Q210' 'P051' 'P60' 'Q750' 'Q263'\n",
      " 'Q234' 'K562' 'P000' 'T149' 'Q315' 'I469' 'P209' 'P523' 'P968' 'Q423'\n",
      " 'R628' 'R99' 'Q336' 'X599' 'R570' 'J969' 'Q749' 'Q410' 'J960' 'R568'\n",
      " 'P369' 'Q909' 'X45' 'Y836' 'Q333' 'Q255' 'T71' 'P916' 'Q613' 'Q913'\n",
      " 'M622' 'P288' 'T179' 'Q792' 'Q039' 'I64' 'P529' 'Q264' 'P525' 'P284'\n",
      " 'I518' 'P271' 'R739' 'P278' 'K449' 'P832' 'P90' 'Q256' 'R064' 'Q251'\n",
      " 'P704' 'T796' 'N19' 'P073' 'K729' 'R162' 'S730' 'R298' 'T813' 'P292'\n",
      " 'P780' 'P599' 'S099' 'R629' 'J985' 'R571' 'Q322' 'Q318' 'Q799' 'R048'\n",
      " 'Q254' 'R278' 'Q213' 'Q748' 'Y848' 'J150' 'P969' 'Q999' 'R198' 'Q645'\n",
      " 'Y839' 'Q898' 'R230' 'R601' 'G001' 'Q231' 'Q871' 'R11' 'Q046' 'P399'\n",
      " 'Q766' 'T749' 'I517' 'Q134' 'J860' 'P280' 'W80' 'P281' 'P614' 'P522'\n",
      " 'I99' 'P77' 'Q935' 'J961' 'T812' 'S223' 'Q390' 'K631' 'Q872' 'Q793'\n",
      " 'Q447' 'R58' 'T435' 'Q431' 'P709' 'Q893' 'Q359' 'R900' 'Q742' 'P021'\n",
      " 'I424' 'Y833' 'P219' 'P269' 'P741' 'L989' 'P220' 'I509' 'Q606' 'P240'\n",
      " 'N288' 'Y832' 'K559' 'J209' 'Q600' 'R633' 'R02' 'S368' 'R34' 'P279'\n",
      " 'Q392' 'W79' 'P910' 'Q917' 'Q870' 'J989' 'Q043' 'Q631' 'Q998' 'G936'\n",
      " 'S361' 'S369' 'S069' 'K661' 'N258' 'Q897' 'Y34' 'Q268' 'Q438' 'Q892'\n",
      " 'I500' 'Q791' 'T860' 'P250' 'P588' 'Q678' 'K639' 'P059' 'N189' 'N390'\n",
      " 'Y840' 'Q878' 'Q212' 'J984' 'M844' 'Q933' 'P548' 'Q642' 'P251' 'Q624'\n",
      " 'P239' 'Q688' 'Q969' 'I709' 'K768' 'P550' 'J81' 'P361' 'T855' 'Q330'\n",
      " 'Q790' 'J80' 'J041' 'Q201' 'P701' 'Q248' 'Q278' 'R609' 'R578' 'W33'\n",
      " 'P781' 'R049' 'T811' 'T509' 'T810' 'Y20' 'Q279' 'S224' 'Q899' 'Q349'\n",
      " 'T862']\n",
      "Column 'record_7': ['2' '1' '3' 'P612' 'R092' 'T818' 'P209' 'R688' 'Q251' 'Q200' 'J189'\n",
      " 'Y839' 'P290' 'Q379' 'P298' 'Q431' '4' 'Q250' 'P369' 'P073' 'Q390' 'P961'\n",
      " 'Q764' 'P022' 'P969' 'J969' 'Q391' 'R568' 'Q878' 'Y833' 'Q410' 'Q433'\n",
      " 'Q264' 'R99' 'Q613' 'T436' 'R048' 'W80' 'Q213' 'Q928' 'P60' 'R633' 'Q233'\n",
      " 'Q893' 'P285' 'Q999' 'Q898' 'J984' 'P90' 'X599' 'Q255' 'Q044' 'N179'\n",
      " 'P251' 'Q688' 'R609' 'K831' 'T814' 'R579' 'Q210' 'T179' 'Q792' 'N19'\n",
      " 'Q791' 'Q789' 'R441' 'J80' 'Q913' 'P529' 'R34' 'J960' 'Q333' 'R068'\n",
      " 'Q288' 'X89' 'Q211' 'K227' 'T811' 'Q872' 'P293' 'K729' 'P968' 'Q921'\n",
      " 'R090' 'N189' 'Q614' 'Q909' 'S822' 'R571' 'Q270' 'Q423' 'R570' 'P072'\n",
      " 'T450' 'Q649' 'P832' 'P271' 'P916' 'Q899' 'T149' 'R18' 'P291' 'Q262'\n",
      " 'N288' 'Q212' 'R634' 'Q256' 'T140' 'Q230' 'Q790' 'Q935' 'Q249' 'P592'\n",
      " 'Q048' 'Q860' 'I619' 'Q528' 'T099' 'S370' 'I959' 'T749' 'T796' 'Q809'\n",
      " 'Q263' 'Q225' 'Q897' 'W78' 'Y848' 'R509' 'P780' 'R160' 'S273' 'Q564'\n",
      " 'Y484' 'Q254' 'Q228' 'P059' 'P960' 'P280' 'P288' 'P702' 'P523' 'R53'\n",
      " 'P522' 'P220' 'R13' 'Q248' 'Q204' 'Q336' 'K720' 'P368' 'R628' 'Y840'\n",
      " 'Y832' 'R060' 'Q923' 'Q871' 'Q224' 'R000' 'Y834' 'P912' 'T510' 'P704'\n",
      " 'R943' 'P521' 'Y20' 'Q645' 'S301' 'Q439' 'Y830']\n",
      "Column 'record_8': ['2' '1' '3' 'Q250' 'Y834' 'P285' 'Q392' 'Q211' 'P529' 'Q750' 'Q928' '4'\n",
      " 'P60' 'Q254' 'R090' 'R18' 'Q766' 'Y836' 'T887' 'Q423' 'R092' 'Q539'\n",
      " 'T814' 'X41' 'R601' 'Q320' 'Q251' 'R048' 'Q909' 'Q336' 'Q913' 'R99'\n",
      " 'Q231' 'R570' 'P290' 'N179' 'Y833' 'W80' 'R688' 'T868' 'T179' 'K768'\n",
      " 'R02' 'R571' 'Q999' 'Y839' 'R17' 'N19' 'K659' 'P612' 'P549' 'P614' 'M622'\n",
      " 'R55' 'P90' 'T149' 'Q878' 'Q749' 'T481' 'P280' 'R162' 'R568' 'M419'\n",
      " 'X599' 'P369' 'R609' 'P523' 'P059' 'Q893' 'Q240' 'W78' 'Q256' 'Q210'\n",
      " 'Q794' 'S378' 'J984' 'Q268' 'P291' 'R161' 'P960' 'Q790' 'Q433' 'Q410'\n",
      " 'Q224' 'R579' 'R628' 'R34' 'R068' 'R198' 'J90' 'P293' 'Q255' 'R060' 'Y14'\n",
      " 'P809' 'P522' 'P521' 'T818' 'Q668' 'S424']\n",
      "Column 'record_9': ['2' '1' '3' 'R688' 'Q410' 'Q939' '4' 'P832' 'R092' 'Y579' 'R628' 'Y838'\n",
      " 'Y831' 'R090' 'Q999' 'Q250' 'R568' 'P524' 'Q256' 'Y848' 'W80' 'N19'\n",
      " 'R011' 'P073' 'N179' 'P780' 'P916' 'Q764' 'T509' 'Q02' 'P612' 'R609'\n",
      " 'P290' 'Q248' 'Q909' 'T091' 'Q246' 'R58' 'Q602' 'Q780' 'P291' 'T179'\n",
      " 'J969' 'Q211' 'P072' 'R629' 'Y15' 'R278' 'R570' 'P523' 'T71' 'T090']\n",
      "Column 'record_10': ['2' '1' '3' 'R740' 'Q423' '4' 'P960' 'Q549' 'Q871' 'R048' 'R13' 'Q249'\n",
      " 'P968' 'R571' 'Q043' 'T828' 'Q251' 'Q259' 'T141' 'P038' 'R601' 'P549'\n",
      " 'Q250' 'W80' 'N19' 'Q909' 'Q913' 'P612']\n",
      "Column 'record_11': ['2' '1' '3' '4' 'R34' 'Q631' 'R578' 'Y442' 'R001' 'Q893' 'P271' 'P612'\n",
      " 'R688' 'R278' 'R068' 'Q250']\n",
      "Column 'record_12': ['2' '1' '3' '4' 'Y831' 'R090']\n",
      "Column 'record_13': [2 1 3 4]\n",
      "Column 'record_14': [2 1 3 4]\n",
      "Column 'record_15': [2 1 3 4]\n",
      "Column 'record_16': [2 1 3 4]\n",
      "Column 'record_17': [2 1 3 4]\n",
      "Column 'record_18': [2 1 3 4]\n",
      "Column 'record_19': [2 1 3 4]\n",
      "Column 'record_20': [2 1 3 4]\n",
      "Column 'd_restatus': [2 1 3 4]\n",
      "Column 'hospd': [1 2 4 9 7 3 5 6]\n",
      "Column 'dweekday': [2 7 3 4 5 1 6]\n",
      "Column 'dod_yy': [2015 2016]\n",
      "Column 'dod_mm': [ 1  4  5  2  3  6  7  9  8 12 11 10]\n"
     ]
    }
   ],
   "source": [
    "#Look at the unique values in each column\n",
    "for col in df.columns:\n",
    "    unique_values = df[col].unique()\n",
    "    print(f\"Column '{col}': {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c3f5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23357 entries, 0 to 23356\n",
      "Data columns (total 343 columns):\n",
      " #    Column       Non-Null Count  Dtype  \n",
      "---   ------       --------------  -----  \n",
      " 0    laterec      23357 non-null  int64  \n",
      " 1    dob_yy       23357 non-null  int64  \n",
      " 2    dob_mm       23357 non-null  int64  \n",
      " 3    dob_tt       23357 non-null  int64  \n",
      " 4    dob_wk       23357 non-null  int64  \n",
      " 5    bfacil       23357 non-null  int64  \n",
      " 6    f_bfacil     23357 non-null  int64  \n",
      " 7    bfacil3      23357 non-null  int64  \n",
      " 8    mageimp      23357 non-null  int64  \n",
      " 9    magerep      23357 non-null  int64  \n",
      " 10   mager        23357 non-null  int64  \n",
      " 11   mager14      23357 non-null  int64  \n",
      " 12   mager9       23357 non-null  int64  \n",
      " 13   mbstate_rec  23357 non-null  int64  \n",
      " 14   restatus     23357 non-null  int64  \n",
      " 15   mrace31      23357 non-null  int64  \n",
      " 16   mrace6       23357 non-null  int64  \n",
      " 17   mrace15      23357 non-null  int64  \n",
      " 18   mbrace       23357 non-null  int64  \n",
      " 19   mraceimp     23357 non-null  int64  \n",
      " 20   mhisp_r      23357 non-null  int64  \n",
      " 21   f_mhisp      23357 non-null  int64  \n",
      " 22   mracehisp    23357 non-null  int64  \n",
      " 23   mar_p        23357 non-null  object \n",
      " 24   dmar         23357 non-null  int64  \n",
      " 25   mar_imp      23357 non-null  int64  \n",
      " 26   f_mar_p      23357 non-null  int64  \n",
      " 27   meduc        23357 non-null  int64  \n",
      " 28   f_meduc      23357 non-null  int64  \n",
      " 29   fagerpt_flg  23357 non-null  int64  \n",
      " 30   fagecomb     23357 non-null  int64  \n",
      " 31   fage11       23357 non-null  int64  \n",
      " 32   frace31      23357 non-null  int64  \n",
      " 33   frace6       23357 non-null  int64  \n",
      " 34   frace15      23357 non-null  int64  \n",
      " 35   fbrace       23357 non-null  int64  \n",
      " 36   fhisp_r      23357 non-null  int64  \n",
      " 37   f_fhisp      23357 non-null  int64  \n",
      " 38   fracehisp    23357 non-null  int64  \n",
      " 39   feduc        23357 non-null  int64  \n",
      " 40   f_feduc      23357 non-null  int64  \n",
      " 41   riorlive     23357 non-null  int64  \n",
      " 42   riordead     23357 non-null  int64  \n",
      " 43   riorterm     23357 non-null  int64  \n",
      " 44   lbo_rec      23357 non-null  int64  \n",
      " 45   tbo_rec      23357 non-null  int64  \n",
      " 46   illb_r       23357 non-null  int64  \n",
      " 47   illb_r11     23357 non-null  int64  \n",
      " 48   ilop_r       23357 non-null  int64  \n",
      " 49   ilop_r11     23357 non-null  int64  \n",
      " 50   ilp_r        23357 non-null  int64  \n",
      " 51   ilp_r11      23357 non-null  int64  \n",
      " 52   recare       23357 non-null  int64  \n",
      " 53   f_mpcb       23357 non-null  int64  \n",
      " 54   recare5      23357 non-null  int64  \n",
      " 55   revis        23357 non-null  int64  \n",
      " 56   revis_rec    23357 non-null  int64  \n",
      " 57   f_tpcv       23357 non-null  object \n",
      " 58   wic          23357 non-null  object \n",
      " 59   f_wic        23357 non-null  int64  \n",
      " 60   cig_0        23357 non-null  int64  \n",
      " 61   cig_1        23357 non-null  int64  \n",
      " 62   cig_2        23357 non-null  int64  \n",
      " 63   cig_3        23357 non-null  int64  \n",
      " 64   cig0_r       23357 non-null  int64  \n",
      " 65   cig1_r       23357 non-null  int64  \n",
      " 66   cig2_r       23357 non-null  int64  \n",
      " 67   cig3_r       23357 non-null  int64  \n",
      " 68   f_cigs_0     23357 non-null  object \n",
      " 69   f_cigs_1     23357 non-null  object \n",
      " 70   f_cigs_2     23357 non-null  object \n",
      " 71   f_cigs_3     23357 non-null  object \n",
      " 72   cig_rec      23357 non-null  object \n",
      " 73   f_tobaco     23357 non-null  int64  \n",
      " 74   mhtr         23357 non-null  int64  \n",
      " 75   f_m_ht       23357 non-null  int64  \n",
      " 76   bmi          23357 non-null  float64\n",
      " 77   bmi_r        23357 non-null  int64  \n",
      " 78   wgt_r        23357 non-null  int64  \n",
      " 79   f_pwgt       23357 non-null  int64  \n",
      " 80   dwgt_r       23357 non-null  int64  \n",
      " 81   f_dwgt       23357 non-null  int64  \n",
      " 82   wtgain       23357 non-null  int64  \n",
      " 83   wtgain_rec   23357 non-null  int64  \n",
      " 84   f_wtgain     23357 non-null  object \n",
      " 85   rf_pdiab     23357 non-null  object \n",
      " 86   rf_gdiab     23357 non-null  object \n",
      " 87   rf_phype     23357 non-null  object \n",
      " 88   rf_ghype     23357 non-null  object \n",
      " 89   rf_ehype     23357 non-null  object \n",
      " 90   rf_ppb       23357 non-null  object \n",
      " 91   f_rf_pdiab   23357 non-null  object \n",
      " 92   f_rf_gdiab   23357 non-null  object \n",
      " 93   f_rf_phype   23357 non-null  object \n",
      " 94   f_rf_ghype   23357 non-null  object \n",
      " 95   f_rf_ehype   23357 non-null  object \n",
      " 96   f_rf_ppb     23357 non-null  object \n",
      " 97   rf_inft      23357 non-null  object \n",
      " 98   rf_drg       23357 non-null  object \n",
      " 99   rf_art       23357 non-null  object \n",
      " 100  f_rf_drg     23357 non-null  object \n",
      " 101  f_rf_art     23357 non-null  object \n",
      " 102  rf_cesar     23357 non-null  object \n",
      " 103  rf_cesarn    23357 non-null  int64  \n",
      " 104  f_rf_cesar   23357 non-null  int64  \n",
      " 105  f_rf_ncesar  23357 non-null  int64  \n",
      " 106  no_risks     23357 non-null  int64  \n",
      " 107  ip_gon       23357 non-null  object \n",
      " 108  ip_syph      23357 non-null  object \n",
      " 109  ip_chlam     23357 non-null  object \n",
      " 110  ip_hepb      23357 non-null  object \n",
      " 111  ip_hepc      23357 non-null  object \n",
      " 112  f_ip_gon     23357 non-null  int64  \n",
      " 113  f_ip_syph    23357 non-null  int64  \n",
      " 114  f_ip_chlam   23357 non-null  int64  \n",
      " 115  f_ip_hepb    23357 non-null  int64  \n",
      " 116  f_ip_hepc    23357 non-null  int64  \n",
      " 117  no_infec     23357 non-null  int64  \n",
      " 118  ob_succ      23357 non-null  object \n",
      " 119  ob_fail      23357 non-null  object \n",
      " 120  f_ob_succ    23357 non-null  int64  \n",
      " 121  f_ob_fail    23357 non-null  int64  \n",
      " 122  seqnum_co    23357 non-null  int64  \n",
      " 123  ld_indl      23357 non-null  object \n",
      " 124  ld_augm      23357 non-null  object \n",
      " 125  ld_ster      23357 non-null  object \n",
      " 126  ld_antb      23357 non-null  object \n",
      " 127  ld_chor      23357 non-null  object \n",
      " 128  ld_anes      23357 non-null  object \n",
      " 129  f_ld_indl    23357 non-null  int64  \n",
      " 130  f_ld_augm    23357 non-null  int64  \n",
      " 131  f_ld_ster    23357 non-null  int64  \n",
      " 132  f_ld_antb    23357 non-null  int64  \n",
      " 133  f_ld_chor    23357 non-null  int64  \n",
      " 134  f_ld_anes    23357 non-null  int64  \n",
      " 135  no_lbrdlv    23357 non-null  int64  \n",
      " 136  me_pres      23357 non-null  int64  \n",
      " 137  me_rout      23357 non-null  int64  \n",
      " 138  me_trial     23357 non-null  object \n",
      " 139  f_me_pres    23357 non-null  int64  \n",
      " 140  f_me_rout    23357 non-null  int64  \n",
      " 141  f_me_trial   23357 non-null  int64  \n",
      " 142  rdmeth_rec   23357 non-null  int64  \n",
      " 143  dmeth_rec    23357 non-null  int64  \n",
      " 144  f_dmeth_rec  23357 non-null  object \n",
      " 145  mm_mtr       23357 non-null  object \n",
      " 146  mm_plac      23357 non-null  object \n",
      " 147  mm_rupt      23357 non-null  object \n",
      " 148  mm_uhyst     23357 non-null  object \n",
      " 149  mm_aicu      23357 non-null  object \n",
      " 150  f_mm_mtr     23357 non-null  int64  \n",
      " 151  f_mm_        23357 non-null  int64  \n",
      " 152  f_mm_rupt    23357 non-null  int64  \n",
      " 153  f_mm_uhyst   23357 non-null  int64  \n",
      " 154  f_mm_aicu    23357 non-null  int64  \n",
      " 155  no_mmorb     23357 non-null  int64  \n",
      " 156  attend       23357 non-null  int64  \n",
      " 157  mtran        23357 non-null  object \n",
      " 158  ay           23357 non-null  int64  \n",
      " 159  ay_rec       23357 non-null  int64  \n",
      " 160  f_pay        23357 non-null  int64  \n",
      " 161  f_pay_rec    23357 non-null  int64  \n",
      " 162  apgar5       23357 non-null  int64  \n",
      " 163  apgar5r      23357 non-null  int64  \n",
      " 164  f_apgar5     23357 non-null  int64  \n",
      " 165  apgar10      23357 non-null  int64  \n",
      " 166  apgar10r     23357 non-null  int64  \n",
      " 167  dplural      23357 non-null  int64  \n",
      " 168  imp_plur     23357 non-null  object \n",
      " 169  setorder_r   23357 non-null  object \n",
      " 170  sex          23357 non-null  object \n",
      " 171  imp_sex      23357 non-null  int64  \n",
      " 172  dlmp_mm      23357 non-null  int64  \n",
      " 173  dlmp_yy      23357 non-null  int64  \n",
      " 174  combgst_imp  23357 non-null  int64  \n",
      " 175  obgest_flg   23357 non-null  int64  \n",
      " 176  combgest     23357 non-null  int64  \n",
      " 177  estrec10     23357 non-null  int64  \n",
      " 178  estrec3      23357 non-null  int64  \n",
      " 179  lmpused      23357 non-null  int64  \n",
      " 180  oegest_comb  23357 non-null  int64  \n",
      " 181  oegest_r10   23357 non-null  int64  \n",
      " 182  oegest_r3    23357 non-null  int64  \n",
      " 183  bwtr14       23357 non-null  int64  \n",
      " 184  bwtr4        23357 non-null  int64  \n",
      " 185  brthwgt      23357 non-null  int64  \n",
      " 186  bwtimp       23357 non-null  object \n",
      " 187  ab_aven1     23357 non-null  object \n",
      " 188  ab_aven6     23357 non-null  object \n",
      " 189  ab_nicu      23357 non-null  object \n",
      " 190  ab_surf      23357 non-null  object \n",
      " 191  ab_anti      23357 non-null  object \n",
      " 192  ab_seiz      23357 non-null  object \n",
      " 193  f_ab_aven1   23357 non-null  int64  \n",
      " 194  f_ab_aven6   23357 non-null  int64  \n",
      " 195  f_ab_nicu    23357 non-null  int64  \n",
      " 196  f_ab_surf    23357 non-null  int64  \n",
      " 197  f_ab_anti    23357 non-null  int64  \n",
      " 198  f_ab_seiz    23357 non-null  int64  \n",
      " 199  no_abnorm    23357 non-null  int64  \n",
      " 200  ca_anen      23357 non-null  object \n",
      " 201  ca_mnsb      23357 non-null  object \n",
      " 202  ca_cchd      23357 non-null  object \n",
      " 203  ca_cdh       23357 non-null  object \n",
      " 204  ca_omph      23357 non-null  object \n",
      " 205  ca_gast      23357 non-null  object \n",
      " 206  f_ca_anen    23357 non-null  object \n",
      " 207  f_ca_mnsb    23357 non-null  object \n",
      " 208  f_ca_cchd    23357 non-null  object \n",
      " 209  f_ca_cdh     23357 non-null  object \n",
      " 210  f_ca_omph    23357 non-null  object \n",
      " 211  f_ca_gast    23357 non-null  object \n",
      " 212  ca_limb      23357 non-null  object \n",
      " 213  ca_cleft     23357 non-null  object \n",
      " 214  ca_clpal     23357 non-null  object \n",
      " 215  ca_down      23357 non-null  object \n",
      " 216  ca_disor     23357 non-null  object \n",
      " 217  ca_hypo      23357 non-null  object \n",
      " 218  f_ca_limb    23357 non-null  int64  \n",
      " 219  f_ca_cleft   23357 non-null  int64  \n",
      " 220  f_ca_clpal   23357 non-null  int64  \n",
      " 221  f_ca_down    23357 non-null  int64  \n",
      " 222  f_ca_disor   23357 non-null  int64  \n",
      " 223  f_ca_hypo    23357 non-null  int64  \n",
      " 224  no_congen    23357 non-null  int64  \n",
      " 225  itran        23357 non-null  object \n",
      " 226  ilive        23357 non-null  object \n",
      " 227  bfed         23357 non-null  object \n",
      " 228  f_bfed       23357 non-null  int64  \n",
      " 229  ubfacil      23357 non-null  int64  \n",
      " 230  urf_diab     23357 non-null  int64  \n",
      " 231  urf_chype    23357 non-null  int64  \n",
      " 232  urf_phype    23357 non-null  int64  \n",
      " 233  urf_ehype    23357 non-null  int64  \n",
      " 234  ume_forc     23357 non-null  int64  \n",
      " 235  ume_vacu     23357 non-null  int64  \n",
      " 236  uob_indu     23357 non-null  int64  \n",
      " 237  uld_bree     23357 non-null  int64  \n",
      " 238  uca_anen     23357 non-null  int64  \n",
      " 239  uca_spina    23357 non-null  int64  \n",
      " 240  uca_omph     23357 non-null  int64  \n",
      " 241  uca_clip     23357 non-null  int64  \n",
      " 242  uca_hern     23357 non-null  int64  \n",
      " 243  uca_down     23357 non-null  int64  \n",
      " 244  flgnd        23357 non-null  int64  \n",
      " 245  aged         23357 non-null  int64  \n",
      " 246  ager5        23357 non-null  int64  \n",
      " 247  ager22       23357 non-null  int64  \n",
      " 248  manner       23357 non-null  object \n",
      " 249  dispo        23357 non-null  object \n",
      " 250  autopsy      23357 non-null  object \n",
      " 251  lace         23357 non-null  object \n",
      " 252  ucod         23357 non-null  object \n",
      " 253  ucodr130     23357 non-null  int64  \n",
      " 254  recwt        23357 non-null  float64\n",
      " 255  eanum        23357 non-null  int64  \n",
      " 256  econdp_1     23357 non-null  int64  \n",
      " 257  econds_1     23357 non-null  int64  \n",
      " 258  enicon_1     23357 non-null  object \n",
      " 259  econdp_2     23357 non-null  int64  \n",
      " 260  econds_2     23357 non-null  int64  \n",
      " 261  enicon_2     23357 non-null  object \n",
      " 262  econdp_3     23357 non-null  int64  \n",
      " 263  econds_3     23357 non-null  int64  \n",
      " 264  enicon_3     23357 non-null  object \n",
      " 265  econdp_4     23357 non-null  int64  \n",
      " 266  econds_4     23357 non-null  int64  \n",
      " 267  enicon_4     23357 non-null  object \n",
      " 268  econdp_5     23357 non-null  int64  \n",
      " 269  econds_5     23357 non-null  int64  \n",
      " 270  enicon_5     23357 non-null  object \n",
      " 271  econdp_6     23357 non-null  int64  \n",
      " 272  econds_6     23357 non-null  int64  \n",
      " 273  enicon_6     23357 non-null  object \n",
      " 274  econdp_7     23357 non-null  int64  \n",
      " 275  econds_7     23357 non-null  int64  \n",
      " 276  enicon_7     23357 non-null  object \n",
      " 277  econdp_8     23357 non-null  int64  \n",
      " 278  econds_8     23357 non-null  int64  \n",
      " 279  enicon_8     23357 non-null  object \n",
      " 280  econdp_9     23357 non-null  int64  \n",
      " 281  econds_9     23357 non-null  int64  \n",
      " 282  enicon_9     23357 non-null  object \n",
      " 283  econdp_10    23357 non-null  int64  \n",
      " 284  econds_10    23357 non-null  int64  \n",
      " 285  enicon_10    23357 non-null  object \n",
      " 286  econdp_11    23357 non-null  int64  \n",
      " 287  econds_11    23357 non-null  int64  \n",
      " 288  enicon_11    23357 non-null  object \n",
      " 289  econdp_12    23357 non-null  int64  \n",
      " 290  econds_12    23357 non-null  int64  \n",
      " 291  enicon_12    23357 non-null  object \n",
      " 292  econdp_13    23357 non-null  int64  \n",
      " 293  econds_13    23357 non-null  int64  \n",
      " 294  enicon_13    23357 non-null  object \n",
      " 295  econdp_14    23357 non-null  int64  \n",
      " 296  econds_14    23357 non-null  int64  \n",
      " 297  enicon_14    23357 non-null  object \n",
      " 298  econdp_15    23357 non-null  int64  \n",
      " 299  econds_15    23357 non-null  int64  \n",
      " 300  enicon_15    23357 non-null  object \n",
      " 301  econdp_16    23357 non-null  int64  \n",
      " 302  econds_16    23357 non-null  int64  \n",
      " 303  enicon_16    23357 non-null  object \n",
      " 304  econdp_17    23357 non-null  int64  \n",
      " 305  econds_17    23357 non-null  int64  \n",
      " 306  enicon_17    23357 non-null  object \n",
      " 307  econdp_18    23357 non-null  int64  \n",
      " 308  econds_18    23357 non-null  int64  \n",
      " 309  enicon_18    23357 non-null  object \n",
      " 310  econdp_19    23357 non-null  int64  \n",
      " 311  econds_19    23357 non-null  int64  \n",
      " 312  enicon_19    23357 non-null  object \n",
      " 313  econdp_20    23357 non-null  int64  \n",
      " 314  econds_20    23357 non-null  int64  \n",
      " 315  enicon_20    23357 non-null  object \n",
      " 316  ranum        23357 non-null  int64  \n",
      " 317  record       23357 non-null  object \n",
      " 318  record_1     23357 non-null  object \n",
      " 319  record_2     23357 non-null  object \n",
      " 320  record_3     23357 non-null  object \n",
      " 321  record_4     23357 non-null  object \n",
      " 322  record_5     23357 non-null  object \n",
      " 323  record_6     23357 non-null  object \n",
      " 324  record_7     23357 non-null  object \n",
      " 325  record_8     23357 non-null  object \n",
      " 326  record_9     23357 non-null  object \n",
      " 327  record_10    23357 non-null  object \n",
      " 328  record_11    23357 non-null  object \n",
      " 329  record_12    23357 non-null  object \n",
      " 330  record_13    23357 non-null  int64  \n",
      " 331  record_14    23357 non-null  int64  \n",
      " 332  record_15    23357 non-null  int64  \n",
      " 333  record_16    23357 non-null  int64  \n",
      " 334  record_17    23357 non-null  int64  \n",
      " 335  record_18    23357 non-null  int64  \n",
      " 336  record_19    23357 non-null  int64  \n",
      " 337  record_20    23357 non-null  int64  \n",
      " 338  d_restatus   23357 non-null  int64  \n",
      " 339  hospd        23357 non-null  int64  \n",
      " 340  dweekday     23357 non-null  int64  \n",
      " 341  dod_yy       23357 non-null  int64  \n",
      " 342  dod_mm       23357 non-null  int64  \n",
      "dtypes: float64(2), int64(224), object(117)\n",
      "memory usage: 61.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True,show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08697c45",
   "metadata": {},
   "source": [
    "## Basic Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "904d0736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "23352    1\n",
       "23353    1\n",
       "23354    0\n",
       "23355    1\n",
       "23356    1\n",
       "Name: sex, Length: 23357, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform the 'sex' column\n",
    "le = LabelEncoder()\n",
    "df['sex'] = le.fit_transform(df['sex'])\n",
    "df['sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52271b57",
   "metadata": {},
   "source": [
    "### Constructing the DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a753f",
   "metadata": {},
   "source": [
    "After looking through the User Guide for the 2015 Period Linked Birth/Infant Death Data Set, we realized that many of the features were simply variations of the same main feature. For example, the mother's race had several corresponding features where it could be categorized into 6, 15, or even 31 groups. As a result, we decided to take only the features that had only int64 values.  \n",
    "\n",
    "There were 130 selected causes of infant death adapted for use from the International Classification of Diseases. Since these were too many classes, we further grouped them into larger categories while still following the ICD-10 codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "442efe52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laterec</th>\n",
       "      <th>dob_yy</th>\n",
       "      <th>dob_mm</th>\n",
       "      <th>dob_tt</th>\n",
       "      <th>dob_wk</th>\n",
       "      <th>bfacil</th>\n",
       "      <th>f_bfacil</th>\n",
       "      <th>bfacil3</th>\n",
       "      <th>mageimp</th>\n",
       "      <th>magerep</th>\n",
       "      <th>...</th>\n",
       "      <th>record_16</th>\n",
       "      <th>record_17</th>\n",
       "      <th>record_18</th>\n",
       "      <th>record_19</th>\n",
       "      <th>record_20</th>\n",
       "      <th>d_restatus</th>\n",
       "      <th>hospd</th>\n",
       "      <th>dweekday</th>\n",
       "      <th>dod_yy</th>\n",
       "      <th>dod_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1504</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1752</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1222</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1107</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>613</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>1130</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23353</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>730</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23354</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>1847</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23355</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>444</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23356</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>2051</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23357 rows Ã— 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       laterec  dob_yy  dob_mm  dob_tt  dob_wk  bfacil  f_bfacil  bfacil3  \\\n",
       "0            0    2015       1    1504       5       1         1        1   \n",
       "1            0    2015       1    1752       7       1         1        1   \n",
       "2            0    2015       1    1222       2       1         1        1   \n",
       "3            0    2015       1    1107       6       1         1        1   \n",
       "4            0    2015       1     613       3       1         1        1   \n",
       "...        ...     ...     ...     ...     ...     ...       ...      ...   \n",
       "23352        0    2015       9    1130       6       1         1        1   \n",
       "23353        0    2015      10     730       5       1         1        1   \n",
       "23354        0    2015      11    1847       4       1         1        1   \n",
       "23355        0    2015      11     444       7       1         1        1   \n",
       "23356        0    2015      12    2051       7       1         1        1   \n",
       "\n",
       "       mageimp  magerep  ...  record_16  record_17  record_18  record_19  \\\n",
       "0            1        1  ...          2          2          2          2   \n",
       "1            2        2  ...          1          1          1          1   \n",
       "2            3        3  ...          1          1          1          1   \n",
       "3            2        2  ...          1          1          1          1   \n",
       "4            2        2  ...          1          1          1          1   \n",
       "...        ...      ...  ...        ...        ...        ...        ...   \n",
       "23352        2        2  ...          3          3          3          3   \n",
       "23353        2        2  ...          3          3          3          3   \n",
       "23354        1        1  ...          1          1          1          1   \n",
       "23355        2        2  ...          1          1          1          1   \n",
       "23356        2        2  ...          3          3          3          3   \n",
       "\n",
       "       record_20  d_restatus  hospd  dweekday  dod_yy  dod_mm  \n",
       "0              2           2      1         2    2015       1  \n",
       "1              1           1      2         2    2015       4  \n",
       "2              1           1      1         2    2015       1  \n",
       "3              1           1      2         7    2015       5  \n",
       "4              1           1      1         3    2015       1  \n",
       "...          ...         ...    ...       ...     ...     ...  \n",
       "23352          3           3      2         1    2016       1  \n",
       "23353          3           3      1         6    2015      10  \n",
       "23354          1           1      2         3    2016       2  \n",
       "23355          1           1      1         7    2015      11  \n",
       "23356          3           3      1         1    2016       4  \n",
       "\n",
       "[23357 rows x 225 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dataframe with only 'int64' values\n",
    "df_int = df.select_dtypes(include='int64')\n",
    "df_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50b8cde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#130 selected causes of infant death\n",
    "plt.figure(figsize=(20,8),dpi=200)\n",
    "sns.countplot(x='ucodr130',data=df_int)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5a55558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 causes of Infant Death make up 69.76067131909063% of deaths\n"
     ]
    }
   ],
   "source": [
    "unique_counts = df_int.ucodr130.value_counts()\n",
    "unique_counts.head(20).sum()/len(df_int)\n",
    "print(f\"Top 20 causes of Infant Death make up {unique_counts.head(20).sum()/len(df_int)*100}% of deaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f725efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laterec</th>\n",
       "      <th>dob_yy</th>\n",
       "      <th>dob_mm</th>\n",
       "      <th>dob_tt</th>\n",
       "      <th>dob_wk</th>\n",
       "      <th>bfacil</th>\n",
       "      <th>f_bfacil</th>\n",
       "      <th>bfacil3</th>\n",
       "      <th>mageimp</th>\n",
       "      <th>magerep</th>\n",
       "      <th>...</th>\n",
       "      <th>record_17</th>\n",
       "      <th>record_18</th>\n",
       "      <th>record_19</th>\n",
       "      <th>record_20</th>\n",
       "      <th>d_restatus</th>\n",
       "      <th>hospd</th>\n",
       "      <th>dweekday</th>\n",
       "      <th>dod_yy</th>\n",
       "      <th>dod_mm</th>\n",
       "      <th>ucodr130copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1504</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1752</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1222</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1107</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>613</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>1130</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23353</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>730</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23354</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>1847</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23355</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>444</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23356</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>2051</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23357 rows Ã— 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       laterec  dob_yy  dob_mm  dob_tt  dob_wk  bfacil  f_bfacil  bfacil3  \\\n",
       "0            0    2015       1    1504       5       1         1        1   \n",
       "1            0    2015       1    1752       7       1         1        1   \n",
       "2            0    2015       1    1222       2       1         1        1   \n",
       "3            0    2015       1    1107       6       1         1        1   \n",
       "4            0    2015       1     613       3       1         1        1   \n",
       "...        ...     ...     ...     ...     ...     ...       ...      ...   \n",
       "23352        0    2015       9    1130       6       1         1        1   \n",
       "23353        0    2015      10     730       5       1         1        1   \n",
       "23354        0    2015      11    1847       4       1         1        1   \n",
       "23355        0    2015      11     444       7       1         1        1   \n",
       "23356        0    2015      12    2051       7       1         1        1   \n",
       "\n",
       "       mageimp  magerep  ...  record_17  record_18  record_19  record_20  \\\n",
       "0            1        1  ...          2          2          2          2   \n",
       "1            2        2  ...          1          1          1          1   \n",
       "2            3        3  ...          1          1          1          1   \n",
       "3            2        2  ...          1          1          1          1   \n",
       "4            2        2  ...          1          1          1          1   \n",
       "...        ...      ...  ...        ...        ...        ...        ...   \n",
       "23352        2        2  ...          3          3          3          3   \n",
       "23353        2        2  ...          3          3          3          3   \n",
       "23354        1        1  ...          1          1          1          1   \n",
       "23355        2        2  ...          1          1          1          1   \n",
       "23356        2        2  ...          3          3          3          3   \n",
       "\n",
       "       d_restatus  hospd  dweekday  dod_yy  dod_mm  ucodr130copy  \n",
       "0               2      1         2    2015       1            70  \n",
       "1               1      2         2    2015       4           118  \n",
       "2               1      1         2    2015       1           118  \n",
       "3               1      2         7    2015       5           134  \n",
       "4               1      1         3    2015       1            70  \n",
       "...           ...    ...       ...     ...     ...           ...  \n",
       "23352           3      2         1    2016       1             1  \n",
       "23353           3      1         6    2015      10            70  \n",
       "23354           1      2         3    2016       2           134  \n",
       "23355           1      1         7    2015      11            70  \n",
       "23356           3      1         1    2016       4           134  \n",
       "\n",
       "[23357 rows x 226 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorize causes of death into 16 classes for a better model\n",
    "df_int['ucodr130copy'] = df_int['ucodr130']\n",
    "\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 1) & (df_int['ucodr130copy'] <= 22), 'ucodr130copy'] = 1\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 23) & (df_int['ucodr130copy'] <= 28), 'ucodr130copy'] = 23\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 29) & (df_int['ucodr130copy'] <= 32), 'ucodr130copy'] = 29\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 33) & (df_int['ucodr130copy'] <= 38), 'ucodr130copy'] = 33\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 39) & (df_int['ucodr130copy'] <= 44), 'ucodr130copy'] = 39\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 46) & (df_int['ucodr130copy'] <= 52), 'ucodr130copy'] = 46\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 53) & (df_int['ucodr130copy'] <= 62), 'ucodr130copy'] = 53\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 63) & (df_int['ucodr130copy'] <= 66), 'ucodr130copy'] = 63\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 67) & (df_int['ucodr130copy'] <= 69), 'ucodr130copy'] = 67\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 70) & (df_int['ucodr130copy'] <= 108), 'ucodr130copy'] = 70\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 109) & (df_int['ucodr130copy'] <= 117), 'ucodr130copy'] = 109\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 118) & (df_int['ucodr130copy'] <= 133), 'ucodr130copy'] = 118\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 134) & (df_int['ucodr130copy'] <= 137), 'ucodr130copy'] = 134\n",
    "df_int.loc[(df_int['ucodr130copy'] >= 138) & (df_int['ucodr130copy'] <= 157), 'ucodr130copy'] = 138\n",
    "\n",
    "df_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc282f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAADMwAAAVYCAYAAADh96XHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAB7CAAAewgFu0HU+AAC6L0lEQVR4nOzdXYyV1dn44XvPHoF3BpEZ5GNEFKu2aWsaMICY2jZIrBWMNcZaDGhRGqG2UmuqclRi2kbb1H740YQSpXiiNlEo2oAa7ZehBNGYxooEIgaCoqUwOMNmwJm93wNfd5kAQ/v/j+zNPdd1tNzPWvez4iHJb55CpVKpBAAAAAAAAAAAAAAAACTRUOsLAAAAAAAAAAAAAAAAQH8SzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAgFcEMAAAAAAAAAAAAAAAAqQhmAAAAAAAAAAAAAAAASEUwAwAAAAAAAAAAAAAAQCqCGQAAAAAAAAAAAAAAAFIRzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAgFcEMAAAAAAAAAAAAAAAAqQhmAAAAAAAAAAAAAAAASEUwAwAAAAAAAAAAAAAAQCqCGQAAAAAAAAAAAAAAAFIRzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAglcZaX4CB6/33u6Knp1zrawAAAAAAAAAAAAAAADVULDbEsGFD+nWmYIaa6ekpR3d3T62vAQAAAAAAAAAAAAAAJNNQ6wsAAAAAAAAAAAAAAABAfxLMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACCVxlpfAAAAAAAAAADg/9fw4U3R0FCo9TUYQMrlSrS3l2p9DQAAAOAoBDMAAAAAAAAAwAmvoaEQxWJDra/BgFKu9QUAAACAPghmAAAAAAAAAIA0eiqVaN//Qa2vQWLD/+ekKBZ8zQgAAADqnWAGAAAAAAAAAEijff8HMX/1a7W+Boktuey8GNE0qNbXAAAAAI7Bt4gBAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpCGYAAAAAAAAAAAAAAABIRTADAAAAAAAAAAAAAABAKoIZAAAAAAAAAAAAAAAAUhHMAAAAAAAAAAAAAAAAkIpgBgAAAAAAAAAAAAAAgFQEMwAAAAAAAAAAAAAAAKQimAEAAAAAAAAAAAAAACAVwQwAAAAAAAAAAAAAAACpNNb6AvVi//798fjjj8dzzz0XmzdvjlKpFMOGDYvPfOYz8dWvfjVmzJgRxWLxqOfL5XKsWLEiVq5cGZs2bYpSqRQjR46M888/P2bNmhWTJ08+5h3qZQYAAAAAAAAAAAAAAMCJrFCpVCq1vkStvfXWW7FgwYLYunXrUfdMmTIlHnjggTjllFMOe9bR0RE333xzrF+//ohnC4VCzJ07NxYtWnTU+fUy43jas6cU3d09tb4GAAAAAAAAAAm0tjZHsdgQ/yodjPmrX6v1dUhsyWXnxYimQdHTU47du/fV+joAAACQQmNjMVpamvp3Zr9OOwGVSqX45je/Gdu3b4+IiMmTJ8esWbOira0t3nrrrXj44Ydjy5YtsX79+vjOd74TjzzySBQKher5SqUSt956azVSueiii+Laa6+NU089NTZu3BhLly6NHTt2xLJly6K1tTVuuummw+5QLzMAAAAAAAAAAAAAAAAyGPBfmPnNb34T9957b0REXHHFFfHTn/60VxBz8ODBmD9/fqxduzYiIn71q1/FV77ylerzVatWxe233x4REVdddVXcfffdvea3t7fH7NmzY8uWLTF48OB49tlnY8yYMb321MuM480XZgAAAAAAAADoL74ww/HiCzMAAADQ/z6OL8w09Ou0E9Cf//zn6nrRokW9YpmIiEGDBsUdd9xR/e/nn3++1/Nly5ZFRMTQoUPjzjvvPGz+8OHD46677oqIiAMHDsQjjzxy2J56mQEAAAAAAAAAAAAAAJDBgA9mdu3aFRERw4YNixEjRhxxz1lnnVVd//Of/6yut2/fHq+//npEREybNi2GDx9+xPOTJk2qzlizZk2vZ/UyAwAAAAAAAAAAAAAAIIsBH8yMGjUqIiLef//9XjHMod58883qesyYMdX1yy+/XF1PnTq1z/dMmTIlIiJ27NgR27Ztq7sZAAAAAAAAAAAAAAAAWQz4YGb69OnV9b333nvY856envjZz35W/e8ZM2ZU11u2bKmux48f3+d7xo0bV11v3ry57mYAAAAAAAAAAAAAAABk0VjrC9TatddeG88//3ysX78+VqxYEe+8805cc8010dbWFtu3b4/ly5fHP/7xj4iImDVrVnzxi1+snt25c2d1fdppp/X5nra2tiOeq5cZAAAAAAAAAAAAAAAAWQz4YGbw4MGxdOnSeOihh2LZsmWxbt26WLduXa89I0eOjDvuuCOuuOKKXr/v3bu3um5ubu7zPU1NTdV1R0dH3c0AAAAAAAAAAAAAAADIYsAHMxERW7ZsiY0bN0apVDri8127dsXq1avjs5/9bJx99tnV3w8ePFhdDxkypM93HPr80HP1MqMWhg3r+64AAAAAAAAA8J9qaCjU+goMMA0NhWht7fsPmwIAAAC1M+CDmT/96U/x3e9+N7q6uqK1tTUWLlwY06dPj+HDh8fbb78dq1atiqVLl8YLL7wQr7zySjz00ENx3nnnRUREsViszikU+v6Ht0qlUl03NDRU1/UyoxaKxdq+HwAAAAAAAADg/1WhUIhiUagFAAAA9WpABzPvvfdefO9734uurq5oaWmJxx9/PM4444zq8/Hjx8fChQvjggsuiHnz5kV7e3vccsstsWbNmhg8eHA0NTVV93Z1dcWgQYOO+q4DBw5U14fuq5cZtdDTU67p+wEAAAAAAADIo6GhcMw/Mgn9qVKpRLlcOfZGAAAA4D/S3x/lGNDBzMqVK6NUKkVExMKFC3vFMoe64IILYvbs2fHb3/423n777Xj++edjxowZ0dz878/q7t+/P4YNG3bUd330noiIU045pbqulxm18P77XdHd3VPTOwAAAAAAAACQQ2trs699cFyVy5XYvXtfra8BAAAAKTQ2FqOlpenYG/8L/ZvfnGD+/ve/V9fTp0/vc+8ll1xSXb/66qsRETF27Njqb++8806f5w99Pnr06Oq6XmYAAAAAAAAAAAAAAABkMaCDmUO/tnLyySf3uXfEiBHVdUdHR0REnHvuudXftm3b1uf57du3V9fnnHNOdV0vMwAAAAAAAAAAAAAAALIY0MFMS0tLdX2s0OTdd9+trj+KZyZMmBCFwoefc96wYUOf59evXx8REW1tbXH66adXf6+XGQAAAAAAAAAAAAAAAFkM6GBmypQp1fXvf//7Pvc+9dRT1fXkyZMj4sPoZMKECRER8cwzz0RnZ+cRz27YsCG2bt0aERGXXnppr2f1MgMAAAAAAAAAAAAAACCLAR3MzJw5M1pbWyMiYvny5fHHP/7xiPueeuqpeOKJJyIi4hOf+ER8/vOfrz677rrrIiKivb09Fi9eHOVyudfZvXv3xuLFiyMi4qSTToo5c+YcNr9eZgAAAAAAAAAAAAAAAGTQWOsL1NLQoUPjxz/+cXz729+Onp6e+Na3vhUzZ86Myy67LEaNGhXvvfderF69Ov7whz9EpVKJIUOGxD333BONjf/+3zZz5sx48skn48UXX4ynn346du7cGddff32MHj06Nm3aFEuWLIkdO3ZERMQtt9wS48aNO+we9TIDAAAAAAAAAAAAAAAgg0KlUqnU+hK19txzz8WiRYuis7PzqHtGjhwZv/jFL2Ly5MmHPevs7IwFCxbESy+9dNTzc+fOjUWLFkWhUDji83qZcTzt2VOK7u6eWl8DAAAAAAAAgARaW5ujWGyIf5UOxvzVr9X6OiS25LLzYkTToOjpKcfu3ftqfR0AAABIobGxGC0tTf06UzDzf3bv3h2PPvpo/OUvf4mtW7fGvn374uSTT45zzz03Lr744rjmmmuiubn5qOfL5XKsXLkyVq1aFW+88UZ0dHRES0tLTJw4MWbPnh1Tp0495h3qZcbxIpgBAAAAAAAAoL8IZjheBDMAAADQ/wQzpCKYAQAAAAAAAKC/CGY4XgQzAAAA0P8+jmCmoV+nAQAAAAAAAAAAAAAAQI0JZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApCKYAQAAAAAAAAAAAAAAIBXBDAAAAAAAAAAAAAAAAKkIZgAAAAAAAAAAAAAAAEhFMAMAAAAAAAAAAAAAAEAqghkAAAAAAAAAAAAAAABSEcwAAAAAAAAAAAAAAACQimAGAAAAAAAAAAAAAACAVAQzAAAAAAAAAAAAAAAApNJY6wvUk82bN8djjz0Wa9eujZ07d0a5XI6xY8fGF77whZg7d260tbUd9Wy5XI4VK1bEypUrY9OmTVEqlWLkyJFx/vnnx6xZs2Ly5MnHfH+9zAAAAAAAAAAAAAAAADiRFSqVSqXWl6gHv/71r+PBBx+M7u7uIz4fOnRo/PznP48vfelLhz3r6OiIm2++OdavX3/Es4VCIebOnRuLFi066vvrZcbxtGdPKbq7e2p9DQAAAAAAAAASaG1tjmKxIf5VOhjzV79W6+uQ2JLLzosRTYOip6ccu3fvq/V1AAAAIIXGxmK0tDT178x+nXaCeuCBB+L++++PiIiWlpa48cYbY+LEidHd3R1r1qyJ3/3ud9HZ2RkLFy6MJ598Ms4+++zq2UqlErfeems1Urnooovi2muvjVNPPTU2btwYS5cujR07dsSyZcuitbU1brrppsPeXy8zAAAAAAAAAAAAAAAAMhjwX5jZuHFjXH311dHd3R1jx46N5cuXx7hx43rtefzxx+MHP/hBRERceumlcd9991WfrVq1Km6//faIiLjqqqvi7rvv7nW2vb09Zs+eHVu2bInBgwfHs88+G2PGjOm1p15mHG++MAMAAAAAAABAf/GFGY4XX5gBAACA/vdxfGGmoV+nnYDuu+++6O7ujkKhEL/85S8Pi2UiIr7+9a/HJz/5yYiIeOGFF6Krq6v6bNmyZRERMXTo0LjzzjsPOzt8+PC46667IiLiwIED8cgjjxy2p15mAAAAAAAAAAAAAAAAZDCgg5k9e/bEX//614j48Msxn/vc5466d968eXHNNdfEjTfeGKVSKSIitm/fHq+//npEREybNi2GDx9+xLOTJk2Ks846KyIi1qxZ0+tZvcwAAAAAAAAAAAAAAADIYkAHM2vXro0PPvggIiIuv/zyPvdeeeWV8cMf/jBuu+22aG1tjYiIl19+ufp86tSpfZ6fMmVKRETs2LEjtm3bVv29XmYAAAAAAAAAAAAAAABkMaCDmTfeeKO6PvTrMuVyOd5999148803Y9++fUc9v2XLlup6/Pjxfb5r3Lhx1fXmzZvrbgYAAAAAAAAAAAAAAEAWjbW+QC19FIycdNJJMWrUqNi1a1fcf//9sXr16ti7d29ERBSLxZg8eXLccsstMWnSpF7nd+7cWV2fdtppfb6rra3tiOfqZQYAAAAAAAAAAAAAAEAWA/oLM+3t7RERMXTo0Hj11Vdj5syZ8dhjj1VjmYiInp6eWLduXcyZMycefvjhXucP3dfc3Nznu5qamqrrjo6OupsBAAAAAAAAAAAAAACQxYD+wsy+ffsiIuLAgQOxYMGC2Lt3b1x33XUxa9asOOOMM2L37t2xevXquO+++6JUKsVPfvKTGDNmTMyYMSMiIg4ePFidNWTIkD7fdejzQ8/Vy4xaGDas77sCAAAAAAAAwH+qoaFQ6yswwDQ0FKK1te8/bAoAAADUzoAOZvbv3x8REaVSKUqlUvzoRz+Kr33ta9XnY8aMiRtuuCEmTpwYc+bMiQ8++CDuueeemD59egwePDiKxWJ1b6HQ9z+8VSqV6rqh4d8f9qmXGbVQLA7oDxwBAAAAAAAAACewQqEQxaJQCwAAAOrVgA5mDv3ayoUXXtgrljnUhAkT4uqrr45HH3003n333Vi7dm1MmzYtmpqaqnu6urpi0KBBR33XgQMHqutD99XLjFro6SnX9P0AAAAAAAAA5NHQUDjmH5mE/lSpVKJcrhx7IwAAAPAf6e+PcgzoYGbo0KHV9Ze//OU+91588cXx6KOPRkTEq6++GtOmTYvm5n9/Vnf//v0xbNiwo54vlUrV9SmnnFJd18uMWnj//a7o7u6p6R0AAAAAAAAAyKG1tdnXPjiuyuVK7N69r9bXAAAAgBQaG4vR0tJ07I3/hf7Nb04wI0eOrK7HjBnT597TTjutut6zZ09ERIwdO7b62zvvvNPn+UOfjx49urqulxkAAAAAAAAAAAAAAABZDOhg5lOf+lR1vXfv3j73Hjx4sLr+6Asu5557bvW3bdu29Xl++/bt1fU555xTXdfLDAAAAAAAAAAAAAAAgCwGdDAzYcKE6vrll1/uc+/mzZur69NPP716vlD48HPOGzZs6PP8+vXrIyKira2ter6eZgAAAAAAAAAAAAAAAGQxoIOZCy+8MEaOHBkREatXr45du3Ydde+KFSsiIqJYLMbFF18cER9GJx9FN88880x0dnYe8eyGDRti69atERFx6aWX9npWLzMAAAAAAAAAAAAAAACyGNDBTLFYjHnz5kVERGdnZ3z/+9+Pffv2HbZv+fLl8be//S0iIi655JIYNWpU9dl1110XERHt7e2xePHiKJfLvc7u3bs3Fi9eHBERJ510UsyZM+ew+fUyAwAAAAAAAAAAAAAAIINCpVKp1PoStVQul+OGG26IdevWRUTEmWeeGd/4xjfi05/+dHR0dMSqVavi6aefjoiI1tbWePrpp2PEiBG9ZsybNy9efPHFiIiYNGlSXH/99TF69OjYtGlTLFmyJHbs2BEREbfddlvMnz//iPeolxnH0549peju7qn1NQAAAAAAAABIoLW1OYrFhvhX6WDMX/1ara9DYksuOy9GNA2Knp5y7N59+B9mBQAAAP57jY3FaGlp6teZAz6YiYjo6uqKO++8M9asWXPUPePHj48HH3wwzjnnnMOedXZ2xoIFC+Kll1466vm5c+fGokWLolAoHPF5vcw4ngQzAAAAAAAAAPQXwQzHi2AGAAAA+p9g5mO2du3aeOKJJ+KVV16JXbt2xcknnxxnnnlmXH755XHllVdGc3PzUc+Wy+VYuXJlrFq1Kt54443o6OiIlpaWmDhxYsyePTumTp16zPfXy4zjRTADAAAAAAAAQH8RzHC8CGYAAACg/wlmSEUwAwAAAAAAAEB/EcxwvAhmAAAAoP99HMFMQ79OAwAAAAAAAAAAAAAAgBoTzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAgFcEMAAAAAAAAAAAAAAAAqQhmAAAAAAAAAAAAAAAASEUwAwAAAAAAAAAAAAAAQCqCGQAAAAAAAAAAAAAAAFIRzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAgFcEMAAAAAAAAAAAAAAAAqQhmAAAAAAAAAAAAAAAASEUwAwAAAAAAAAAAAAAAQCqCGQAAAAAAAAAAAAAAAFIRzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAgFcEMAAAAAAAAAAAAAAAAqQhmAAAAAAAAAAAAAAAASEUwAwAAAAAAAAAAAAAAQCqCGQAAAAAAAAAAAAAAAFIRzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAgFcEMAAAAAAAAAAAAAAAAqQhmAAAAAAAAAAAAAAAASEUwAwAAAAAAAAAAAAAAQCqCGQAAAAAAAAAAAAAAAFIRzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAgFcEMAAAAAAAAAAAAAAAAqQhmAAAAAAAAAAAAAAAASEUwAwAAAAAAAAAAAAAAQCqCGQAAAAAAAAAAAAAAAFIRzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAgFcEMAAAAAAAAAAAAAAAAqQhmAAAAAAAAAAAAAAAASEUwAwAAAAAAAAAAAAAAQCqCGQAAAAAAAAAAAAAAAFIRzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAgFcEMAAAAAAAAAAAAAAAAqQhmAAAAAAAAAAAAAAAASEUwAwAAAAAAAAAAAAAAQCqCGQAAAAAAAAAAAAAAAFIRzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAgFcEMAAAAAAAAAAAAAAAAqQhmAAAAAAAAAAAAAAAASEUwAwAAAAAAAAAAAAAAQCqCGQAAAAAAAAAAAAAAAFIRzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAgFcEMAAAAAAAAAAAAAAAAqQhmAAAAAAAAAAAAAAAASEUwAwAAAAAAAAAAAAAAQCqCGQAAAAAAAAAAAAAAAFIRzAAAAAAAAAAAAAAAAJCKYAYAAAAAAAAAAAAAAIBUBDMAAAAAAAAAAAAAAACkIpgBAAAAAAAAAAAAAAAgFcEMAAAAAAAAAAAAwP+yd/+xWtf3/f8f13WOSIHyqzCKiNMVqa4dIrFKM1O1Gp2zXRVbh/FHGU2oNVJJk67U0TJcV03mfth0m36rJXVm2jiBWtywoVE66lagE0cnUJ1mIIJIEQER8HDe3z86T7XCAT87XNd1Xud2S0jfnuv1er2f/1w5NfHOCwCAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAovSaYGbXrl15+umnmz0GAAAAAAAAAAAAAAAALa5hwcz555+f888/Pw888MA73vv3f//3OfPMM/P5z3/+KEwGAAAAAAAAAAAAAABASdob9aJNmzalVqtl9+7d73hvW1tbqqrKiy++eBQmAwAAAAAAAAAAAAAAoCQNu2Hm/9XevXvz2GOPJUlqtVpzhwEAAAAAAAAAAAAAAKDl9egNMwcOHMj06dPz/PPPH3LNHXfckXvvvfeIzuvs7Mz27duzf//+1Gq1nHTSST01KgAAAAAAAAAAAAAAAIXq0WCmra0t06dPz2c/+9mD3gZTVVV27tyZnTt3HvGZVVUl+eXtMldffXWPzQoAAAAAAAAAAAAAAECZ6j194DnnnJMLL7wwVVW95c8bfv3n3f2p1+sZMmRIfvu3fzvz5s3LpZde2tPjAgAAAAAAAAAAAAAAUJgevWHmDd/4xjfe9rNTTjkltVotf/zHf5w/+qM/OhqvBQAAAAAAAAAAAAAAgJ6/YaY7b75pBgAAAAAAAAAAAAAAAI6Go3LDzMH88Ic/TJIMGTKkUa8EAAAAAAAAAAAAAACgD2pYMDNmzJhGvQoAAAAAAAAAAAAAAIA+rN7sAQAAAAAAAAAAAAAAAKAnNeyGmTf893//d77zne/k3//93/PSSy9l//796ezsPKK9tVotTz311FGeEAAAAAAAAAAAAAAAgN6socHMokWLMmfOnBw4cCBJUlVVI18PAAAAAAAAAAAAAABAH9CwYGbDhg35yle+ko6Ojl+9vL09gwcPTv/+/Rs1BgAAAAAAAAAAAAAAAIVrWDDzD//wD3n99ddTq9Xy/ve/PzfddFMmTZqU9vaGXnIDAAAAAAAAAAAAAABA4RpWqyxfvjxJMnjw4MyfPz/Dhg1r1KsBAAAAAAAAAAAAAADoQ+qNetGWLVtSq9Xye7/3e2IZAAAAAAAAAAAAAAAAjpqGBTPHHHNMkmTMmDGNeiUAAAAAAAAAAAAAAAB9UMOCmeOOOy5J8tJLLzXqlQAAAAAAAAAAAAAAAPRBDQtmzjvvvFRVlcceeyxVVTXqtQAAAAAAAAAAAAAAAPQxDQtmrrrqqgwZMiTPP/987rzzzka9FgAAAAAAAAAAAAAAgD6mYcHMiBEj8pd/+Zfp379/br/99syePTtPPvlkOjo6GjUCAAAAAAAAAAAAAAAAfUB7o170p3/6p0mS8ePH58knn8z3vve9fO9730tbW1uGDBmS/v37H/aMWq2WpUuXHuVJAQAAAAAAAAAAAAAA6M0aFszcf//9qdVqSdL1v1VVpaOjI9u3bz/s/qqquvYBAAAAAAAAAAAAAADAoTQsmEl+Gb28k58DAAAAAAAAAAAAAADAO9WwYGbdunWNehUAAAAAAAAAAAAAAAB9WL3ZAwAAAAAAAAAAAAAAAEBPEswAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARWlv1IsWLVrUI+dceumlPXIOAAAAAAAAAAAAAAAAZWpYMDN79uzUarX/0xm1Wk0wAwAAAAAAAAAAAAAAQLcaFswkSVVVjXwdAAAAAAAAAAAAAAAAfVDDgpkbbrjhsGuqqsq+ffvy0ksvZc2aNXn22WdTq9Vy8cUXZ/r06Q2YEgAAAAAAAAAAAAAAgN6upYKZX7d06dLcdNNN+Zd/+ZeMGzcu119//VGYDAAAAAAAAAAAgBIMHTog9Xqt2WPQh3R2VtmxY0+zxwAA4CAaFsz8v7jgggvSr1+/zJgxI3/3d3+Xc845Jx/4wAeaPRYAAAAAAAAAAAAtqF6vpa2t3uwx6FM6mz0AAACH0NLBTJJ85CMfycSJE/Pkk0/mvvvuy9e+9rVmjwQAAAAAAAAAAEALqzqr7NsrZODoObZ/PTW3GQEAtLSWD2aS5Iwzzsjq1avzk5/8pNmjAAAAAAAAAAAA0OL27e3Mo99/udljULDzPj4s/Qe0NXsMAAC60Svunuzfv3+SZOvWrU2eBAAAAAAAAAAAAAAAgFbXK4KZNWvWJEkGDBjQ5EkAAAAAAAAAAAAAAABodS0fzCxbtiw/+tGPUqvVMn78+GaPAwAAAAAAAAAAAAAAQItrb9SLVq5ceUTrqqrK/v37s3379jz++ONZvHhxqqpKrVbLJZdccpSnBAAAAAAAAAAAAAAAoLdrWDBzzTXXpFarveN9VVUlSU4++eRcfvnlPT0WAAAAAAAAAAAAAAAAhak38mVVVb3jP0kyadKk3HXXXWlra2vkuAAAAAAAAAAAAAAAAPRCDbth5rLLLjvitbVaLe9617vyG7/xG/nwhz+cCRMmHMXJAAAAAAAAAAAAAAAAKEnDgplbbrmlUa8CAAAAAAAAAAAAAACgD6s3ewAAAAAAAAAAAAAAAADoSYIZAAAAAAAAAAAAAAAAitLerBf/z//8TxYsWJCVK1dm48aNeeWVV1Kv1/Pud787Y8eOzaRJk/Kxj30sp5xySrNGBAAAAAAAAAAAAAAAoBdqeDCzf//+fO1rX8uDDz6Yzs7Orp9XVZUk2bdvX7Zt25Ynnngid999dy6//PLMmTMn/fv3b/SoAAAAAAAAAAAAAAAA9EINDWZee+21fPrTn86aNWu6Aplf9+s/f/DBB/Nf//Vfue+++0QzAAAAAAAAAAAAAAAAHFZDg5k5c+bkP//zP3/54vb2/P7v/34uvvjinHrqqRk6dGgOHDiQl19+OevWrcuSJUuyZMmSdHR0ZN26dbn55pvz9a9/vZHjAgAAAAAAAAAAAAAA0As1LJh58skn8/DDD6dWq2XYsGG54447MmHChLetGzhwYI4//vhccMEFufbaa/O5z30uv/jFL7Jw4cJMnTr1oHsAAAAAAAAAAAAAAADgDfVGvWjBggVdz9/4xjeOKHyZMGFCbr/99tRqtSTJgw8+eNTmAwAAAAAAAAAAAAAAoAwNC2ZWrlyZWq2Ws846K2ecccYR7zvjjDMyefLkVFWVlStXHsUJAQAAAAAAAAAAAAAAKEHDgpkXX3wxSXL66ae/471v7Nm0aVOPzgQAAAAAAAAAAAAAAEB5GhbMdHR0JEn69ev3jve2t7cnSWq1Wo/OBAAAAAAAAAAAAAAAQHkaFsy85z3vSZI8/fTT73jvM888kyQZPnx4j84EAAAAAAAAAAAAAABAeRoWzPzO7/xOqqrKo48+mq1btx7xvhdffDGPPvpoarVaPvjBDx7FCQEAAAAAAAAAAAAAAChBw4KZiy++OEmyd+/ezJo1K6+++uph97z66qu58cYb89prryVJLrzwwqM6IwAAAAAAAAAAAAAAAL1fw4KZCy+8MOPHj0+SPPHEE/nEJz6RRYsWZffu3W9bu3v37ixcuDCf+MQn8uSTT6ZWq+V973tfLrnkkkaNCwAAAAAAAAAAAAAAQC/V3qgX1ev13Hbbbbn66quza9eubNq0KV/+8pdz00035fjjj8+QIUNSq9Xy8ssvZ9OmTamqKklSVVUGDRqUv/mbv0mtVmvUuAAAAAAAAAAAAAAAAPRSDbthJknGjx+fe++9N2PGjElVVamqKp2dndm4cWN+9rOfZc2aNXn++efT2dnZ9fkJJ5yQe++9N+PGjWvkqAAAAAAAAAAAAAAAAPRSDbth5g3jx4/PkiVL8k//9E95+OGHs3r16rz++utvWXPMMcfkgx/8YC677LJceuml6devX6PHBAAAAAAAAAAAAAAAoJdqeDCTJO3t7Zk6dWqmTp2affv25cUXX8yOHTtSVVWGDBmSgQMHprOzM6NGjWrGeAAAAAAAAAAAAAAAAPRi9Wa8dPHixbnmmmvyF3/xFzn22GNzwgknZMKECTnttNNy4oknZvHixTn33HPzqU99Kj/4wQ+aMSIAAAAAAAAAAAAAAAC9VENvmNmzZ09mzpyZxx9/PEnyrne966DrNmzYkKqq8rOf/Sw33nhjPvaxj+XWW29NW1tbI8cFAAAAAAAAAAAAAACgF2roDTNf+MIX8uMf/zhVVaWqqmzbtu2g68aOHZvf/M3f7Fq3ePHizJs3r5GjAgAAAAAAAAAAAAAA0Es1LJh57LHH8thjj6VWq2XAgAH5+te/nvvvv/+ga6dPn55HHnkkd911V0aOHJmqqvLAAw9k9erVjRoXAAAAAAAAAAAAAACAXqphwcyCBQuSJLVaLfPnz8+UKVPSr1+/bvecffbZueuuu9Le3p4k+e53v3vU5wQAAAAAAAAAAAAAAKB3a1gws2bNmtRqtXz0ox/NaaeddsT73v/+9+ejH/1oqqrKypUrj+KEAAAAAAAAAAAAAAAAlKBhwcy2bduSJKeccso73nvqqacmSV566aUenQkAAAAAAAAAAAAAAIDyNCyYaWtrS5K8/vrr73hvR0dHkqS9vb1HZwIAAAAAAAAAAAAAAKA8DQtmjj/++CTJihUr3vHe1atXJ0lGjRrVkyMBAAAAAAAAAAAAAABQoIYFM2eddVaqqsrq1auzbNmyI973H//xH3n88cdTq9Vy5plnHsUJAQAAAAAAAAAAAAAAKEHDgplPfvKTXc9f+MIXsnTp0sPu+bd/+7fccMMNqaoqtVotn/rUp47miAAAAAAAAAAAAAAAABSgvVEvOvXUUzNlypQsWLAge/bsycyZMzN+/Pice+65OfnkkzN48OAkya5du/Lss8/mX//1X7NmzZquWOaTn/xkPvCBDzRqXAAAAAAAAAAAAAAAAHqphgUzSTJ37txs2bIljz/+eJLk5z//eX7+858fcn1VVUmSc845J1/96lcbMiMAAAAAAAAAAAAAAAC9W72RLzv22GNz11135Ytf/GLe8573pKqqbv+MGDEis2fPzh133JH29oa2PQAAAAAAAAAAAAAAAPRSDa9Q6vV6PvOZz2T69Ol54okn8uMf/zhbtmzJL37xi3R0dGTw4MEZO3ZsJk2alA9/+MPp169fo0cEAAAAAAAAAAAAAACgF2vatS21Wi2TJk3KpEmTmjUCAAAAAAAAAAAAAAAABao3ewAAAAAAAAAAAAAAAADoSYIZAAAAAAAAAAAAAAAAiiKYAQAAAAAAAAAAAAAAoCiCGQAAAAAAAAAAAAAAAIoimAEAAAAAAAAAAAAAAKAoghkAAAAAAAAAAAAAAACKIpgBAAAAAAAAAAAAAACgKIIZAAAAAAAAAAAAAAAAiiKYAQAAAAAAAAAAAAAAoCiCGQAAAAAAAAAAAAAAAIoimAEAAAAAAAAAAAAAAKAoghkAAAAAAAAAAAAAAACKIpgBAAAAAAAAAAAAAACgKIIZAAAAAAAAAAAAAAAAiiKYAQAAAAAAAAAAAAAAoCiCGQAAAAAAAAAAAAAAAIoimAEAAAAAAAAAAAAAAKAoghkAAAAAAAAAAAAAAACKIpgBAAAAAAAAAAAAAACgKIIZAAAAAAAAAAAAAAAAiiKYAQAAAAAAAAAAAAAAoCiCGQAAAAAAAAAAAAAAAIoimAEAAAAAAAAAAAAAAKAoghkAAAAAAAAAAAAAAACKIpgBAAAAAAAAAAAAAACgKIIZAAAAAAAAAAAAAAAAiiKYAQAAAAAAAAAAAAAAoCiCGQAAAAAAAAAAAAAAAIoimAEAAAAAAAAAAAAAAKAoghkAAAAAAAAAAAAAAACKIpgBAAAAAAAAAAAAAACgKIIZAAAAAAAAAAAAAAAAiiKYAQAAAAAAAAAAAAAAoCiCGQAAAAAAAAAAAAAAAIoimAEAAAAAAAAAAAAAAKAoghkAAAAAAAAAAAAAAACKIpgBAAAAAAAAAAAAAACgKIIZAAAAAAAAAAAAAAAAiiKYAQAAAAAAAAAAAAAAoCiCGQAAAAAAAAAAAAAAAIoimAEAAAAAAAAAAAAAAKAoghkAAAAAAAAAAAAAAACKIpgBAAAAAAAAAAAAAACgKIIZAAAAAAAAAAAAAAAAiiKYAQAAAAAAAAAAAAAAoCiCGQAAAAAAAAAAAAAAAIoimAEAAAAAAAAAAAAAAKAoghkAAAAAAAAAAAAAAACKIpgBAAAAAAAAAAAAAACgKIIZAAAAAAAAAAAAAAAAiiKYAQAAAAAAAAAAAAAAoCiCGQAAAAAAAAAAAAAAAIoimAEAAAAAAAAAAAAAAKAoghkAAAAAAAAAAAAAAACK0t7sAVrZzp07c8kll2Tr1q35+Mc/nttuu+2Qazs7O7Nw4cIsWrQo69evz549ezJy5MhMmjQpU6dOzYc+9KHDvq9VzgAAAAAAAAAAAAAAAOjNBDPd+LM/+7Ns3br1sOt27dqV66+/PitWrHjLz1944YW88MILefjhhzNt2rTMnj275c8AAAAAAAAAAAAAAADo7QQzh7B06dI89NBDh11XVVVmzZrVFamcffbZufLKKzNixIisXbs23/rWt7Jp06bMnz8/w4cPz4wZM1r2DAAAAAAAAAAAAAAAgBLUmz1AK9q+fXvmzp17RGu///3vZ/ny5UmSKVOm5O67784FF1yQiRMn5sorr8yCBQsybty4JMk3v/nNbNmypWXPAAAAAAAAAAAAAAAAKIFg5iDmzZuXbdu2Zfjw4YddO3/+/CTJoEGD8qUvfeltnw8dOjTz5s1Lkuzbty/33HNPy54BAAAAAAAAAAAAAABQAsHMr/nnf/7nLFmyJPV6PXPmzOl27caNG/PUU08lSc4777wMHTr0oOvOOOOMnHTSSUmSJUuWtOQZAAAAAAAAAAAAAAAApRDMvMm2bdty8803J0mmTZuW0047rdv1P/3pT7ueJ0+e3O3aM888M0myadOmbNiwoeXOAAAAAAAAAAAAAAAAKIVg5k3mzp2bl19+OSeddFJmzZp12PXPPPNM1/OJJ57Y7dqxY8d2PT/99NMtdwYAAAAAAAAAAAAAAEApBDP/a9GiRVm6dGnq9XpuueWWHHvssYfds2XLlq7n4447rtu1o0ePPui+VjkDAAAAAAAAAAAAAACgFIKZJC+++GL+/M//PEkybdq0nH766Ue075VXXul6HjhwYLdrBwwY0PW8a9euljsDAAAAAAAAAAAAAACgFO3NHqAVzJkzJzt37syJJ56YG2+88Yj37d+/v+u5f//+3a598+dv3tcqZzTD4MHdzwoAAAAAAAAAR6perzV7BPqYer2W4cO7/4tNgcbz+4BG8/sAAKB19flg5oEHHsiPfvSj1Ov13HLLLYcNTt6sra2t67lW6/5ftKqq6nqu1391sU+rnNEMbW0uOAIAAAAAAAAAeqdarZa2Nv9hPkBf5/cBAEDr6tPBzAsvvJBbb701SfLpT386kyZNekf7BwwY0PW8d+/e9OvX75Br9+3b1/X85nWtckYzHDjQ2dT3AwAAAAAAAFCOer122L9kEnpSVVXp7KwOvxBoKL8PaDS/DwAAek5PX8rRZ4OZqqryJ3/yJ9m9e3dOPPHEzJo16x2fMXDgr65RfO211zJ48OBDrt2zZ0/X85AhQ1rujGbYuXNvOjoONHUGAAAAAAAAAMowfPhAf7s7DdXZWWX79lebPQbwa/w+oNH8PgAA6Bnt7W0ZNmzA4Re+kzN79LRe5Lvf/W4ef/zxJMm1116b55577m1rtm7d2vW8c+fOrF27NkkyYsSIjBw5MmPGjOn6fPPmzRk1atQh37d58+au5zeva5UzAAAAAAAAAAAAAAAAStFng5nVq1d3Pd98882HXb9s2bIsW7YsSXLDDTdk5syZOfnkk7s+37BhQyZOnHjI/Rs3bux6HjduXNdzq5wBAAAAAAAAAAAAAABQinqzB+jNJk6cmFrtl9d3rlq1qtu1K1asSJKMHj06xx9/fMudAQAAAAAAAAAAAAAAUIo+G8zceuutWb9+fbd/fvjDH3at//jHP97185kzZyb5ZXTyxm0ujzzySHbv3n3Qd61atSrPPfdckuSiiy56y2etcgYAAAAAAAAAAAAAAEAp+mww01OuueaaJMmOHTsyd+7cdHZ2vuXzV155JXPnzk2SHHPMMbn66qtb9gwAAAAAAAAAAAAAAIAStDd7gN7ukksuyYIFC7J8+fIsXrw4W7ZsybXXXptRo0Zl/fr1ufPOO7Np06YkycyZMzN27NiWPQMAAAAAAAAAAAAAAKAEgpkecPvtt+e6667LypUrs2rVqqxatepta6ZNm5YZM2a0/BkAAAAAAAAAAAAAAAC9nWCmBwwaNCj33HNPFi1alIceeijr1q3Lrl27MmzYsJx++um56qqrMnny5F5xBgAAAAAAAAAAAAAAQG9Xq6qqavYQ9E0vv7wnHR0Hmj0GAAAAAAAAAAUYPnxg2trq+cWe/fnsv/ys2eNQsDsv/mDeM6BfDhzozPbtrzZ7HODXvPH7YO+eA3n0+y83exwKdt7Hh6X/gDa/DwAAekh7e1uGDRvQo2fWe/Q0AAAAAAAAAAAAAAAAaDLBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQFMEMAAAAAAAAAAAAAAAARRHMAAAAAAAAAAAAAAAAUBTBDAAAAAAAAAAAAAAAAEURzAAAAAAAAAAAAAAAAFAUwQwAAAAAAAAAAAAAAABFEcwAAAAAAAAAAAAAAABQlPZmDwAAAAAAAAAAAABAzxg6dEDq9Vqzx6AP6eyssmPHnmaPAQBvI5gBAAAAAAAAAAAAKES9XktbW73ZY9CndDZ7AAA4KMEMAAAAAAAAAAAAQGGqziode4QMHD3tA+qpuc0IgBYmmAEAAAAAAAAAAAAoTMeezvz83m3NHoOCjb96RI4Z1NbsMQDgkNy5BwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABSlvdkDAAAAAAAAAAAA/3dDhw5IvV5r9hj0IZ2dVXbs2NPsMQAAAA5KMAMAAAAAAAAAAAWo12tpa6s3ewz6lM5mDwAAAHBIghkAAAAAAAAAAChIZ1Xl1b1CBo6egf3rqdfcZgQAALQ2wQwAAAAAAAAAABTk1b2d+bslW5s9BgW7/vd+I+9+V1uzxwAAAOiWO1gBAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICitDd7gFaybdu23HfffVm+fHmee+657NmzJ4MGDcrJJ5+c888/P1dccUUGDBhwyP2dnZ1ZuHBhFi1alPXr12fPnj0ZOXJkJk2alKlTp+ZDH/rQYWdolTMAAAAAAAAAAAAAAAB6K8HM/1q6dGlmz56dXbt2veXnL7/8clasWJEVK1bknnvuyd/+7d/m1FNPfdv+Xbt25frrr8+KFSve8vMXXnghL7zwQh5++OFMmzYts2fPPuQMrXIGAAAAAAAAAAAAAABAbyaYSbJixYrMmjUrr7/+eo455phcccUVOffcczN06NBs3rw5CxcuzKOPPppNmzZl+vTpWbBgQUaPHt21v6qqzJo1qytSOfvss3PllVdmxIgRWbt2bb71rW9l06ZNmT9/foYPH54ZM2a8bYZWOQMAAAAAAAAAAAAAAKC3qzd7gGarqirz5s3rimXuvvvufPWrX81HPvKRTJgwIRdddFHuuOOOfP7zn0+SbN++Pbfddttbzvj+97+f5cuXJ0mmTJmSu+++OxdccEEmTpyYK6+8MgsWLMi4ceOSJN/85jezZcuWt83RKmcAAAAAAAAAAAAAAAD0dn0+mFm9enWeeeaZJMnUqVNz1llnHXTd9ddfn/HjxydJfvCDH2TPnj1dn82fPz9JMmjQoHzpS196296hQ4dm3rx5SZJ9+/blnnvueduaVjkDAAAAAAAAAAAAAACgt+vzwczKlSu7ns8///xDrqvVavnd3/3dJMn+/fvz7LPPJkk2btyYp556Kkly3nnnZejQoQfdf8YZZ+Skk05KkixZsuQtn7XKGQAAAAAAAAAAAAAAACXo88HMhAkTct111+Wyyy7rCkkOpaqqrud9+/YlSX760592/Wzy5Mnd7j/zzDOTJJs2bcqGDRu6ft4qZwAAAAAAAAAAAAAAAJSgvdkDNNvkyZMPG5i84Sc/+UnX85gxY5IkzzzzTNfPTjzxxG73jx07tuv56aefzgknnNBSZwAAAAAAAAAAAAAAAJSgz98wc6SWLVuWtWvXJknGjx+f9773vUmSLVu2dK057rjjuj1j9OjRXc9v3tcqZwAAAAAAAAAAAAAAAJRAMHMEtm/fnrlz53b982c+85mu51deeaXreeDAgd2eM2DAgK7nXbt2tdwZAAAAAAAAAAAAAAAAJWhv9gCt7tVXX83nPve5bN68OUly5pln5g/+4A+6Pt+/f3/Xc//+/bs9682fv3lfq5zRaIMHdz8nAAAAAAAAAByper3W7BHoY+r1WoYP7/4vNW003wMazfcAfA8gac3vAQAkgplu7dq1KzNmzMjq1auTJO9973vzV3/1V6nXf3UxT1tbW9dzrdb9/8msqqrruRXPaLS2NhccAQAAAAAAAAC9U61WS1ub/yCZvs33AHwPIPE9AKB1CWYOYevWrZkxY0bWrl2bJBkxYkS+/e1vZ+TIkW9ZN2DAgK7nvXv3pl+/foc8c9++fV3Pb17XKmc02oEDnU17NwAAAAAAAABlqddrh/0LJqEnVVWVzs7q8AsbyPeARvM9AN8DSFrzewBA79TTl3IIZg5i3bp1+exnP5stW7Yk+eXNMt/+9rfzvve9721rBw781RVyr732WgYPHnzIc/fs2dP1PGTIkJY7o9F27tybjo4DTXs/AAAAAAAAAOUYPnygv9WahursrLJ9+6vNHuMtfA9oNN8D8D2ApDW/BwD0Pu3tbRk2bMDhF74DPZvfFGDZsmW58soru2KZ3/qt38o//uM/HjSWSZIxY8Z0PW/evLnbs9/8+ahRo1ruDAAAAAAAAAAAAAAAgBIIZt5k4cKFuf7667tuYJk0aVLuu+++t8Qov+7kk0/uet6wYUO352/cuLHredy4cS13BgAAAAAAAAAAAAAAQAkEM/9rwYIF+fKXv5yOjo4kycUXX5zvfOc7GTp0aLf7Jk6cmFrtl1cXrlq1qtu1K1asSJKMHj06xx9/fMudAQAAAAAAAAAAAAAAUALBTJKVK1dmzpw5qaoqSXL11Vfnr//6r9OvX7/D7h09enQmTpyYJHnkkUeye/fug65btWpVnnvuuSTJRRdd1JJnAAAAAAAAAAAAAAAAlKDPBzO7d+/OF7/4xRw4cCBJcvnll+crX/lK120tR+Kaa65JkuzYsSNz585NZ2fnWz5/5ZVXMnfu3CTJMccck6uvvrplzwAAAAAAAAAAAAAAAOjt2ps9QLPde++92bx5c5Jk5MiRueKKK7J27drD7hs9enSGDh2aJLnkkkuyYMGCLF++PIsXL86WLVty7bXXZtSoUVm/fn3uvPPObNq0KUkyc+bMjB079m3ntcoZAAAAAAAAAAAAAAAAvV2fD2buv//+rueXXnopf/iHf3hE+2655ZZMmTKl659vv/32XHfddVm5cmVWrVqVVatWvW3PtGnTMmPGjEOe2SpnAAAAAAAAAAAAAAAA9GZ9OpjZvn171+0y/1eDBg3KPffck0WLFuWhhx7KunXrsmvXrgwbNiynn356rrrqqkyePLlXnAEAAAAAAAAAAAAAANCb9elgZvjw4Vm/fn2PnVev1zNlypS33DzTW88AAAAAAAAAAAAAAADorerNHgAAAAAAAAAAAAAAAAB6kmAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKIpgBgAAAAAAAAAAAAAAgKIIZgAAAAAAAAAAAAAAACiKYAYAAAAAAAAAAAAAAICiCGYAAAAAAAAAAAAAAAAoimAGAAAAAAAAAAAAAACAoghmAAAAAAAAAAAAAAAAKEp7swcAAAAAAAAAAAAAAOgJQ4cOSL1ea/YY9CGdnVV27NjT7DGAgxDMAAAAAAAAAAAAAABFqNdraWurN3sM+pTOZg8AHIJgBgAAAAAAAAAAAAAoStVZpfPVjmaPQcHqA9tTc5sRtDTBDAAAAAAAAAAAAABQlM5XO/LS//ffzR6Dgo2c8b60vfuYZo8BdMN9YwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAAAAAAURTADAAAAAAAAAAAAAABAUQQzAAAAAAAAAAAAAAAAFEUwAwAAAAAAAAAAAAAAQFEEMwAAAAAAAAAAAAAAABRFMAMAAAAAAAAAAAAAAEBRBDMAAAAAAAAAAAD8/+3dd5hV1bk/8O/MUARBQClixRt7jO3aotgFY8felahXMcYSY9Qklmhy1SSa/IyaxEpEvbF37IrtqqBGoxFRRBREuoAgnZnfHzycOxOYYWBmmJnj5/M8PM/i7LX3efeZtXZ/9wIAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCotGjsAWF4dO7ZNaWlJY4fBt0h5eUWmTp3Z2GEAAAAAAAAAAAAAALAUEmZotkpLS1JWZpAkVqTyxg4AAAAAAAAAAAAAAIBakDBDs1dRXp7ymbMaOwyKWGnbNikplZwFAAAAAAAAAAAAANBcSJih2SufOStf3fFQY4dBEVv1+INT1m7lxg4DAAAAAAAAAAAAAIBaMmQCAAAAAAAAAAAAAAAARcUIMwAAAAAA0Mx17Ng2paUljR0G3yLl5RWZOnVmY4cBAAAAAABQLQkzAAAAAADQzJWWlqSszKDyrEjljR0AAAAAAABAjSTMAAAAAABAkVhQUZ4ps436QcPptFLblJVIzgIAAAAAAJo+CTMAAAAAAFAkpsyemROf7N/YYVDEbt/nh+ncpl1jhwEAAAAAALBUXgEGAAAAAAAAAAAAAABAUZEwAwAAAAAAAAAAAAAAQFGRMAMAAAAAAAAAAAAAAEBRkTADAAAAAAAAAAAAAABAUZEwAwAAAAAAAAAAAAAAQFGRMAMAAAAAAAAAAAAAAEBRkTADAAAAAAAAAAAAAABAUZEwAwAAAAAAAAAAAAAAQFGRMAMAAAAAAAAAAAAAAEBRadHYAQAAAAAA1EXHjm1TWlrS2GHwLVJeXpGpU2c2dhgAAAAAAABADSTMAAAAAADNWmlpScrKDKbNilTe2AEAAAAAAAAASyFhBgAAAAAoCgsqyjNl9teNHQZFrNNKq6SsRHIWAAAAAAAANAcSZgAAAACAojBl9tc54elfN3YYFLEBe1+czm06NnYYAAAAAAAAQC14FR4AAAAAAAAAAAAAAABFRcIMAAAAAAAAAAAAAAAARUXCDAAAAAAAAAAAAAAAAEVFwgwAAAAAAAAAAAAAAABFRcIMAAAAAAAAAAAAAAAARUXCDAAAAAAAAAAAAAAAAEVFwgwAAAAAAAAAAAAAAABFRcIMAAAAAAAAAAAAAAAARUXCDAAAAAAAAAAAAAAAAEVFwgwAAAAAAAAAAAAAAABFRcIMAAAAAAAAAAAAAAAARUXCDAAAAAAAAAAAAAAAAEWlRWMHAAAAAHXRsWPblJaWNHYYfIuUl1dk6tSZjR0GAAAAAAAAAAA1kDADAABAs1ZaWpKyMgOosiKVN3YAAAAAAAAAAAAshYQZAAAAikJ5+YLMnPVVY4dBEWvbZtWUlpY1dhgAAAAAAAAAANSChBkAAACKwsxZX+WuB49r7DAoYscecmfardylscMAAAAAAAAAAKAWShs7AAAAAAAAAAAAAAAAAKhPEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCoSZgAAAAAAAAAAAAAAACgqEmYAAAAAAAAAAAAAAAAoKhJmAAAAAAAAAAAAAAAAKCotGjsAAABg+XXs2DalpSWNHQbfIuXlFZk6dWZjhwEAAAAAAAAAAFAjCTMAANCMlZaWpKzMwJGsSOWNHQAAAAAAAAAAAMBSSZgBAIAiUFG+ILNnTWnsMChiK7XplJLSssYOAwAAoFpGYWVFMworAAAAAEDTJmEGAACKwOxZU/LMPcc3dhgUsd5H3pE2K3du7DAAAACqZRRWVjyjsAIAAAAANGUSZgAAAAAAACgaCyrKM2XW7MYOgyLWqc1KKSuRnAUAAAAA0NRJmAEAAAAAAKBoTJk1O32feKixw6CI/W3fg9O5bdvGDgMAAAAAgKXw6iMAAAAAAAAAAAAAAACKioQZAAAAAAAAAAAAAAAAioqEGQAAAAAAAAAAAAAAAIqKhBkAAAAAAAAAAAAAAACKioQZAAAAAAAAAAAAAAAAikqLxg4AAAAAAAAAAAAAAACoHx07tk1paUljh8G3SHl5RaZOndnYYSxGwgwA0Gw5qGdFa6oH9QAAAAAAAAAAAIuUlpakrKy0scPgW6W8sQNYIgkzAM2YZAFWtKaWLOCgnhWvaR7UAwAAAEDivgErXlO7bwAAAABUVVFekfKZcxo7DIpYadvWKWnC1yQlzAA0Y5IFWPGaZrJARfmCzJs5pbHDoIi1bNspJaVljR0GAAAAANTIfQNWvKZ53wAAAABYqHzmnEzu/3pjh0ERW+2H309Zu5UaO4xqSZgBKAIV5eUpnzm9scOgiJW2bZ+S0qZ7k3XezCn5510/bOwwKGJbHNs/rdp1buwwAAAAAKBWFlRUZMosbw6l4XRq0zplJU33zaEAAAAAkEiYKUrl5eV56KGH8vDDD+ejjz7KzJkz06VLl2y99dY56qijsu222zZ2iEA9K585PRMGXNHYYVDEup7wi5S169DYYQAAAAAAUAtTZs3JyU8MauwwKGK37rt7Ordtum8OBQAAAIBEwkzRmT59en70ox9lyJAhVT7/8ssv8+WXX2bgwIHp27dvLrzwwkaKEAAAAAAAAAAAAAAAoGFJmCkiFRUVOeeccwrJMj179szRRx+dzp0758MPP8zNN9+cMWPGpH///ll11VVz6qmnNnLEAAAAAAAAAAAAAAAA9a+0sQOg/jz22GN59dVXkySHHHJIbr311uy1117Zcsstc/TRR+fBBx/M+uuvnyS5/vrrM27cuMYMFwAAAAAAAAAAAAAAoEFImCki/fv3T5K0a9cuF1xwwWLTO3bsmMsuuyxJMmfOnAwYMGCFxgcAAAAAAAAAAAAAALAiSJgpEqNHj87QoUOTJLvvvns6duy4xHrbbLNN1ltvvSTJU089taLCAwAAAAAAAAAAAAAAWGEkzBSJt99+u1DeYYcdaqy73XbbJUnGjBmTUaNGNWhcAAAAAAAAAAAAAAAAK5qEmSLxySefFMo9evSose7aa69dKA8fPryhQgIAAAAAAAAAAAAAAGgUEmaKxLhx4wrlNdZYo8a63bt3X+J8AAAAAAAAAAAAAAAAxaBFYwdA/Zg2bVqhvPLKK9dYt23btoXy9OnTGyympSkrq6d8rdLStFi9S/0sC5ak9P/aaosWZY0YSA1Ky9Jy9R6NHQXFrPT/2n5T7AclpS3SbvVNGzsMilhJ6f8dNjfFPpAkpaUtsmq37zZ2GBSx0mbSD1bvoh/QcJpyP2jfvnVKSkoaOwy+RSoqKjJ9+pzGDmMxLUrLsumq6zV2GBSxFk38/DhJWpSWZtPVui+9IiynFs3geunCfuC+AQ2nefSDkmyyWqfGDoMi1qL0/85Bm2I/aFFako1Xq/m+OdRFU+8DSVJWmqy5WsvGDoMiVvmxn6baD0pKk06dPR5HwylpJv2g7er2BzScJt8PykrScs02jR0Fxays6Z8bpLQkLbt3aOwoKGb1eI5cb/kFlZRUVFRU1PtSWeFOPPHEvPHGG0mS9957L61bt6627muvvZYf/vCHSZIzzjgjZ5111gqJEQAAAAAAAAAAAAAAYEWo/xQcGkVZ2f9lYy3tjbKVc6RKSzUBAAAAAAAAAAAAAACguMiWKBJt27YtlGfPnl1j3Tlz5hTKrVq1arCYAAAAAAAAAAAAAAAAGoOEmSKx8sorF8qzZs2qse7MmTML5Q4dOjRYTAAAAAAAAAAAAAAAAI1BwkyRWHPNNQvlsWPH1li38vRu3bo1WEwAAAAAAAAAAAAAAACNQcJMkdhggw0K5VGjRtVYd/To0YXy+uuv32AxAQAAAAAAAAAAAAAANAYJM0Viyy23TElJSZLkrbfeqrHukCFDkiTdu3fPWmut1eCxAQAAAAAAAAAAAAAArEgSZopE9+7ds+WWWyZJnn766cyYMWOJ9d56662MHDkySbL33nuvqPAAAAAAAAAAAAAAAABWGAkzReT4449PkkydOjWXXnppysvLq0yfNm1aLr300iRJy5Ytc9xxx63wGAEAAAAAAAAAAAAAABpaSUVFRUVjB0H9Ofnkk/Pqq68mSbbZZpuccMIJ6datWz766KPceOONGTNmTJLk3HPPzWmnndaYoQIAAAAAAAAAAAAAADQICTNFZsaMGenXr1/efPPNauv07ds3F154YUpKSlZgZAAAAAAAAAAAAAAAACuGhJkiVF5enocffjiPPvpohg0blunTp6dTp07Zaqutcuyxx2aHHXZo7BABAAAAAAAAAAAAAAAajIQZAAAAAAAAAAAAAAAAikppYwcAAAAAAAAAAAAAAAAA9UnCDAAAAAAAAAAAAAAAAEVFwgwAAAAAAAAAAAAAAABFRcIMAAAAAAAAAAAAAAAARUXCDAAAAAAAAAAAAAAAAEVFwgwAAAAAAAAAAAAAAABFRcIMAAAAAAAAAAAAAAAARUXCDAAAAAAAAAAAAAAAAEVFwgwAAAAAAAAAAAAAAABFRcIMAAAAAAAAAAAAAAAARUXCDAAAAAAAAAAAAAAAAEVFwgwAAAAAAAAAAAAAAABFRcIMAAAAAAAAAAAAAAAARUXCDAAAAAAAAAAAAAAAAEWlRWMHAKx4F198ce69997069cvP/nJTxo7HKizSZMm5e9//3teffXVjBw5MjNnzky7du2ywQYbZM8998wRRxyRtm3bVjv/+PHjc8cdd+Sll17KF198kSTp1q1bevbsmcMPPzwbbbTRiloVWG517QdTpkzJHXfckUGDBmXUqFGZO3du1lhjjey444457rjj8p3vfGcFrg0su7puy+0LKAZ1bcf2BRSrr7/+Ovvtt18mTJiQAw44IFdfffUS67300ks59dRTa7XMnj175tZbb63PMKHB1LYPLDJ8+PDcfffdee211zJu3LiUl5dnzTXXzM4775y+ffume/fuKyhyWHb1sS13bkCxqMv2XD+gGCxrH7juuuty/fXXL/P3HHzwwbnqqqvqK2yok/psx+Xl5XnooYfy8MMP56OPPsrMmTPTpUuXbL311jnqqKOy7bbb1lfYUG+W5TmI+mjjrqfSVC3PM0Fz587NoYcemo8//jj9+/fPjjvuuNR5xo8fnwEDBuSVV17JF198kXnz5qVLly7Zaqutcswxx+Q///M/67oqsFyWpQ801Pnvsl6Thfq2ovvBrFmzcs899+TZZ5/N8OHDM3PmzKyyyirZdNNNc9BBB2XfffdNWVlZvawb1FZt+0F93SPWD5o2CTPwLfPss8/m3nvvbewwoN4899xzufDCCzN9+vQqn0+ZMiVDhgzJkCFDMmDAgNxwww3ZZJNNljj/BRdckBkzZlT5fOTIkRk5cmT+/ve/p1+/fjnzzDMbdD2gLuraD1599dWce+65mTZtWpXPP/vss3z22We59957c/755+fEE09s0PWA5VXXbbl9AcWgru3YvoBi9utf/zoTJkxYar1hw4atgGhgxattH0iSP//5z7nhhhsyf/78Kp+PGDEiI0aMyP33358//OEP2XXXXRsiVKizum7LnRtQLOqyPdcPKAYr8pimZcuWdV4GNLZ/b8fTp0/Pj370owwZMqTK519++WW+/PLLDBw4MH379s2FF164IsOEGi3LcxD10cZdT6WpWt5ngn7/+9/n448/rnX9QYMG5bzzzlvsvGHMmDEZM2ZMHn/88Zxwwgn5xS9+kZKSkmWOB5bXsvSBhjz/XZZrslDfVnQ/+Oyzz9KvX7+MHDmyyueTJ0/OK6+8kldeeSX33ntvrr/++nTo0GHZVwiWw7L0g/q4R6wfNH0SZuBb5KWXXjKiDEVlyJAhOeecczJv3ry0bNkyRxxxRHbbbbd07NgxY8eOzUMPPZRBgwZlzJgxOemkk/Lggw9WeWvcO++8U5i/rKwsRxxxRHbZZZe0a9cuQ4cOzc0335xJkybl+uuvz8orr5yTTjqpEdcWlqyu/eDtt99Ov379Mm/evCQpvCGie/fuGTVqVAYMGJD33nsvV1xxRb7++msPQ9Dk1HVbbl9AMahrO7YvoJg999xzefTRR2tVd+jQoUmSzp0755Zbbqmxbrt27eocG6wIy9IHrr/++lx33XVJkk6dOuWkk07KVlttlfnz5+epp57KvffemxkzZuSss87Kgw8+6E25NEl12ZY7N6BY1GV7rh9QDJa3Dxx11FHZa6+9lrr8L774Ij/5yU8Kb1A/44wzGnR9YFnURzuuqKjIOeecU0gk6NmzZ44++uh07tw5H374YW6++eaMGTMm/fv3z6qrrlrrt/BCQ1qW5yDqo427nkpTtbzPBF177bUZMGBAresPHTo0Z511VubOnZuSkpIccsgh2XPPPdO+ffu89957uemmmzJt2rQMGDAg7dq1y9lnn73MMcHyWJY+0JDnv8tyTRbq24ruBzNnzswpp5yS0aNHJ0m23XbbHHXUUenevXs+++yz3Hbbbfnkk08yZMiQ/PjHP86AAQMkUtLglvWYqK73iPWD5qGkoqKiorGDABre3/72t1x99dWFizZJlmn4VWhqKioqsv/+++eTTz5Jy5Ytc+utt2b77bdfrN4NN9yQP/3pT0mS/fffP9dcc01h2sEHH1w44LnhhhsWu4kwefLkHHTQQZk4cWLatm2bF198UYYvTUpd+8H8+fOzzz77ZNSoUUmSM844I2eddVaVeefPn5+f/vSneeqpp1JWVpb7778/m266aQOvGdReXbfl9gUUg7q0Y/sCitlXX32VAw44IJMmTSp8dsABB+Tqq69eYv3evXvn888/zy677JKbb755RYUJDWZZ+sCHH36Yww47LPPnz8+aa66Z22+/PWuvvXaVOvfcc08uueSSJMnee+9dOMeApqQu23LnBhSDum7P9QOau4Y+ppk7d26OPPLIDB06NKWlpfnb3/62xOux0JQtrR0/+uij+dnPfpYkOeSQQ3LllVdWmX/q1Kk59thj88knn6R169Z55plnsvrqq6/QdYDKlvU5iLq2cddTaaqW55mgWbNm5dJLL80jjzxS5fP+/ftnxx13rHa+U045Ja+88kqS5De/+U0OP/zwKtPHjRuXww47LBMnTkzLli3z/PPPp1u3bsuzWlBry9oHGur8d1nvS0B9aox+cNNNNxWeQTrwwAPzu9/9rkoiwNy5c3PaaafltddeS7IwSfMHP/hB3VcWqrE8x0R1vUesHzQPpY0dANCwFg31deWVVxaygaEYvPvuu/nkk0+SLHxjVnU3pX70ox9lww03TJI888wzmTlzZpLkX//6V+Ggf++9917iG7dWW221nHzyyUkWZgK/+OKL9b0aUCd17Qcvvvhi4YL+jjvuuNgF/SRp0aJFrrjiinTs2DELFizI73//+4ZYFVgudd2W2xdQDOraju0LKGaXXXZZJk2alFVXXXWpdWfMmFHoCx5goFgsSx/405/+lPnz56ekpCT/7//9v8UeLE2SI488snBe8cILL2T27Nn1HjPURV225c4NKBZ12Z7rBxSDhj6muf766wv95KSTTpIsQ7O0tHbcv3//JAvfmnvBBRcsNn/Hjh1z2WWXJUnmzJmzTCMSQH1a3ucg6trGXU+lqVnevvD666/nsMMOKyTL1Ha+uXPn5vXXX0+SrL/++oslyyTJ6quvnlNOOSVJMm/evLz88su1WjYsj+XpAw15/rss12ShvjRmP3jppZcK5QsvvHCxUTNatWqV888/v/D/559/vlbrBMtqeY+J6uMesX7QPEiYgSJ21113Zf/998+gQYOSLDxZXXRxB5q7N998s1Dec889q61XUlKSnXbaKcnCizeffvppobzXXntlnXXWSa9evaqd/z/+4z8K5bFjx9Y1bKhXde0Hiy5mJskJJ5xQ7fwrr7xyIbP9jTfeyOTJk+sUN9SXum7L7QsoBnVtx/YFFKsnnngiTz31VEpLS3PRRRcttf6wYcOyaBDmTTbZpKHDgwa3LH1gypQphbeC7r333tl8882rrXvyySfniCOOyEknnVRIxIemoi7bcucGFIO6bs/1A5q7hj6mGTZsWG699dYkyTrrrJMzzzyz7kHDCra0djx69OjCQ3O77757OnbsuMTlbLPNNllvvfWSJE899VTDBQzVWN7nIOqjjbueSlOyvH3hpz/9afr27Vt4MWPv3r1z4okn1uo7p06dmvnz5ydJevToUW29RX0oSSZOnFirZcOyWt4+0FDnv8t6XwLqQ2P3g0WjKa2yyipZbbXVlrgM+wQaWl2ek66Pe8T6QfPQorEDABrO+++/n3nz5qVVq1b54Q9/mDPOOCPvvvtuY4cF9WLzzTdPv379Mn78+CoHFEuy6KAmWfgmoCTZeuuts/XWWy/1e8aMGVMod+3adTmjhYZR135QuX1vscUWNc6/wQYbJEnKy8vz7rvv1pigAytKXbfl9gUUg7q2Y/sCitGkSZNy+eWXJ0n69u271LadpPCwRJJ897vfbbDYYEVY1j7w2muvFYam33///Wus26dPn/Tp06de4oT6VpdtuXMDikFdt+f6Ac1dQx/T/PrXvy48HHrRRRdlpZVWWq44oTEtrR2//fbbhfIOO+xQ47K22267jBw5MmPGjMmoUaOyzjrr1H/AUI3lfQ6iPtq466k0JcvbF955550kC0cOOP/889OnT59cd911tfrO1VZbLS1btsy8efMyYsSIauuNHDmyUF599dVrtWxYVsvbBxri/Hd57ktAfWjsftC1a9d89tln+frrrzNx4sR06dJlsTqLXuqb2CfQMOrynHR93CPWD5oHCTNQxFq3bp3DDz88p59+etZcc83GDgfq1Q477LDUC5mLDB48uFBelr7w1Vdf5bbbbkuStG3bNrvvvvuyBQkNrK79YNEN5GRhG69Jixb/d9j42WefLUOU0Ljqui23L6AY1NSO7QsoRpdeemmmTJmS9dZbL+ecc06t3tLz4YcfJknat2+fBQsW5Morr8yrr76a0aNHp0WLFll33XWz55575oQTTsgqq6zS0KsAdbKsfWDYsGGFcuU3sZeXl2fixIn55ptv0q1bt6y88soNFjPUh4beljs3oKlbEdtz/YCmrCH7wHPPPZe33norSbLTTjtl1113rXvAsILVph0vGmkgqXnUgCRZe+21C+Xhw4dLmGGFWt7nIOqjjbueSlOyvH2hc+fOOfTQQ9O3b99lPjYqKyvLLrvskueffz4jR47Mgw8+mEMOOaRKncmTJ+eWW25JsrCf7Lbbbsv0HVBbDflc3LKe/y7PfQmoD43dD/bcc88MGTIkSXLNNdfkqquuqjJ9wYIFufrqqwv/33fffes1Rkjq1g/q476CftA8SJiBInbppZemtLS0scOARvXSSy8VDmw23HDDpWbozpkzJ1988UWef/75DBgwIBMnTkxJSUkuvvjidOrUaUWEDPWuun5QuU2PGzeuxpsDlYdWdXGHpq6u23L7AopBbduxfQHF5uGHH85zzz2X0tLSXHnllWndunWt5lv09qB58+Zl//33r/Lww5w5czJ06NAMHTo0d955Z6677rpsu+22DRI/1NXy9IHhw4cnSVq2bJmuXbtm0qRJue666/Lkk09m2rRpSRY+DLHtttvmzDPPzDbbbNOg6wDLqyG25c4NaE4aanuuH9BcNOQxTeU3rp911ln1GzisILVpx+PGjSuU11hjjRqX17179yXOByvC8j4HUR9t3PVUmpLl7Qt33313nZ4luuCCC/Kvf/0r48ePzy9/+cu8++672W233bLKKqtk6NChuemmmzJx4sSUlZXlsssuy6qrrrrc3wU1qe/n4pb3/Hd570tAfWjsfnD00Ufn+eefz5AhQ/LQQw9l7NixOeKII9K9e/eMHj06t99+ez744IMkyVFHHZVddtml3mKFRerSD+rjvoJ+0DxImIEiJlmGb7uvvvoql156aeH/J598co3133///Rx22GFVPlt99dXzq1/9ytsSabZq6gdbbrllHnvssSTJM888k1NPPbXa5bzwwguF8syZMxsgUqgfdd2W2xdQDJalHdsXUEzGjx+f//7v/06S9O3bN1tttVWt5ps7d25GjBiRJJk9e3bat2+fvn37Zvvtt88qq6ySkSNH5oEHHsiQIUMyZcqUnHzyyfmf//mfbLbZZg22LrA8lrcPTJ06NUnSrl27vPvuu+nXr1/hs0UWLFiQN954I4MHD87555+fk046qT5DhzpriG25cwOam4bYnusHNCcNdUzz2muvFUav2W677bLlllvWc+TQ8GrbjhcllyVZ6ogDlUfWmD59et2DhGWwvM9B1Ecbdz2VpmR5+0JdnyVad911c++99+ZPf/pTHnroodxzzz255557qtT53ve+l1/+8pe1vj4Fy6M+n4tb3vPf5b0mC/WlsftB69atc/PNN+fWW29N//7988Ybb+SNN96oUqdLly45//zzc+CBB9ZbrFDZ8vaD+rqvoB80D56mB6AoffPNNzn99NMLb+7ZbrvtlnrA8eWXXy722cSJE3PPPffkX//6V4PECQ1paf3gBz/4QVZaaaUkyY033lhlKPrKBgwYkI8//rjw//nz5zdg1FA3dd2W2xdQDJalHdsXUEwuuuiifP311+nRo0fOPvvsWs83fPjwwtuCevTokYcffjjnnXdedt5552yxxRbp06dP7rjjjsIDEHPmzMn555+f8vLyBlkPWF7L2we++eabJAvbdr9+/TJt2rQcf/zxGThwYN5///289NJLufDCC9O2bdtUVFTkt7/9bZ544omGWg1YLg2xLXduQHPTENtz/YDmpKGOafr3718on3LKKQ0WPzSk2rbjuXPnFsqLrhdVp/L0yvNBU1Yfbdz1VFjo3XffzfDhw6s9rx4+fHgGDhyYr7/+egVHBstnec9/l/eaLDRFy9sPPvnkk3z44YfVJghPmjQpTz75ZCExAZqK+ryvoB80fRJmACg606dPzymnnJJ33303ycJs9z/84Q9LzSbu0aNHbrzxxtx333254YYbsu+++2bBggUZNGhQjjvuuLzyyisrIHqoH7XpB507d86PfvSjJMmMGTNyzDHH5I477siECRMyb968fPrpp/nNb36TK664It26dSvM17JlyxW6LrAs6rotty+gGCxLO7YvoFjcd999efnll1NaWporr7xyqQ89VLbxxhvn2WefTf/+/XPrrbdmrbXWWmK9c889t/B2uBEjRuTFF1+sj9ChXtSlD8yaNSvJwrfdTp06Nb/+9a9z0UUXZf3110+rVq2y+uqr54c//GH69+9f2P5fddVVmTNnToOsCyyPhtiWOzeguWmI7bl+QHPSEH1gxIgRhXa+0UYbZdddd234FYF6tiztuKysrFAuKSmpcbkVFRWFcn2+1RoaUn20cddTIfnTn/6Us88+O++991423njj/OUvf8lbb72V9957L/fdd1/233//zJ49O3fccUf69u272Kh/0BQtz/lvXa7JQlO0PP3gxRdfzLHHHptnn302HTp0yK9+9au88soref/99/P000/njDPOSMuWLfPCCy/kmGOO8QIWmpT6uq+gHzQPrlwAUFQmTJiQ448/Pv/4xz+SLLxoedttt6VLly5LnXejjTbKbrvtls033zx77bVX/vjHP+aKK65IsvBm23nnnZcZM2Y0aPxQH5alH5x66qk55phjkiwciv43v/lNdt5552y22WbZZ599cscdd2TNNdfMNddcU5in8jD00NTUdVtuX0AxWNZ2bF9Ac/fll1/mqquuSpKceOKJ2XrrrZdp/rKysqyzzjrZcccdq70Qmix8kOLII48s/P+1115bvoChntW1D1S+kfv9738/hx9++BLrbbnlljnssMOSJOPHj9cHaFIaYlvu3IDmpiG25/oBzUlD9IHHH3+88MD0IYccUo/RwoqzLO248vWe2bNn11i3crJZq1at6hAhrDj11cZdT+XbbNCgQbnhhhuSJFtttVXuueee7LHHHmnfvn1at26dzTffPNdcc03OPffcJMkHH3yQX/3qV40YMdTOsp7/1vWaLDRFy9oPJkyYkJ/85CeZPXt2OnXqlHvuuSdHH310unbtmlatWqVHjx4566yzcsstt6Rly5aZOnVqzjzzTC/josmoj/sK+kHzIWEGgKIxbNiwHH744fnwww+TLBxRY8CAAfnOd76z3Ms89NBDs/feeydJpk6dmqeffrpeYoWGsqz9oKSkJJdeemmuv/76fO9736vyRq0uXbrkv/7rv/LII49klVVWKXzeuXPnhl0JqGd13ZbbF1AMamrH9gU0ZxUVFfnlL3+ZGTNmpEePHjnnnHMa9Ps22WSTQnnMmDEN+l1QG/XRB9q1a1co9+7du8a6e+yxR6G8aDRLaG7qsi13bkBTtqK25/oBTVVD9IFnn302ycLz5n322aduAUIjWZZ2vPLKKxfKi0Ztqs7MmTML5Q4dOtQhQlhx6quNu57Kt9mdd95ZKP/mN7+pdkSN0047Ld/97neTJE8//XQmTJiwQuKD+lTd+e+Kvi8Bjamm60APP/xw4ZjprLPOyjrrrLPEZWy//fY59thjkyxMNnv++ecbOGqof9XdV9APmo8WjR0AANSHl156Keecc07hAOQ//uM/csstt2TNNdes87J79+5dOOBflIQATVFd+kGvXr3Sq1evfP3115k4cWLat2+fLl26FC7yjxgxolC3pqx6aKrqui23L6AYLK0d2xfQHN1zzz2Ft/iccMIJGTly5GJ1Kt+M/frrrwvtv3PnzrUaibKyyjeA586duzwhQ72qjz5QuR+svvrqNX7fGmusUShPmTKlTrFDY6nrtty5AU3Vitye6wc0RfXdBz777LMMHz48SbLNNtukW7du9RAlrFjL2o4r30sYO3ZsjfXHjh1bKOsfNBf13cZdT+Xb6P3330+SrLvuull//fVrrLvXXnvlgw8+SHl5ed57773stddeKyJEqFdLOv9d0fcloLFVdx3ovffeK5T33HPPGpfRq1ev/O1vf0uy8MUV++67b/0HCg2ouvsK+kHzIWEGgGbvoYceykUXXZT58+cnSbbeeuv85S9/SceOHaudZ/r06Rk1alS++OKL9O7du8qbf/5d5eXMmzevvsKGerU8/WBJVllllSpvvFrknXfeKZQ33XTTOsUK9aWu23L7AopBQ7Rj+wKak8pvg7788suXWv+ll17KSy+9lCT58Y9/nDPPPDNDhw7NF198kcmTJ6dPnz5p06ZNtfNPnjy5UPZmUJqC+ugDG220UZ555pkkybRp02qcv/JNgCXtK6Cx1HVb7tyAYlDX7bl+QHNX38c0ld/0aXQZmqtlbccbbLBBoTxq1KhsueWW1dYdPXp0oby0B6ahqWioNu56Kt8mi17c2L59+6XWXW211QrlGTNmNFhMsKzqev5bH9dkobHVx3WgyiPyLW2/UHmfMH369OWIGOpffdwj1g+aDwkzADRrDz74YH7xi1+koqIiycIL/r/73e/SqlWrGue7/PLL8+ijjyZZODRe5WHz/t2oUaMK5aW9mQ4aw/L2g9GjR+eBBx7I5MmTc+ihh1Z7Y6CioqJwY22dddbJ2muvXa/xw/Kq67bcvoBiUNd2bF8Ayc0335wnnngiSdKjR498//vfr7bu22+/XShvvvnmDR4brAiVt/1vv/12Dj744GrrLno7deLtuDQtdd2WOzegGNR1e64f0NzV9zHNm2++WShvv/32dQ8QGsGytuMtt9wyJSUlqaioyFtvvZUDDzyw2rpDhgxJknTv3t25Ac1GfbRx11P5tuvUqVMmTJiQMWPGpLy8PKWlpdXWHT9+fKG86qqrrojwoFac/0L99INOnTpVqbPxxhtXu4zK+4TKSQPQmOrjHrF+0HxUf9QKAE3cm2++mYsuuqiQJHDcccflj3/841KTBJJk2223LZTvv//+auuVl5dXmd6zZ886RAz1ry79YN68efnLX/6Se++9Nw8//HC19Z544omMGTMmSdKnT5/6CBvqRV235fYFFIO6tmP7Apq7q666Kh999FGN/yq/UfeAAw4ofL7oLW477LBDYXpN/WDWrFm5++67kyQtW7ZM7969G2alYBnURx/4/ve/ny5duiRJnnzyyUyaNKna73vooYeSJGVlZdljjz0acM1g2dR1W+7cgGJQ1+25fkBzV9/HNIveGt2+fft85zvfqd9gYQVZ1nbcvXv3wsP/Tz/9dLWjAbz11lsZOXJkkmTvvfeul1hhRaiPNu56Kt922223XZJkypQphREzlmTBggWFB1BbtmyZrbbaaoXEB7VR1/Pf+rgmC42tPq4DLdonJMkjjzxS4/c99thjS/xuaEz1cY9YP2g+JMwA0CzNmDEjP/vZz7JgwYIkyaGHHpqLL764xiEiK9t3330LGb733HNPXn/99cXqVFRU5IorrsgHH3yQJNlpp53yve99r57WAOqurv3gP/7jP7LhhhsmWThKTeU3Ky7y0Ucf5bLLLkuyMLv9uOOOq6fooe7qui23L6AY1LUd2xfAwn60aDj5Rx99NM8999xidebNm5cLLrig8KDDMcccU3gYD5q7srKynHzyyUkWnmOcd955+eabbxard/vttxf2M7169UrXrl1XaJxQk7puy50bUAzquj3XD2ju6vOYZvz48ZkyZUqS5Hvf+16tr7dCU7K87fj4449PkkydOjWXXnppysvLq0yfNm1aLr300iQLHxRynYjmpq5t3PVUvu0qt+dLL700n3/++WJ1ysvL8+tf/7qQeNanT5+0b99+hcUIS+P8F+qnH+y3336FEcRuv/32DBo0aInf9dhjj+WBBx5IsvBYaqeddqrXdYHlVR/3iPWD5qNFYwcAAMvjzjvvzNixY5MkXbp0yRFHHJEPP/xwqfN17949HTt2TLt27XLZZZflnHPOybx583LSSSfl8MMPz6677prOnTtn5MiRufvuu/POO+8kWTik5BVXXNGg6wTLqq79IEl++tOf5rTTTsucOXNy3HHH5b/+67+yxRZbZP78+Xn11Vdz1113ZdasWSkrK8uVV16ZDh06NOQqwTKp67bcvoBiUB/t2L6Ab7v27dvn0ksvzbnnnpvy8vKcddZZOfzww9O7d++0a9cuH3/8cQYMGJCPP/44ycJhtn/yk580ctRQv0488cS8+OKLeeONN/L666/n4IMPzoknnphNNtkk06dPz6OPPprHH388SbLqqqvmkksuaeSIoaq6bsudG1As6rI91w8oBvV1TPPZZ58Vyuuss86KCB3q3fK24/322y8PPvhgXn311Tz++OMZN25cTjjhhHTr1i0fffRRbrzxxsKDQmeeeWbWXnvt+g4dGlR9tHHXU/k222qrrXLSSSfltttuy/jx43PwwQfnyCOPzE477ZRVVlkln376aZXzhnXXXTc//elPGzlqqMr5L9RPP2jXrl3++7//O2eccUYWLFiQ008/Pfvtt1/22WefdO3aNRMmTMiTTz6ZgQMHpqKiIiuttFKuuuqqtGjhsXWahvq4R6wfNB8lFRUVFY0dBLDiDB48OCeccEKSpF+/fh7yodnabbfdCokCy+LKK6/MIYccUvj/448/nosvvjgzZ86sdp7NNtss1157bdZaa63lihUaSn31g9tvvz2//e1vCyPV/Lv27dvnqquuyl577bXcsUJDquu23L6AYlDXdmxfQDH74osvsueeeyZJDjjggFx99dVLrPfwww/nV7/6VWbNmlXtsnr27Jk//vGPWWWVVRokVmgIte0Ds2fPzgUXXJCnnnqq2mX16NEjN9xwQ9Zff/0GiRXqqq7bcucGFIO6bs/1A5q7+jimefjhh3PBBRckSX7yk5+kX79+DRIrNKS6tOMZM2akX79+efPNN6ut07dv31x44YVGYKLJWJbnIOqjjbueSlO1vM8EXXfddbn++uuTJP3798+OO+5Ybd2Kiopce+21ufHGGxcbpamyLbbYItdee226d+++DGsAdbMsfaAhz39re00WGsKK7gfPPvtsLrzwwsyYMaPaZXTp0iV//OMfs+2229ZyLaBulqUf1Mc9Yv2g6ZOiBECz89VXXy1XksCS7L///tl2221z11135eWXX86oUaMyd+7cdOrUKZtvvnn222+//OAHP0hpaWm9fB/Ul/rsByeeeGK22WabDBgwIEOGDMnEiRPTsmXL9OjRI7vttluOO+64rLbaavXyXdAQ6rotty+gGNS1HdsXQNKnT59sv/32ueuuu/Lqq68W+lHnzp2z+eab56CDDirc4IJitNJKK+Xaa6/Na6+9lgceeCD/+Mc/MmnSpLRv3z7rrrtu9t9///Tp0ycrr7xyY4cK1arrtty5AcWgrttz/YDmrj6Oab755ptCefXVV18RYUO9q0s7bteuXQYMGJCHH344jz76aIYNG5bp06enU6dO2WqrrXLsscdmhx12qO+QYYWpjzbueirfZiUlJTnnnHNywAEH5H/+53/yxhtv5Msvv8y8efPSqVOnfO9738v+++/vvIEmz/kv1E8/6NWrV/7zP/8zf//73/Pyyy9n5MiR+eabb9K+fftssMEG2WOPPXLEEUe4t0CTVR/3iPWDps8IMwAAAAAAAAAAAAAAABQV6a8AAAAAAAAAAAAAAAAUFQkzAAAAAAAAAAAAAAAAFBUJMwAAAAAAAAAAAAAAABQVCTMAAAAAAAAAAAAAAAAUFQkzAAAAAAAAAAAAAAAAFBUJMwAAAAAAAAAAAAAAABQVCTMAAAAAAAAAAAAAAAAUFQkzAAAAAAAAAAAAAAAAFBUJMwAAAAAAAAAAAAAAABQVCTMAAAAAAAAAAAAAAAAUFQkzAAAAAAAAAAAAAAAAFBUJMwAAAAAAAAAAAAAAABQVCTMAAAAAAAAAAAAAAAAUFQkzAAAAAAAAAAAAAAAAFBUJMwAAAAAAAAAAAAAAABQVCTMAAAAAAAAAAAAAAAAUlRaNHQAAAAAAAAANa6ONNkqSrLnmmnnhhRca7Huuueaa3HTTTTn44INz1VVX1WqeefPmZeDAgRk4cGCGDh2aadOmpUOHDll77bXTu3fv9OnTJ6uuumqtljVr1qzce++9eeqpp/LJJ59k1qxZ6dq1azbZZJMccsgh2XPPPeuyegAAAAAAQDMiYQYAAAAAAIA6e/PNN3Prrbcu0zyjR4/OWWedlaFDh1b5fNKkSZk0aVLeeeed3HjjjbnoootywAEH1LisESNG5PTTT8/nn39e5fMxY8ZkzJgxee6557LHHnvk97//fdq1a7dMcQIAAAAAAM2PhBkAAAAAAADqZOjQoTnjjDOyYMGCWs8zefLkHHfccRk3blySZKWVVspee+2VHj16ZMqUKRk8eHA++eSTTJ06NT/72c9SVlaWfffdd4nLmjBhQk488cRMnDgxSbL66qunV69eWXXVVTN8+PA899xzmTt3bl544YWcc845ufHGG1NWVlb3FQcAAAAAAJosCTMAAAAAAAAst0GDBuVnP/tZpk+fvkzzXXHFFYVkme9+97u54YYb0r1798L0BQsW5JZbbskf/vCHVFRU5JJLLskuu+yyxNFhLr/88kKyzB577JFrrrkmbdu2LUwfPnx4/uu//itjx47NK6+8kvvuuy9HHXXU8qwuAAAAAADQTJQ2dgAAAAAAAAA0P3Pnzs0111yT008/fZmTZb788ss88cQTSZI2bdrk2muvrZIskyRlZWU57bTTsvvuuydJpk+fnscff3yxZQ0bNizPPvtskqRz586LJcskyQYbbJDrr78+JSUlSZIbbrgh8+fPX6aYAQAAAACA5kXCDAAAAAAAALVWUVGRgQMH5gc/+EFuuummVFRUpKSkJLvttlutl/Haa6+lvLw8SdKzZ8+svfba1dbdeeedC+Xhw4cvNv3BBx8slI8//vjFkmUW2WyzzQrJNxMmTMgbb7xR63gBAAAAAIDmp0VjBwAAAAAAANDQ9thjj4wZMyZJ8tFHH9VY9/jjj8+QIUOSJM8//3zWWmutxerMnj07Dz/8cJ599tl8+OGHmTZtWtq0aZMePXpk5513zjHHHJMuXbrU+D1jxozJPffck9deey2jRo3KzJkz07Fjx6y//vrZfffdc/jhh1eb/FHZjBkzcvfdd+eZZ57JJ598kgULFmSNNdZI7969c+KJJ2bVVVetcf4LL7wwDz30UFq1apX3338/w4YNy29/+9u88847adOmTTbYYIMcd9xx6d27dyHuc889tzB/586dc9lll6V9+/Z58cUXlxpvkhx22GHZbbfdMnz48KXGN2fOnEK5RYvFb229+uqrhfKuu+5a47J23XXXvPDCC0mSZ599Nj179lxivYqKigwaNCiPPfZY/vnPf2bChAlp2bJlVl999Wy77bY55phjsvHGG9f4XTNmzMgDDzyQF198MR9//HGmTZuWlVdeOWuttVZ69uyZo446arFRdSpb1A7XXHPNvPDCC5kxY0b+9re/5emnn84XX3yRioqKrLvuutltt91y/PHHp3Pnzost45xzzsmTTz6ZJPnxj3+cM888s8aYv/zyy+yxxx6pqKjIxhtvnEceeaTG+gAAAAAA0JRJmAEAAAAAAFgGr7/+ei688MKMGzeuyufTp0/P+++/n/fffz933HFHrrrqquy1116Lzb9gwYL8+c9/zl//+tfMnz+/yrSJEydm4sSJef3113PTTTflyiuvzC677FJtLMOGDctpp522WCyffvpp/vrXv+b+++/Pn//851qv26hRo3L88cfn66+/TpLMmjUrgwcPLiTLVNaiRYscccQROfvss9OxY8cMHjy41t+TLEy0WVKSR2Xl5eV56qmnCv/fYostqkyfNWtWPv300yRJ69atl5rEsuWWWxbK77333hLrfPHFFznvvPPyzjvvVPl83rx5+fTTT/Ppp5/mvvvuS79+/XL22WcvcRnPPPNMLr744kydOrXK51OnTs3UqVPzr3/9K7fddlvOPPPMnHrqqTXGnCz8u5xyyin5/PPPq3w+bNiwDBs2LHfeeWeuu+667LjjjlWm9+nTp5Aw8/jjjy81Yebxxx9PRUVFkuSggw5aalwAAAAAANCUSZgBAAAAAACopddeey2nnnpq5s2blyTp0KFD9txzz6y99tqZPHlyBg0alDFjxmT69Ok5++yzc9ttt2X77bevsoxLL7009913X+H/G2ywQXr27JmOHTtmzJgxeeGFFzJp0qRMmjQp/fr1y9VXX5199913sViGDRuW4447LtOnT0+SrLrqqunVq1e6d++esWPH5plnnsmkSZNqlZCxyEUXXVRIllmktLS0SsJMy5Ytc+yxx6Zv375ZZ511ar3sZTVhwoT87ne/yz//+c8kyYYbbpi99967Sp3PP/+8kOCx5pprpqSkpMZlVh7R5bPPPlts+vjx43PMMcdk/PjxSRau684775xNNtkkc+bMyZtvvpl//vOfKS8vz5///Oe0atUqp59+epVlPPLII7ngggsKcXXp0iV77LFH1lhjjUydOjWvvPJKPvnkk8ydOzfXXHNNxo0bl0suuaTamGfPnp1+/frl888/T6tWrdKrV6+sv/76mTx5cp555plMmDAhM2bMyKmnnpq//vWvVUbN6dmzZzp37pxJkybls88+ywcffJDvfve71X7XY489lmTh33y//far8bcEAAAAAICmTsIMAAAAAABALXzzzTc5//zzC8kye+65Z6688sp06NChUOf888/PL3/5yzz22GOZP39+Lrnkkjz55JMpLS1Nktx///2FZJkWLVrk4osvzpFHHlkl0ePnP/95fv3rX+fBBx/MggUL8otf/CKbbLJJ1ltvvSrxXHbZZYVkmV122SV/+MMf0r59+8L08847L+edd15eeumlWq3f3LlzM3jw4Ky33nq57LLLsvnmm2fMmDEZPHhwunbtWqjXrVu3GhM86uLxxx/PBx98kJEjR+bVV18t/Nbrrbdebr755pSVlVWpP3HixEJ59dVXX+ryO3TokJVWWimzZ8/OzJkzM3PmzLRt27Yw/ZJLLikky6y33nq54YYb8p3vfKfKMu688878+te/TpJcf/31OfDAA7PmmmsmSUaMGJFf/vKXhWSZI488Mj//+c/Tpk2bwvwXXHBB7rzzzlx55ZVZsGBB7rrrrmy55ZY58MADlxjz5MmTM3ny5Ky99tq58cYbq8Tz05/+NBdeeGGefvrpzJs3L7/61a/yxBNPpFWrVkkWtrH99tsvt99+e+H3rS5hZtiwYfn444+TJDvuuGO6deu21N8TAAAAAACastLGDgAAAAAAAKA5ePjhhwsJGptuummuvfbaKskySdK6detcccUV6dGjR5KFo5gMHjw4STJv3rzccMMNhboXXnhhjjrqqMVGRWnbtm2uvPLK7L777kmSWbNmVZkvSV588cX84x//SJKstdZa+dOf/lQlWSZJVllllVx//fWLJXzUpGXLlrn11luz/fbbp02bNll//fVz7LHH1nr+uvrrX/+a2267LYMGDSoky2y66aa5/fbbl5gQsyhhKElWWmmlWn1H5XqV5x8+fHhefPHFJAv/BrfccssSf7vjjjsuffr0SZLMnz8/999/f2HaDTfcUIi7d+/eufzyy6skyyRJSUlJjj/++Jx33nmFz/7f//t/mT9/frUxt2nTJrfeeuti8bRt2zZ/+MMfsummmyZJRo8eXWX0oiSFWJPkiSeeKCTz/LtFo8skqTZ5BwAAAAAAmhMJMwAAAAAAALXw3HPPFcqnn356WrZsucR6rVq1yrHHHpvvfe97OeCAAwqjorz99tv58ssvkyxMcllaIsrPf/7zQjLNU089lZkzZxamPf/884XyD3/4w8WSMirHcvrpp9di7RbabbfdCqOlNIaxY8cu9tnQoUOz9957589//vNiyR5z584tlGubMNO6deslzl/573vooYdmrbXWqnYZxx57bDbccMP07t07a6yxRpJk9uzZefbZZ5MsTIo5//zza4yjb9++hd96zJgxeeONN6qte8wxx2Tddddd4rQWLVrkjDPOKPz/mWeeqTJ90003zYYbbpgkGTduXN56663FllFRUZGBAwcmWZiE06tXrxpjBwAAAACA5kDCDAAAAAAAwFLMnTs3b775ZpKkrKwsu+yyS431TzjhhNx///25+uqrs9122yVJlYSIXr16pbS05ts06667bmHkkHnz5uWdd94pTPvf//3fQnlpsey+++6LjWJTnS233LJW9RpCRUVF+vfvn3/84x959913c9999+Wggw5KsnCUnWuvvTZXXHFFlXkWJSMlqfU6Vk66qfw3qPyb7rbbbjUuY/PNN89jjz2W6667LocffniS5J133ikk4Gy66aZZe+21a1xGaWlpevfuXfj/ova1JPvtt1+Ny9pll10KCVxvvfVWZs+eXWV65VFmHn/88cXmf/PNNwvJSr169Urbtm1r/D4AAAAAAGgOJMwAAAAAAAAsxeTJkzNv3rwkC0eHqe1oJpV98cUXhfLGG29cq3kq1xs9enSSpLy8POPGjUuStGzZcqmJGe3atav1qDE1jarS0EpKSrL55ptn5ZVXTps2bbL55pvnd7/7XS666KJCnQEDBuSf//xn4f+VEzvmzJlTq++pPKpMq1atCuVFv2mSbLDBBsscf339ff9dy5Yts9FGG9W4nFatWhXawfz58zNhwoQq0yuPdPT0009n/vz5VaY/9thjhfKiJCUAAAAAAGjuJMwAAAAAAAAsxaRJkwrlVVZZZbmWMXXq1EK5Y8eOtZqncr1p06YVlrNgwYIkSfv27Ws1skqnTp1q9X3Lu24N6fjjj8+OO+5Y+P8DDzxQKFdOmPn3UVWqU7le+/btC+XJkycXysvzO0yZMqVQ7tChQ63mqfx3WfT3/XerrLJKWrRosdRlVf7Oyu01Sbp27Zrvf//7hTgrj6Yzd+7cPP3004vVAwAAAACA5k7CDAAAAAAAQCUVFRWLfbYoQaW+llubJJdk4WgyyzrPkrRs2bJW9RaNQtLU7LvvvoXyv/71r0K5a9euhfK/j6qyJNOmTSskzLRr167KSEH/PupKXdT2b1W5XVU3T22SZf59WUv6e/fp06dQfvzxxwvll19+uZCss//++6e01O1DAAAAAACKgyveAAAAAADAt8qSEmIqmzNnzmKfVR6JZPr06cv1vZVHi6k8GklNKtdbNOpJp06dCgkR06dPr5JUU50ZM2YsQ6Qrzpw5c2qVjNS9e/dC+ZtvvimU11133cJvMWbMmKUu58svvyyUe/ToUWVa5VFlvv7666Uu699VHuGlLn/ff1fb9lZ5hJrKiUSL9OrVKyuvvHKS5Pnnn8/cuXOTJAMHDizUOeigg2r1XQAAAAAA0BxImAEAAAAAAIpe5dE7FiUKVGfixImLfbbGGmsURvr44osvlrqMcePG5dxzz80f//jHPPfcc0mSddZZpzB92LBhtYr7ww8/LJTXXnvtJAvXZVECybx58/Lpp5/WuIz58+fn888/r9X3rSiXX355dtlll2yxxRYZPHjwUutXTgbp1KlTodyiRYusv/76SRYm0owYMaLG5bz77ruF8ne/+90q0xb9vkmW+psmyS9+8YtcddVVueuuu1JeXl7l7/vRRx8tdf5kyX/ffzdz5syMGzeuxuXMmjUro0ePTpK0bds2q6222mJ1Vlpppey9995JFv5WgwcPzvz58/PKK68kSTbaaKNsvPHGtYobAAAAAACaAwkzAAAAAABA0WvTpk2h/NVXX1Vbb+LEiRk7duwS51+UTDB//vy8/vrrNX7f4MGDM3DgwPz1r3/NoEGDkiTbbLNNYfozzzyz1JFhRo4cWUi8KCsryxZbbFGYtuuuuxbKzz777FJjWdKoOY2poqIi48ePT0VFRZ566qml1l+U1JEkm222WZVpu+22W6H80ksv1bicytN32mmnKtO22mqrJX7fkowbNy4PPPBA+vfvn7/97W8pLS3NFltsURjtZujQoRk1alSNyygvLy8kUyXJ1ltvXW3dl19+ucZlDRo0qNCedt1110Jy17/r06dPofzCCy/kzTffLIxgY3QZAAAAAACKjYQZAAAAAACg6HXt2rVQ/t///d9q6910003VTjvggAMK5RtvvDEVFRXV1v373/9eKO+1115Jku23374wMsyYMWNy11131Rjz7373u0J51113Tbt27Qr/32+//Qrl22+/PZMmTVriMsrLy3PDDTfU+D2NYdFIJ0nyyCOP5Isvvqi27vvvv5/HHnus8P/Kf4ek6m/Rv3//zJgxY4nLee+99/Liiy8mWThKze67715l+oEHHlgoP/DAA9X+pknyP//zP4Xyor9v27ZtC+tVUVGRq6++utr5k2TAgAGF5KxVV1013//+96ute+utt2b27NlLnDZ37tz85S9/Kfx/3333rXY52223XdZcc80kC5NsFv0epaWl2X///WuMFwAAAAAAmhsJMwAAAAAAQNGrnIxw7bXXZvTo0VWml5eX5+abb86dd95Z7TIOO+ywdOvWLUny9ttv55e//OViSQwLFizIFVdckXfeeSdJsuGGGxZGg2nRokXOOOOMQt2rrroqd99992KJN7NmzcpFF12UF154IcnC0W3OO++8KnW22mqrQnLGlClTcsopp+TLL7+sUmf27Nn5xS9+kbfffrvadWosO+ywQ7bddtskC+M8/fTTM2bMmMXqDRkyJKeddlrmz5+fJNl///2rjLSTJBtssEEhSWTChAn50Y9+lGnTplWpM3z48Jx55pmF3/rUU09Nq1atqtTZZJNNCkk0U6dOzWmnnZZx48YtFtMTTzyRW2+9NcnCv81xxx1XmHbaaacVlvv000/nkksuyaxZs6rMX1FRkb///e9VEqIuuOCCxeKp7LPPPstZZ52Vr7/+usrn06dPz1lnnZWPP/44ycKEmF69elW7nJKSkkJi0NixY3P//fcnWdg/FrVtAAAAAAAoFiUVNb3+DAAAAAAAoAh89dVX6d27d6ZPn54kWWmllbLPPvtknXXWyVdffZVBgwbliy++SKtWrdKzZ89Cssrzzz+ftdZaq7CcN998MyeddFLmzp2bZOHINXvuuWe6d++eKVOm5IUXXsjnn3+eZOGII3feeWe++93vVonl/PPPzyOPPFL4/wYbbJCdd945HTp0yJdffpkXXnghEydOTLJw5I8rrrgiBx988GLrNHHixBx55JGFRJO2bdumd+/e6dGjRyZPnpxnn30248aNS7t27bLSSitl0qRJWXPNNQvrtsiFF16Yhx56KMnCUU+233775fqNBw8enBNOOCFJcvDBB+eqq66qsf7o0aNz9NFHF9a1devW6dWrVzbYYIPMmjUr//jHPzJkyJBC/c022yx33HFH2rZtu9iyJkyYkEMOOaSwrE6dOmWfffZJly5dMmLEiDzzzDOFv9l2222Xv/3tbykrK1tsOV999VUOO+ywwm/apk2b7LnnnvnOd76TuXPnZvDgwfnHP/5RqH/ZZZflqKOOqrKM++67LxdffHEhOadLly7ZY489ssYaa2TatGl55ZVXMnz48EL9Qw89NFdcccVisRx//PGF9W/ZsmXmzZuXTp06Ze+990737t0zduzYPP3005kyZUqSZLXVVstdd92V9dZbr8bf/bPPPqsywk+ycDSjgw46qMb5AAAAAACguZEwAwAAAAAAfCsMGTIkP/7xjxcbfWSRDh065KqrrsrIkSMLo3/8e8JMkrz11ls599xzM378+Gq/q1u3bvnjH/+Y//zP/1xsWnl5ea699trccssthZFTlqRLly75/e9/X2V0nH83YcKE9OvXLx988MESp7dt2zbXXnttrrnmmgwbNqxJJcwkyeeff55zzjknQ4cOrbHeAQcckMsvv3yJyTKLjBgxIv369cuoUaOqrbPTTjvlT3/6U9q1a1dtnfHjx+fss88ujBK0JK1bt87Pf/7zHH300Uuc/uSTT+ZXv/pVpk6dWu0yWrZsmfPOOy99+/Zd4vTKCTNXX311fvOb31S7vA033DB/+ctfFmur1TnyyCPz7rvvJlnYRv73f/+3xt8WAAAAAACaoxaNHQAAAAAAAMCKsN122+Xpp5/OHXfckRdeeCGjRo1KRUVF1lxzzey+++457rjj0q1bt9x66601LmebbbbJM888k/vuuy/PP/98hg8fnmnTpqVNmzZZf/3106tXrxxxxBHVJmWUlpbmJz/5SQ499NDcc889ef311zNmzJhMnz497du3z8Ybb5y99torhxxySFZeeeUaY+natWvuvffePPTQQ3nsscfy4YcfZtasWenatWt69uyZk08+Oeuuu26uueaa5f7dGtK6666b+++/P0899VQGDhyY999/P1OmTEnr1q2z+uqrZ9ttt81hhx2WzTbbbKnL+s53vpPHH388d999d55++umMGDEiM2bMSIcOHbLZZpulT58+2WeffVJSUlLjcrp165a///3vefbZZzNw4MC89957mTRpUlq0aJG11lorPXv2zLHHHltjcso+++yTnj175t57781LL72UESNGZNq0aWnVqlV69OiRnXfeOUceeWTWWGONWv1OW221VQYOHJhbb701zz//fMaOHZuVVlopm2yySQ444ID06dMnLVu2rNWykuTAAw8sJMz06tVLsgwAAAAAAEXJCDMAAAAAAADQxFQeYWZJIx3VxXXXXZfrr78+SdK/f//suOOO9bZsAAAAAABoKkobOwAAAAAAAABgxXn00UeTJN27d88OO+zQyNEAAAAAAEDDkDADAAAAAAAA3xIvv/xyRo0alSQ59NBDU1rqdiEAAAAAAMXJFXAAAAAAAAAoUjNmzCiU//nPf+biiy9OkrRs2TJHHnlkY4UFAAAAAAANrkVjBwAAAAAAAAA0jOuvvz733XdfSktL8/XXXxc+P/HEE9O1a9dGjAwAAAAAABqWhBkAAAAAAAAoUquvvnqVUWaSZMstt8xZZ53VSBEBAAAAAMCKIWEGAAAAAAAAitRmm22WHj16ZMyYMenatWt+8IMf5Iwzzkjr1q0bOzQAAAAAAGhQJRUVFRWNHQQAAAAAAAAAAAAAAADUl9LGDgAAAAAAAAAAAAAAAADqk4QZAAAAAAAAAAAAAAAAioqEGQAAAAAAAAAAAAAAAIqKhBkAAAAAAAAAAAAAAACKioQZAAAAAAAAAAAAAAAAioqEGQAAAAAAAAAAAAAAAIqKhBkAAAAAAAAAAAAAAACKioQZAAAAAAAAAAAAAAAAioqEGQAAAAAAAAAAAAAAAIqKhBkAAAAAAAAAAAAAAACKioQZAAAAAAAAAAAAAAAAioqEGQAAAAAAAAAAAAAAAIqKhBkAAAAAAAAAAAAAAACKioQZAAAAAAAAAAAAAAAAioqEGQAAAAAAAAAAAAAAAIqKhBkAAAAAAAAAAAAAAACKioQZAAAAAAAAAAAAAAAAioqEGQAAAAAAAAAAAAAAAIqKhBkAAAAAAAAAAAAAAACKyv8HODg7L+YlT4QAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 4000x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#16 Classes of Infant Death\n",
    "plt.figure(figsize=(20,8),dpi=200)\n",
    "sns.countplot(x='ucodr130copy',data=df_int)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f356376",
   "metadata": {},
   "source": [
    "### Creating a Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a974941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7008561643835617\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aged</th>\n",
       "      <td>0.034104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brthwgt</th>\n",
       "      <td>0.033055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oegest_r10</th>\n",
       "      <td>0.032219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combgest</th>\n",
       "      <td>0.029742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ager22</th>\n",
       "      <td>0.028080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oegest_comb</th>\n",
       "      <td>0.027185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bwtr14</th>\n",
       "      <td>0.025928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lmpused</th>\n",
       "      <td>0.023735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eanum</th>\n",
       "      <td>0.023077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranum</th>\n",
       "      <td>0.022416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estrec10</th>\n",
       "      <td>0.020859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>econdp_2</th>\n",
       "      <td>0.020690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>econds_2</th>\n",
       "      <td>0.020656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ager5</th>\n",
       "      <td>0.019239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apgar5</th>\n",
       "      <td>0.018423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bwtr4</th>\n",
       "      <td>0.017694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospd</th>\n",
       "      <td>0.014457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seqnum_co</th>\n",
       "      <td>0.014218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dob_tt</th>\n",
       "      <td>0.014101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dwgt_r</th>\n",
       "      <td>0.012540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wgt_r</th>\n",
       "      <td>0.012085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             col_name\n",
       "aged         0.034104\n",
       "brthwgt      0.033055\n",
       "oegest_r10   0.032219\n",
       "combgest     0.029742\n",
       "ager22       0.028080\n",
       "oegest_comb  0.027185\n",
       "bwtr14       0.025928\n",
       "lmpused      0.023735\n",
       "eanum        0.023077\n",
       "ranum        0.022416\n",
       "estrec10     0.020859\n",
       "econdp_2     0.020690\n",
       "econds_2     0.020656\n",
       "ager5        0.019239\n",
       "apgar5       0.018423\n",
       "bwtr4        0.017694\n",
       "hospd        0.014457\n",
       "seqnum_co    0.014218\n",
       "dob_tt       0.014101\n",
       "dwgt_r       0.012540\n",
       "wgt_r        0.012085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Using randomforestclassifier.feature_importances_ to find most important features\n",
    "\n",
    "X = df_int.drop(['ucodr130copy','ucodr130'],axis=1)\n",
    "y = df_int['ucodr130copy']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "\n",
    "feature_names = [f\"feature {i}\" for i in range(X.shape[1])]\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print('Accuracy score:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "imp_features = pd.DataFrame({'col_name': rf.feature_importances_}, index=X.columns).sort_values(by='col_name', ascending=False)\n",
    "\n",
    "display(imp_features.head(21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a83249fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aged',\n",
       " 'brthwgt',\n",
       " 'oegest_r10',\n",
       " 'combgest',\n",
       " 'ager22',\n",
       " 'oegest_comb',\n",
       " 'bwtr14',\n",
       " 'lmpused',\n",
       " 'eanum',\n",
       " 'ranum',\n",
       " 'estrec10',\n",
       " 'econdp_2',\n",
       " 'econds_2',\n",
       " 'ager5',\n",
       " 'apgar5',\n",
       " 'bwtr4',\n",
       " 'hospd',\n",
       " 'seqnum_co',\n",
       " 'dob_tt',\n",
       " 'dwgt_r',\n",
       " 'wgt_r']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Top 21 features\n",
    "display(imp_features.head(21).index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d68f509a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aged</th>\n",
       "      <th>brthwgt</th>\n",
       "      <th>oegest_comb</th>\n",
       "      <th>lmpused</th>\n",
       "      <th>ager22</th>\n",
       "      <th>ager5</th>\n",
       "      <th>ranum</th>\n",
       "      <th>combgest</th>\n",
       "      <th>bwtr14</th>\n",
       "      <th>oegest_r10</th>\n",
       "      <th>...</th>\n",
       "      <th>estrec10</th>\n",
       "      <th>eanum</th>\n",
       "      <th>econds_2</th>\n",
       "      <th>apgar5</th>\n",
       "      <th>obgest_flg</th>\n",
       "      <th>seqnum_co</th>\n",
       "      <th>dob_tt</th>\n",
       "      <th>hospd</th>\n",
       "      <th>dwgt_r</th>\n",
       "      <th>ucodr130copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1559</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1504</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>3288</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1752</td>\n",
       "      <td>2</td>\n",
       "      <td>195</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2438</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1222</td>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>2920</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1107</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>613</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>100</td>\n",
       "      <td>3317</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>23353</td>\n",
       "      <td>1130</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23353</th>\n",
       "      <td>1</td>\n",
       "      <td>774</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>23354</td>\n",
       "      <td>730</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23354</th>\n",
       "      <td>83</td>\n",
       "      <td>3080</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>23355</td>\n",
       "      <td>1847</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23355</th>\n",
       "      <td>0</td>\n",
       "      <td>2325</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>23356</td>\n",
       "      <td>444</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23356</th>\n",
       "      <td>127</td>\n",
       "      <td>3011</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>23357</td>\n",
       "      <td>2051</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23357 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aged  brthwgt  oegest_comb  lmpused  ager22  ager5  ranum  combgest  \\\n",
       "0         4     1559           31        3       6      3      4        31   \n",
       "1        93     3288           36        3      14      5      3        35   \n",
       "2         0     2438           39        3       1      1      1        39   \n",
       "3       141     2920           39        3      15      5      2        39   \n",
       "4         0      580           22        2       2      2      2        22   \n",
       "...     ...      ...          ...      ...     ...    ...    ...       ...   \n",
       "23352   100     3317           39        3      14      5      3        39   \n",
       "23353     1      774           24        2       3      3      3        24   \n",
       "23354    83     3080           39        3      13      5      1        39   \n",
       "23355     0     2325           36        3       2      2      1        36   \n",
       "23356   127     3011           38        3      15      5      2        38   \n",
       "\n",
       "       bwtr14  oegest_r10  ...  estrec10  eanum  econds_2  apgar5  obgest_flg  \\\n",
       "0           6           3  ...         3      4         2       8           3   \n",
       "1           9           5  ...         5      3         1       9           3   \n",
       "2           7           7  ...         7      1         0       2           3   \n",
       "3           8           7  ...         7      2         1      10           1   \n",
       "4           2           2  ...         2      3         1       2           2   \n",
       "...       ...         ...  ...       ...    ...       ...     ...         ...   \n",
       "23352       9           7  ...         7      3         2       9           3   \n",
       "23353       3           2  ...         2      4         1       7           1   \n",
       "23354       9           7  ...         7      1         1       9           1   \n",
       "23355       7           5  ...         5      1         0       7           3   \n",
       "23356       9           6  ...         6      2         2       9           3   \n",
       "\n",
       "       seqnum_co  dob_tt  hospd  dwgt_r  ucodr130copy  \n",
       "0              1    1504      1     100            70  \n",
       "1              2    1752      2     195           118  \n",
       "2              3    1222      1     199           118  \n",
       "3              4    1107      2     168           134  \n",
       "4              5     613      1     153            70  \n",
       "...          ...     ...    ...     ...           ...  \n",
       "23352      23353    1130      2     140             1  \n",
       "23353      23354     730      1     188            70  \n",
       "23354      23355    1847      2     151           134  \n",
       "23355      23356     444      1     157            70  \n",
       "23356      23357    2051      1     201           134  \n",
       "\n",
       "[23357 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create test dataframe with top 20 features\n",
    "df_int20 = df_int[['aged',\n",
    " 'brthwgt',\n",
    " 'oegest_comb',\n",
    " 'lmpused',\n",
    " 'ager22',\n",
    " 'ager5',\n",
    " 'ranum',\n",
    " 'combgest',\n",
    " 'bwtr14',\n",
    " 'oegest_r10',\n",
    " 'econdp_2',\n",
    " 'estrec10',\n",
    " 'eanum',\n",
    " 'econds_2',\n",
    " 'apgar5',\n",
    " 'obgest_flg',\n",
    " 'seqnum_co',\n",
    " 'dob_tt',\n",
    " 'hospd',\n",
    " 'dwgt_r',\n",
    "'ucodr130copy'             \n",
    "              ]]\n",
    "df_int20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45791a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparations of different types of classifiers\n",
    "\n",
    "log = LogisticRegression()\n",
    "svc = SVC()\n",
    "lsvc = LinearSVC()\n",
    "rf = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0731cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a basic model\n",
    "def base_model(df,model):\n",
    "    X = df.drop('ucodr130copy',axis=1)\n",
    "    y = df['ucodr130copy']\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'Accuracy score for {model}: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f\"Precision for for {model}: {precision_recall_fscore_support(y_test, y_pred, average='weighted')[0]}\")\n",
    "    print(f\"Recall for for {model}: {precision_recall_fscore_support(y_test, y_pred, average='weighted')[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1fd287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for LogisticRegression(): 0.6708904109589041\n",
      "Precision for for LogisticRegression(): 0.5957816990245027\n",
      "Recall for for LogisticRegression(): 0.6708904109589041\n"
     ]
    }
   ],
   "source": [
    "base_model(df_int20,log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe23c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SVC(): 0.6818493150684931\n",
      "Precision for for SVC(): 0.6086704160673722\n",
      "Recall for for SVC(): 0.6818493150684931\n"
     ]
    }
   ],
   "source": [
    "base_model(df_int20,svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f74c31f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for LinearSVC(): 0.6585616438356164\n",
      "Precision for for LinearSVC(): 0.5487152881565704\n",
      "Recall for for LinearSVC(): 0.6585616438356164\n"
     ]
    }
   ],
   "source": [
    "base_model(df_int20,lsvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "570a763e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for RandomForestClassifier(): 0.690068493150685\n",
      "Precision for for RandomForestClassifier(): 0.6320401537111024\n",
      "Recall for for RandomForestClassifier(): 0.690068493150685\n"
     ]
    }
   ],
   "source": [
    "base_model(df_int20,rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b0bf712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for GradientBoostingClassifier(): 0.6921232876712329\n",
      "Precision for for GradientBoostingClassifier(): 0.6430173198978905\n",
      "Recall for for GradientBoostingClassifier(): 0.6921232876712329\n"
     ]
    }
   ],
   "source": [
    "base_model(df_int20,gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f819c87d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  18.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  10.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   9.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   9.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   8.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   8.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  18.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  14.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   8.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  10.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   9.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   8.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  20.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  14.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  14.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  10.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   8.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   8.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  28.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  17.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  26.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  22.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  22.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  18.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  10.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  20.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  23.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  21.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  15.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  14.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  23.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  32.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  25.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  20.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  23.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  34.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  25.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  22.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  30.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  29.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  16.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  21.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  21.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  15.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  15.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  24.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  30.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  22.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  19.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  18.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  21.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  20.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  20.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  21.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  17.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  17.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  34.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  48.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  52.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  47.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  52.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  45.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  45.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  44.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  44.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  48.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  46.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   4.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   5.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   6.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   4.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  31.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  33.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  31.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  27.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  33.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  43.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  43.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  43.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  41.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  43.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  43.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  43.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  43.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  42.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  43.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   6.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   6.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   4.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   4.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   3.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   4.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  34.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  33.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  27.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  28.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  32.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  42.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  42.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  43.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  46.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  41.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  41.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  42.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  43.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  39.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  43.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   5.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   4.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   6.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  25.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  29.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  31.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  30.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  24.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  30.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  31.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  25.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  29.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  31.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  26.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  24.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  37.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  37.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  37.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   5.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  32.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  26.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  29.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  31.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  31.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  27.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  27.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  32.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  31.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  29.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  26.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  29.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  38.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  35.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  33.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   5.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   3.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   2.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   4.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   6.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  26.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  31.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  30.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  23.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  31.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  30.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  25.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  31.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  22.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  29.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  30.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  19.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  38.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  35.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  25.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   4.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   5.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   7.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   6.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   5.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   4.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   4.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   5.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  41.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  42.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  27.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  42.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  35.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  41.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time= 1.1min\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time= 1.1min\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time= 1.1min\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  53.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time= 1.0min\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time= 1.1min\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  47.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time= 1.0min\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  51.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   4.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   4.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   4.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   4.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   3.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   4.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   4.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   4.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   4.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   4.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   4.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   4.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   4.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   4.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   5.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  39.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  31.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  43.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  30.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  32.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  46.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  43.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  39.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  37.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  49.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  36.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  54.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  32.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  43.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  42.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   4.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   4.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   5.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  30.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  19.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  25.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  34.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  23.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  31.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  45.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  28.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  26.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  41.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  30.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  27.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  41.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  29.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  28.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  18.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  24.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  22.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  23.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  29.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  30.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  23.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  22.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  25.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  29.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  26.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  22.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  16.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  17.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  21.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  21.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  24.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  21.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  23.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  27.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  25.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  21.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  22.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  28.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  25.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  21.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  19.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  19.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  18.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  15.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  15.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  23.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  25.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  23.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  20.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  25.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  27.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  20.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  21.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  19.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  18.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  14.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  15.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  15.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  14.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  16.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  15.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  19.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  18.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  14.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  20.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  22.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  14.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  17.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  18.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  14.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  17.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  18.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  22.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  20.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  14.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  28.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  25.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  15.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  21.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  31.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  33.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  22.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  24.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  38.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  27.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  25.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  34.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  31.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  18.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  26.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  19.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  15.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  16.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  35.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  26.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  20.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  24.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  35.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  25.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  21.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  32.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  32.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  22.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  18.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  18.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  16.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  14.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  15.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  29.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  25.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  28.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  28.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  20.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  19.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  27.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  31.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  21.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  17.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  17.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  15.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  16.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  22.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  26.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  17.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  15.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  16.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  24.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  25.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  10.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  17.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  21.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  15.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  23.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  24.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  16.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  25.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  23.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  15.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  19.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  16.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  18.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  24.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  22.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  17.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  17.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  21.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  25.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  19.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  15.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  19.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  10.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  10.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  17.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  20.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  14.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  14.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  14.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  18.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  13.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  15.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  15.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  23.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  13.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  19.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  18.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  10.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  17.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  17.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  21.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  14.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  25.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  24.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  22.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  26.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  35.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  23.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  21.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  34.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  32.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  22.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  26.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  37.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  14.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  18.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  24.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  20.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  15.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  20.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  25.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  30.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  22.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  20.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  28.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  31.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  23.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  23.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  31.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  17.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  22.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  19.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  23.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  27.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  22.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  19.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  21.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  28.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  24.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  19.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  14.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  18.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  17.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  17.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  20.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  24.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  16.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  16.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  22.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  26.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  17.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  15.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  17.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  14.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  22.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  23.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  23.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  22.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  16.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  17.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  15.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  20.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  25.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  17.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  21.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  23.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  19.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  17.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  18.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  14.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  23.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  15.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  17.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  20.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  15.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  14.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  18.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  16.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  15.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  16.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  16.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  17.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  11.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  22.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  20.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  22.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  24.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  18.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  17.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  17.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  33.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  27.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  23.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  26.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  32.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  27.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  28.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  34.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  27.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  24.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  19.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  15.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  15.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  20.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  24.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  25.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  20.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  24.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  33.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  24.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  22.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  27.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  32.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  24.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  23.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  15.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  15.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  15.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  18.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  28.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  21.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  21.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  27.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  23.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  19.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  20.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  27.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  28.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  14.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  19.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  17.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  15.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  15.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  24.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  16.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  16.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  18.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  23.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  14.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  16.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  21.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  15.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  22.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  21.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  16.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  22.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  14.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  16.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  23.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  23.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  18.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  18.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  15.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  14.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  16.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  16.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  18.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  17.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  15.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  16.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  16.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  14.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  15.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  14.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  16.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  18.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  14.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  10.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  17.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  19.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  15.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  21.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  24.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  18.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  21.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  21.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  29.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  27.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  21.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  24.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  31.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  28.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  23.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  24.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   2.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   3.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  16.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  14.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  14.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  16.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  20.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  27.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  20.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  19.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  21.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  28.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  26.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  20.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  21.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  30.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  26.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  23.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  21.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  14.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  23.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  28.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  17.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  18.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  25.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  25.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  18.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  18.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  14.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  14.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  23.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  15.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  16.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  22.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  22.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  10.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  10.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  17.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  18.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  18.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  14.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  14.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  15.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  22.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  23.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  15.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  23.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  21.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  24.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  17.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  19.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  10.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  14.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   9.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  15.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  15.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  14.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  21.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  16.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  18.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  17.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  12.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  10.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   9.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  10.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  11.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  20.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  17.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  15.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  15.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  18.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  29.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  23.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  20.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  22.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  28.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  27.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  29.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  28.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  17.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  22.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  18.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  14.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  18.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  19.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  27.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  25.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  19.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  25.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  24.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   8.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  19.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  14.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  17.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  24.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  24.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  24.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time= 2.0min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time= 3.0min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time= 3.5min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time= 3.5min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time= 3.4min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time= 3.5min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time= 1.7min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  18.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  14.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  14.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  14.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  19.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  20.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time= 1.8min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time= 2.3min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time= 2.5min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time= 2.6min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time= 2.6min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time= 2.6min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time= 2.7min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time= 2.6min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   9.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   6.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  28.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  16.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  17.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  26.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   3.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   5.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   4.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   5.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   6.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   9.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   7.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   8.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=  12.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=  10.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time= 1.4min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time= 1.5min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time= 1.5min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time= 1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time= 1.6min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time= 1.8min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  55.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time= 1.3min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time= 1.3min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time= 1.3min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time= 1.3min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time= 1.2min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time= 1.2min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time= 1.1min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time= 1.1min\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   4.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   5.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   3.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   3.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   3.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   5.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   5.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   3.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   4.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   6.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   5.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  36.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  38.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  35.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  26.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  31.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  25.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  38.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  15.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   9.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  14.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  19.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=44.0min\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  17.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  37.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  14.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  14.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  14.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  14.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  11.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   3.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  18.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  17.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  14.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  19.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  14.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  16.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  14.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  17.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   8.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   8.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   9.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  10.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   9.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   9.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  12.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   2.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  16.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  24.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  21.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  20.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  20.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  20.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  21.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  18.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  18.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  18.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  18.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  18.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  19.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  16.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  18.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  18.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  18.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  19.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  15.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  15.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  15.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  15.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  15.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  10.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  10.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  15.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  14.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  15.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  14.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  14.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  14.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  14.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  14.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   9.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  10.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  14.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  14.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  10.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   9.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  10.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  10.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  10.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   9.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  12.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  10.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   9.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  10.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  10.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  10.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  10.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  10.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  10.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  10.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   9.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   9.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   9.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  12.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=log2, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  18.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  19.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  20.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=  12.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  17.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  18.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  15.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  16.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  15.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.30000000000000004, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.1, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  11.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.30000000000000004, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.5; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=0.9; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=10, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=0.9; total time=   8.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  11.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=0.5, min_samples_split=0.5, n_estimators=100, subsample=1.0; total time=  10.9s\n",
      "Best hyperparameters: {'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.1, 'min_samples_split': 0.30000000000000004, 'n_estimators': 100, 'subsample': 0.9} \n",
      "\n",
      "Test set accuracy: 0.6917808219178082 \n",
      "\n",
      "Test Precision: 0.6330230067801185\n",
      "Test Recall: 0.6917808219178082\n"
     ]
    }
   ],
   "source": [
    "#Example of using GridSearch to finetune parameters for each basic model\n",
    "X = df_int20.drop('ucodr130copy',axis=1)\n",
    "y = df_int20['ucodr130copy']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "param_grid = [{\n",
    "    \"loss\":['log_loss'],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 3),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 3),\n",
    "    \"max_depth\":[5,8,10],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": ['friedman_mse', 'squared_error'],\n",
    "    \"subsample\":[0.5, 0.9, 1.0],\n",
    "    \"n_estimators\":[10,100]\n",
    "    }]\n",
    "\n",
    "grid = GridSearchCV(\n",
    "        gbc,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=5,\n",
    "        verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameters:\", grid.best_params_, \"\\n\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_accuracy, \"\\n\")\n",
    "print(\"Test Precision:\",precision_recall_fscore_support(y_test, y_pred, average='weighted')[0])\n",
    "print(\"Test Recall:\",precision_recall_fscore_support(y_test, y_pred, average='weighted')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be91245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 34 candidates, totalling 170 fits\n",
      "[CV] END .....................voting=hard, weights=(0, 1, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(0, 1, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(0, 1, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(0, 1, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(0, 1, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 0, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 0, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 0, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 0, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 0, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 1, 0); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 1, 0); total time= 4.1min\n",
      "[CV] END .....................voting=hard, weights=(1, 1, 0); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 1, 0); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 1, 0); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 2); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 2); total time= 1.9min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 2); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(1, 1, 2); total time= 1.9min\n",
      "[CV] END .....................voting=hard, weights=(1, 1, 2); total time= 1.9min\n",
      "[CV] END .....................voting=hard, weights=(1, 1, 2); total time= 1.9min\n",
      "[CV] END .....................voting=hard, weights=(1, 1, 2); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(1, 1, 2); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 1); total time= 1.9min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 1); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 1); total time= 2.4min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 1); total time= 1.9min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 1); total time= 1.9min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 2); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 2); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 2); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 2); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 2); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 3); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 3); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 3); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 3); total time= 1.8min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 3); total time= 1.7min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 0, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 0, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 0, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 0, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 0, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 0, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 1, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 1, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 1, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 1, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 1, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 2, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 2, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 2, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 2, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(2, 2, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 3); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 3); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 3); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 3); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 2, 3); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 3, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 3, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 3, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 3, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(1, 3, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 1, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 1, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 1, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 1, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 1, 2); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 2, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 2, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 2, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 2, 1); total time= 1.6min\n",
      "[CV] END .....................voting=hard, weights=(3, 2, 1); total time= 7.7min\n",
      "[CV] END .....................voting=hard, weights=(0, 2, 2); total time= 9.3min\n",
      "[CV] END .....................voting=hard, weights=(0, 2, 2); total time= 9.4min\n",
      "[CV] END .....................voting=hard, weights=(0, 2, 2); total time= 9.5min\n",
      "[CV] END .....................voting=hard, weights=(0, 2, 2); total time= 9.6min\n",
      "[CV] END .....................voting=hard, weights=(0, 2, 2); total time=12.5min\n",
      "[CV] END .....................voting=soft, weights=(0, 1, 1); total time=10.2min\n",
      "[CV] END .....................voting=soft, weights=(0, 1, 1); total time=16.5min\n",
      "[CV] END .....................voting=soft, weights=(0, 1, 1); total time=11.5min\n",
      "[CV] END .....................voting=soft, weights=(0, 1, 1); total time=13.3min\n",
      "[CV] END .....................voting=soft, weights=(0, 1, 1); total time=12.5min\n",
      "[CV] END .....................voting=soft, weights=(1, 0, 1); total time=11.7min\n",
      "[CV] END .....................voting=soft, weights=(1, 0, 1); total time=11.9min\n",
      "[CV] END .....................voting=soft, weights=(1, 0, 1); total time=10.3min\n",
      "[CV] END .....................voting=soft, weights=(1, 0, 1); total time=11.9min\n"
     ]
    }
   ],
   "source": [
    "#Example of GridSearch on Voting Classifier\n",
    "X = df_int20.drop('ucodr130copy',axis=1)\n",
    "y = df_int20['ucodr130copy']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "model2 = SVC(C= 2.25, gamma= 0.1, kernel= 'rbf',probability=True,random_state=42)\n",
    "model3 = RandomForestClassifier(\n",
    "                bootstrap= False, criterion= 'entropy', max_depth= 50, max_features= 'log2', \n",
    "                min_samples_leaf= 1, min_samples_split= 10, n_estimators= 100, random_state=42)\n",
    "model4 = GradientBoostingClassifier(\n",
    "                criterion= 'squared_error', learning_rate= 0.1, loss= 'log_loss', max_depth= 5, \n",
    "                max_features= 'log2', min_samples_leaf= 0.1, min_samples_split= 0.1, n_estimators= 100, \n",
    "                subsample= 1.0, random_state=42)\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[('svc',model2),('rf', model3),('gbc',model4)])\n",
    "\n",
    "param_grid = {'voting':['hard', 'soft'],\n",
    "              'weights':[(0,1,1), (1,0,1), \n",
    "                         (1,1,0), (1,2,2),\n",
    "                         (1,1,2), (1,2,1),\n",
    "                         (2,0,2), (2,0,3),\n",
    "                         (2,0,1), (3,0,2),\n",
    "                         (2,1,2), (2,2,1), \n",
    "                         (1,2,3), (1,3,2),\n",
    "                         (3,1,2), (3,2,1),\n",
    "                         (0,2,2)]}\n",
    "\n",
    "scoring = {'precision': make_scorer(precision_score, average = 'weighted'),\n",
    "           'recall': make_scorer(recall_score, average = 'weighted')}\n",
    "\n",
    "grid = GridSearchCV(ensemble,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring=scoring,\n",
    "                    cv=5,\n",
    "                    verbose=2,\n",
    "                    refit='precision')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameters:\", grid.best_params_, \"\\n\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.4f}\".format(best_model.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.4f}\".format(best_model.score(X_test, y_test)))\n",
    "print(\"Precision on training set:\",precision_recall_fscore_support(y_train, y_pred_train, average='weighted')[0])\n",
    "print(\"Precision on test set:\",precision_recall_fscore_support(y_test, y_pred, average='weighted')[0])\n",
    "print(\"Recall on training set:\",precision_recall_fscore_support(y_train, y_pred_train, average='weighted')[1])\n",
    "print(\"Recall on test set:\",precision_recall_fscore_support(y_test, y_pred, average='weighted')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df2a72",
   "metadata": {},
   "source": [
    "#### After using GridSearch to fine-tune each basic model, we ended using a majority ensemble method for classification to create the best model based on the precision and recall metrics. Due to the fact that we have very imbalanced classes, accuracy was not the best metric to base our model on. \n",
    "#### One thing to note is that we dropped any feature scaling. Initially we kept the feature scaling even though it did not make a difference to our model however we eliminated it when we realized that it was not allowing us to make accurate predictions.\n",
    "#### We also trimmed down the number of input features based on their definitions and user friendliness. This resulted in 8 input features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4376cba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brthwgt</th>\n",
       "      <th>aged</th>\n",
       "      <th>oegest_r10</th>\n",
       "      <th>ranum</th>\n",
       "      <th>estrec10</th>\n",
       "      <th>eanum</th>\n",
       "      <th>apgar5r</th>\n",
       "      <th>hospd</th>\n",
       "      <th>ucodr130copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1559</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3288</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2438</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2920</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>580</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>3317</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23353</th>\n",
       "      <td>774</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23354</th>\n",
       "      <td>3080</td>\n",
       "      <td>83</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23355</th>\n",
       "      <td>2325</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23356</th>\n",
       "      <td>3011</td>\n",
       "      <td>127</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23357 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       brthwgt  aged  oegest_r10  ranum  estrec10  eanum  apgar5r  hospd  \\\n",
       "0         1559     4           3      4         3      4        3      1   \n",
       "1         3288    93           5      3         5      3        4      2   \n",
       "2         2438     0           7      1         7      1        1      1   \n",
       "3         2920   141           7      2         7      2        4      2   \n",
       "4          580     0           2      2         2      3        1      1   \n",
       "...        ...   ...         ...    ...       ...    ...      ...    ...   \n",
       "23352     3317   100           7      3         7      3        4      2   \n",
       "23353      774     1           2      3         2      4        3      1   \n",
       "23354     3080    83           7      1         7      1        4      2   \n",
       "23355     2325     0           5      1         5      1        3      1   \n",
       "23356     3011   127           6      2         6      2        4      1   \n",
       "\n",
       "       ucodr130copy  \n",
       "0                70  \n",
       "1               118  \n",
       "2               118  \n",
       "3               134  \n",
       "4                70  \n",
       "...             ...  \n",
       "23352             1  \n",
       "23353            70  \n",
       "23354           134  \n",
       "23355            70  \n",
       "23356           134  \n",
       "\n",
       "[23357 rows x 9 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final dataframe we are working with\n",
    "\n",
    "df_intx = df_int[\n",
    "['brthwgt',#Imputed Birthweight in grams\n",
    "'aged',#Age at Death in Days\n",
    "'oegest_r10',#Obstetric Estimate Recode10\n",
    "'ranum',#Number of Record-Axis Conditions \n",
    "'estrec10',#Combined Gestation Recode 10\n",
    "'eanum',#Number of Entity-Axis Conditions\n",
    "'apgar5r',#Five Minute APGAR Recode\n",
    "'hospd',#Place of Death and Decendentâ€™s Status\n",
    "'ucodr130copy'#Selected Causes of Infant Death\n",
    "]]\n",
    "\n",
    "df_intx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9305bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Birthweight (grams)</th>\n",
       "      <th>Age at Death (days)</th>\n",
       "      <th>Obstetric Estimate</th>\n",
       "      <th>Number of Record-Axis Conditions</th>\n",
       "      <th>Combined Gestation</th>\n",
       "      <th>Number of Entity-Axis Conditions</th>\n",
       "      <th>Five Minute APGAR</th>\n",
       "      <th>Place of Death and Descendentâ€™s Status</th>\n",
       "      <th>Selected Causes of Infant Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1559</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3288</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2438</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2920</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>580</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>3317</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23353</th>\n",
       "      <td>774</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23354</th>\n",
       "      <td>3080</td>\n",
       "      <td>83</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23355</th>\n",
       "      <td>2325</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23356</th>\n",
       "      <td>3011</td>\n",
       "      <td>127</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23357 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Birthweight (grams)  Age at Death (days)  Obstetric Estimate  \\\n",
       "0                     1559                    4                   3   \n",
       "1                     3288                   93                   5   \n",
       "2                     2438                    0                   7   \n",
       "3                     2920                  141                   7   \n",
       "4                      580                    0                   2   \n",
       "...                    ...                  ...                 ...   \n",
       "23352                 3317                  100                   7   \n",
       "23353                  774                    1                   2   \n",
       "23354                 3080                   83                   7   \n",
       "23355                 2325                    0                   5   \n",
       "23356                 3011                  127                   6   \n",
       "\n",
       "       Number of Record-Axis Conditions  Combined Gestation  \\\n",
       "0                                     4                   3   \n",
       "1                                     3                   5   \n",
       "2                                     1                   7   \n",
       "3                                     2                   7   \n",
       "4                                     2                   2   \n",
       "...                                 ...                 ...   \n",
       "23352                                 3                   7   \n",
       "23353                                 3                   2   \n",
       "23354                                 1                   7   \n",
       "23355                                 1                   5   \n",
       "23356                                 2                   6   \n",
       "\n",
       "       Number of Entity-Axis Conditions  Five Minute APGAR  \\\n",
       "0                                     4                  3   \n",
       "1                                     3                  4   \n",
       "2                                     1                  1   \n",
       "3                                     2                  4   \n",
       "4                                     3                  1   \n",
       "...                                 ...                ...   \n",
       "23352                                 3                  4   \n",
       "23353                                 4                  3   \n",
       "23354                                 1                  4   \n",
       "23355                                 1                  3   \n",
       "23356                                 2                  4   \n",
       "\n",
       "       Place of Death and Descendentâ€™s Status  Selected Causes of Infant Death  \n",
       "0                                           1                               70  \n",
       "1                                           2                              118  \n",
       "2                                           1                              118  \n",
       "3                                           2                              134  \n",
       "4                                           1                               70  \n",
       "...                                       ...                              ...  \n",
       "23352                                       2                                1  \n",
       "23353                                       1                               70  \n",
       "23354                                       2                              134  \n",
       "23355                                       1                               70  \n",
       "23356                                       1                              134  \n",
       "\n",
       "[23357 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename Column Names\n",
    "pd.options.mode.chained_assignment = None  # default='warn'-->This removes the warning\n",
    "\n",
    "df_intx.rename(columns={\n",
    "'brthwgt':'Birthweight (grams)',\n",
    "'aged': 'Age at Death (days)',\n",
    "'oegest_r10':'Obstetric Estimate',\n",
    "'ranum':'Number of Record-Axis Conditions', \n",
    "'estrec10':'Combined Gestation',\n",
    "'eanum':'Number of Entity-Axis Conditions',\n",
    "'apgar5r':'Five Minute APGAR',\n",
    "'hospd':'Place of Death and Descendentâ€™s Status',\n",
    "'ucodr130copy':'Selected Causes of Infant Death'\n",
    "},inplace=True)\n",
    "\n",
    "df_intx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58d044cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some additional data transformation\n",
    "df_intx['Obstetric Estimate'] = df_intx['Obstetric Estimate'].replace(99, 11)\n",
    "df_intx['Combined Gestation'] = df_intx['Combined Gestation'].replace(99, 11)\n",
    "df_intx['Place of Death and Descendentâ€™s Status'] = df_intx['Place of Death and Descendentâ€™s Status'].replace(9, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5c14ca50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.44      0.46       140\n",
      "          23       0.00      0.00      0.00        30\n",
      "          29       0.00      0.00      0.00        30\n",
      "          33       0.00      0.00      0.00        53\n",
      "          39       0.00      0.00      0.00        70\n",
      "          46       0.00      0.00      0.00       109\n",
      "          53       0.42      0.22      0.29       120\n",
      "          63       0.00      0.00      0.00        43\n",
      "          67       0.00      0.00      0.00        31\n",
      "          70       0.77      0.87      0.82      2323\n",
      "         109       0.49      0.15      0.23       569\n",
      "         118       0.57      0.74      0.64      1199\n",
      "         134       0.81      0.85      0.83       702\n",
      "         138       0.55      0.81      0.65       390\n",
      "         158       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.68      5840\n",
      "   macro avg       0.27      0.27      0.26      5840\n",
      "weighted avg       0.63      0.68      0.64      5840\n",
      "\n",
      "Accuracy on training set: 0.7592\n",
      "Accuracy on test set: 0.6832\n",
      "Precision on training set: 0.7612943280230917\n",
      "Precision on test set: 0.6268571177027373\n",
      "Recall on training set: 0.7592053433807159\n",
      "Recall on test set: 0.6832191780821918\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ensemble Majority Model using the VotingClassifier class\n",
    "\n",
    "X = df_intx.drop('Selected Causes of Infant Death',axis=1)\n",
    "y = df_intx['Selected Causes of Infant Death']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    bootstrap= False, criterion= 'gini', max_depth= 20, max_features= 'log2', \n",
    "    min_samples_leaf= 2, min_samples_split= 10, n_estimators= 100,random_state=42)\n",
    "gbc = GradientBoostingClassifier(\n",
    "    criterion= 'squared_error', learning_rate= 0.1, loss= 'log_loss', max_depth= 5, \n",
    "    max_features= 'log2', min_samples_leaf= 0.1, min_samples_split= 0.1, n_estimators= 100, \n",
    "    subsample= 1.0,random_state=42)\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf),('gbc',gbc)], voting='soft')\n",
    "\n",
    "ensemble.fit(X_train.values, y_train)\n",
    "\n",
    "y_pred = ensemble.predict(X_test.values)\n",
    "y_pred_train = ensemble.predict(X_train.values)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy on training set: {:.4f}\".format(ensemble.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.4f}\".format(ensemble.score(X_test, y_test)))\n",
    "print(\"Precision on training set:\",precision_recall_fscore_support(y_train, y_pred_train, average='weighted')[0])\n",
    "print(\"Precision on test set:\",precision_recall_fscore_support(y_test, y_pred, average='weighted')[0])\n",
    "print(\"Recall on training set:\",precision_recall_fscore_support(y_train, y_pred_train, average='weighted')[1])\n",
    "print(\"Recall on test set:\",precision_recall_fscore_support(y_test, y_pred, average='weighted')[1])\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred,labels = ensemble.classes_)\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ensemble.classes_)\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "cmp.plot(ax=ax)\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48167099",
   "metadata": {},
   "source": [
    "#### Same Model but Trained on Entire Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0fcdb093",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Test: 0.756689643361733\n",
      "Precision: 0.7667184382564824\n",
      "Recall: 0.756689643361733\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df_intx.drop('Selected Causes of Infant Death',axis=1)\n",
    "y = df_intx['Selected Causes of Infant Death']\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    bootstrap= False, criterion= 'gini', max_depth= 20, max_features= 'log2', \n",
    "    min_samples_leaf= 2, min_samples_split= 10, n_estimators= 100,random_state=42)\n",
    "gbc = GradientBoostingClassifier(\n",
    "    criterion= 'squared_error', learning_rate= 0.1, loss= 'log_loss', max_depth= 5, \n",
    "    max_features= 'log2', min_samples_leaf= 0.1, min_samples_split= 0.1, n_estimators= 100, \n",
    "    subsample= 1.0,random_state=42)\n",
    "\n",
    "ensemble1 = VotingClassifier(estimators=[('rf', rf),('gbc',gbc)], voting='soft')\n",
    "\n",
    "ensemble1.fit(X.values, y)\n",
    "\n",
    "y_pred = ensemble1.predict(X.values)\n",
    "\n",
    "print(f'Accuracy score for Test: {accuracy_score(y, y_pred)}')\n",
    "print(\"Precision:\",precision_recall_fscore_support(y, y_pred, average='weighted')[0])\n",
    "print(\"Recall:\",precision_recall_fscore_support(y, y_pred, average='weighted')[1])\n",
    "\n",
    "cm = confusion_matrix(y,y_pred,labels = ensemble1.classes_)\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ensemble1.classes_)\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "cmp.plot(ax=ax)\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e99151",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model to pickle file\n",
    "with open(\"ensemble1.pkl\", \"wb\") as file: \n",
    "    pickle.dump(ensemble1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "689b08cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening saved model\n",
    "with open(\"ensemble1.pkl\", \"rb\") as file:\n",
    "    loaded_ensemble1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a646a6",
   "metadata": {},
   "source": [
    "### Making Predictions with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd98738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn Output Labels into Strings\n",
    "def predictions_to_strings(predictions):\n",
    "    label_mapping = {\n",
    "        1: 'Certain infectious and parasitic diseases',\n",
    "        23: 'Neoplasms',\n",
    "        29: 'Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism',\n",
    "        33: 'Endocrine, nutritional and metabolic diseases',\n",
    "        39: 'Diseases of the nervous system',\n",
    "        45: 'Diseases of the ear and mastoid process',\n",
    "        46: 'Diseases of the circulatory system',\n",
    "        53: 'Diseases of the respiratory system',\n",
    "        63: 'Diseases of the digestive system',\n",
    "        67: 'Diseases of the genitourinary system',\n",
    "        70: 'Certain conditions originating in the perinatal period',\n",
    "        109: 'Hemorrhagic and hematological disorders of newborn',\n",
    "        118: 'Congenital malformations, deformations and chromosomal abnormalities',\n",
    "        134: 'Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified',\n",
    "        138: 'External causes of mortality',\n",
    "        158: 'Other external causes'\n",
    "    }\n",
    "    \n",
    "    # Convert integer predictions to strings using mapping\n",
    "    string_predictions = [label_mapping[pred] for pred in predictions]\n",
    "    \n",
    "    return string_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf53da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output top 3 predictions with corresponding probabilities\n",
    "def top_3_predictions(new_data):\n",
    "    predicted_probabilities = loaded_ensemble1.predict_proba(new_data)\n",
    "    \n",
    "    for i, probs in enumerate(predicted_probabilities):\n",
    "        # Get indices of top 3 probabilities\n",
    "        top3_indices = probs.argsort()[-3:][::-1]\n",
    "        # Get corresponding class labels and probabilities\n",
    "        top3_classes = loaded_ensemble1.classes_[top3_indices]\n",
    "        top3_probs = probs[top3_indices] * 100  # Convert probabilities to percentages\n",
    "        \n",
    "        # Convert integer predictions to strings using the mapping\n",
    "        top3_classes_strings = predictions_to_strings(top3_classes)\n",
    "        \n",
    "        # Print predictions for each sample\n",
    "        print(f\"Top 3 predictions for {new_data}:\")\n",
    "        for j, (pred_class, pred_class_string, pred_prob) in enumerate(zip(top3_classes, top3_classes_strings, top3_probs)):\n",
    "            print(f\"   Prediction {j + 1}: Class {pred_class_string}, Probability of {pred_prob:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe89d2",
   "metadata": {},
   "source": [
    "#### Predicting various known patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "003c1092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predictions for [[1559    4    3    4    3    4    3    1]]:\n",
      "   Prediction 1: Class Certain conditions originating in the perinatal period, Probability of 45.23%\n",
      "   Prediction 2: Class Congenital malformations, deformations and chromosomal abnormalities, Probability of 24.42%\n",
      "   Prediction 3: Class Hemorrhagic and hematological disorders of newborn, Probability of 22.21%\n"
     ]
    }
   ],
   "source": [
    "S = np.array([[1559,4,3,4,3,4,3,1]])#70\n",
    "top_3_predictions(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "589bc9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predictions for [[2325    0    5    1    5    1    3    1]]:\n",
      "   Prediction 1: Class Congenital malformations, deformations and chromosomal abnormalities, Probability of 66.99%\n",
      "   Prediction 2: Class Certain conditions originating in the perinatal period, Probability of 23.88%\n",
      "   Prediction 3: Class Diseases of the genitourinary system, Probability of 2.62%\n"
     ]
    }
   ],
   "source": [
    "D = np.array([[2325,0,5,1,5,1,3,1]])#70\n",
    "top_3_predictions(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f84cbd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predictions for [[3011  127    6    2    6    2    4    1]]:\n",
      "   Prediction 1: Class External causes of mortality, Probability of 25.52%\n",
      "   Prediction 2: Class Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified, Probability of 22.43%\n",
      "   Prediction 3: Class Congenital malformations, deformations and chromosomal abnormalities, Probability of 20.31%\n"
     ]
    }
   ],
   "source": [
    "E = np.array([[3011,127,6,2,6,2,4,1]])#134\n",
    "top_3_predictions(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36321f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predictions for [[3288   93    5    3    5    3    4    2]]:\n",
      "   Prediction 1: Class External causes of mortality, Probability of 35.17%\n",
      "   Prediction 2: Class Congenital malformations, deformations and chromosomal abnormalities, Probability of 17.01%\n",
      "   Prediction 3: Class Certain infectious and parasitic diseases, Probability of 11.91%\n"
     ]
    }
   ],
   "source": [
    "F = np.array([[3288,93,5,3,5,3,4,2]])#118\n",
    "top_3_predictions(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e9ad3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predictions for [[2438    0    7    1    7    1    1    1]]:\n",
      "   Prediction 1: Class Congenital malformations, deformations and chromosomal abnormalities, Probability of 71.32%\n",
      "   Prediction 2: Class Certain conditions originating in the perinatal period, Probability of 15.05%\n",
      "   Prediction 3: Class Hemorrhagic and hematological disorders of newborn, Probability of 10.96%\n"
     ]
    }
   ],
   "source": [
    "G = np.array([[2438,0,7,1,7,1,1,1]])#118\n",
    "top_3_predictions(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f9625ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predictions for [[580   0   2   2   2   3   1   1]]:\n",
      "   Prediction 1: Class Certain conditions originating in the perinatal period, Probability of 78.38%\n",
      "   Prediction 2: Class Hemorrhagic and hematological disorders of newborn, Probability of 12.87%\n",
      "   Prediction 3: Class Congenital malformations, deformations and chromosomal abnormalities, Probability of 7.88%\n"
     ]
    }
   ],
   "source": [
    "H = np.array([[580,0,2,2,2,3,1,1]])#70\n",
    "top_3_predictions(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9feb8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predictions for [[3080   83    7    1    7    1    4    2]]:\n",
      "   Prediction 1: Class Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified, Probability of 95.32%\n",
      "   Prediction 2: Class Diseases of the respiratory system, Probability of 1.77%\n",
      "   Prediction 3: Class Congenital malformations, deformations and chromosomal abnormalities, Probability of 1.10%\n"
     ]
    }
   ],
   "source": [
    "I = np.array([[3080,83,7,1,7,1,4,2]])#134\n",
    "top_3_predictions(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73add68",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce0d018",
   "metadata": {},
   "source": [
    "Infant mortality is one of the world's largest public health issues. While infant mortality rates have plummeted dramatically with industrialization and the advent of modern medicine, there is still much work to be done. The loss of a child brings tremendous suffering to the expecting parent(s), especially when the cause is not clear. \n",
    "\n",
    "There are many determinants that contribute to infant mortality. Healthcare is complex and there are rarely easy answers. However in this project we have attempted to create a simple model that allows the attending physician to provide some rapid and precise answers to the grieving parent(s) as to why their child did not survive. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc78d70c",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "https://www.nber.org/research/data/linked-birthinfant-death-cohort-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c49776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
